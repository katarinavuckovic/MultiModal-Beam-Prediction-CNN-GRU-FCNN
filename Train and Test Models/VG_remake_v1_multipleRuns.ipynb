{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 01:09:51.970196: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-25 01:09:52.731366: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-25 01:09:54.897777: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sa457043/miniconda3/envs/tf_jupyter/lib/:/home/sa457043/lib/python3.10/site-packages/nvidia/cudnn/lib:\n",
      "2024-08-25 01:09:54.897905: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sa457043/miniconda3/envs/tf_jupyter/lib/:/home/sa457043/lib/python3.10/site-packages/nvidia/cudnn/lib:\n",
      "2024-08-25 01:09:54.897913: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Apr 19 13:55:28 2023\n",
    "\n",
    "@author: Saba\n",
    "\"\"\"\n",
    "\n",
    "'''\n",
    "To change at each run with different models:\n",
    "    the name of the file in commands: \n",
    "        result.to_csv\n",
    "    the name of ckpt in:\n",
    "        callbacks      \n",
    "        \n",
    "This is Lidar_Transformed plus Vision data to be trained with CNN to make a multimodal network.\n",
    "Image (Vision) is transformed from RGB to gray.\n",
    "'''\n",
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Conv2D, BatchNormalization, MaxPool2D, GlobalMaxPool2D\n",
    "from keras.layers import TimeDistributed, GRU, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.lines as mlines\n",
    "import utm\n",
    "from collections import Counter\n",
    "import random\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import math\n",
    "import pickle \n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)  # Set TensorFlow seed as well\n",
    "     \n",
    "#%% Main                \n",
    "#Score function\n",
    "def compute_acc(y_pred, y_true, top_k=[1,3,5]):\n",
    "    \"\"\" Computes top-k accuracy given prediction and ground truth labels.\"\"\"\n",
    "    n_top_k = len(top_k)\n",
    "    total_hits = np.zeros(n_top_k)\n",
    "    \n",
    "    n_test_samples = len(y_true)\n",
    "    if len(y_pred) != n_test_samples:\n",
    "        raise Exception('Number of predicted beams does not match number of labels.')\n",
    "    \n",
    "    # For each test sample, count times where true beam is in k top guesses\n",
    "    for samp_idx in range(len(y_true)):\n",
    "        for k_idx in range(n_top_k):\n",
    "            hit = np.any(y_pred[samp_idx,:top_k[k_idx]] == y_true[samp_idx, -1])\n",
    "            total_hits[k_idx] += 1 if hit else 0\n",
    "    \n",
    "    # Average the number of correct guesses (over the total samples)\n",
    "    return np.round(total_hits / len(y_true), 4)\n",
    "\n",
    "def save_pred_to_csv(sample_index, y_pred, top_k=[1,2,3], target_csv='beam_pred.csv'):\n",
    "    \"\"\" \n",
    "    Saves the predicted beam results to a csv file. \n",
    "    Expects y_pred: n_samples x N_BEAMS, and saves the top_k columns only. \n",
    "    \"\"\"\n",
    "    \n",
    "    cols = [f'top-{i} beam' for i in top_k]\n",
    "    df = pd.DataFrame(data=y_pred[:, np.array(top_k)-1], columns=cols)\n",
    "    df.index.name = 'index'\n",
    "    df['sample_index'] = sample_index\n",
    "    df.to_csv(target_csv)\n",
    "\n",
    "def compute_DBA_score(y_pred, y_true, max_k=3, delta=5):\n",
    "    \"\"\" \n",
    "    The top-k MBD (Minimum Beam Distance) as the minimum distance\n",
    "    of any beam in the top-k set of predicted beams to the ground truth beam. \n",
    "    \n",
    "    Then we take the average across all samples.\n",
    "    \n",
    "    Then we average that number over all the considered Ks.\n",
    "    \"\"\"\n",
    "    n_samples = y_pred.shape[0]\n",
    "    #n_beams = y_pred.shape[-1] \n",
    "    \n",
    "    yk = np.zeros(max_k)\n",
    "    for k in range(max_k):\n",
    "        acc_avg_min_beam_dist = 0\n",
    "        idxs_up_to_k = np.arange(k+1)\n",
    "        for i in range(n_samples):\n",
    "            aux1 = np.abs(y_pred[i, idxs_up_to_k] - y_true[i]) / delta\n",
    "            # Compute min between beam diff and 1\n",
    "            aux2 = np.min(np.stack((aux1, np.zeros_like(aux1)+1), axis=0), axis=0)\n",
    "            acc_avg_min_beam_dist += np.min(aux2)\n",
    "            \n",
    "        yk[k] = 1 - acc_avg_min_beam_dist / n_samples\n",
    "    \n",
    "    return np.mean(yk)\n",
    "\n",
    "#%% Power factor\n",
    "def compute_powerfactor(y_pred, pwrs_array, k=3):\n",
    "    '''\n",
    "    Calculate the maximum power factor for top-1 to top-k predictions.\n",
    "    \n",
    "    Args:\n",
    "    y_pred (numpy array): Sorted predictions (n_samples, 64), indices of beams sorted by probability.\n",
    "    pwrs_array (numpy array): Power values for beams (n_samples, 64).\n",
    "    k (int): The top-k predictions to consider.\n",
    "    \n",
    "    Returns:\n",
    "    numpy array: Array of average max PFs from top-1 to top-k.\n",
    "    '''\n",
    "    max_Pr = np.max(pwrs_array, axis=1)  # Maximum power across all beams for each sample\n",
    "    PF_max_k = np.zeros(k)  # Array to store the average of maximum PFs for each top-k\n",
    "    #PF_max_k_stds = np.zeros(k)  # Array to store the standard deviation of maximum PFs for each top-k\n",
    "    \n",
    "    for i in range(1, k+1):\n",
    "        max_PF = np.zeros(pwrs_array.shape[0])  # Array to hold the max PF for each sample for current top-i\n",
    "        for j in range(pwrs_array.shape[0]):  # Iterate over each sample\n",
    "            # Calculate PFs for the top-i predictions and find the maximum\n",
    "            top_k_PFs = pwrs_array[j, y_pred[j, :i]] / max_Pr[j]\n",
    "            max_PF[j] = np.max(top_k_PFs)  # Maximum PF for this sample among top-i\n",
    "        PF_max_k[i-1] = np.round(np.mean(max_PF), 2)  # Average of maximum PFs across all samples for top-i\n",
    "        #PF_max_k_stds[i-1] = np.round(np.std(max_PF), 2)  # Standard deviation of maximum PFs for top-i\n",
    "\n",
    "    return PF_max_k #, PF_max_k_stds\n",
    "\n",
    "def calculate_top_beams(predictions, truths):\n",
    "    correct_top1_count = 0\n",
    "    correct_top3_count = 0\n",
    "    total_count = len(predictions)  # Assuming predictions and truths are lists of numpy arrays\n",
    "    \n",
    "    for pred, true in zip(predictions, truths):\n",
    "        # Find the index of the highest value in the predicted array\n",
    "        top_pred_index = np.argmax(pred)\n",
    "        \n",
    "        # Find the indices of the top 3 highest values in the true array\n",
    "        top_true_indices = np.argsort(true)[-3:]\n",
    "        \n",
    "        # Check if the top predicted index is among the top 3 true indices for top-1 accuracy\n",
    "        if top_pred_index in top_true_indices:\n",
    "            correct_top1_count += 1\n",
    "        \n",
    "        # Find the indices of the top 3 highest values in the predicted array\n",
    "        top_pred_indices = np.argsort(pred)[-3:]\n",
    "        \n",
    "        # Check if there is any intersection between the top 3 predicted indices and the top 3 true indices for top-3 accuracy\n",
    "        if set(top_pred_indices) & set(top_true_indices):\n",
    "            correct_top3_count += 1\n",
    "    \n",
    "    # Calculate the percentage of correct predictions for top-1 and top-3 accuracies\n",
    "    top1_accuracy = (correct_top1_count / total_count)\n",
    "    top3_accuracy = (correct_top3_count / total_count) \n",
    "    top1_accuracy  = round(top1_accuracy, 2)\n",
    "    top3_accuracy  = round(top3_accuracy, 2)\n",
    "    return [top1_accuracy,top3_accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#%% GPU optimization\n",
    "#\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "        \n",
    "#\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\" #to allow automatic assignment of operations to different GPUs to prevent OOM issue\n",
    "'''   \n",
    "\n",
    "# Set environment variables to disable GPU usage and use CPU instead\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # This line disables GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% some global params\n",
    "model_name = \"VG_remake_v1_multipleRuns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%Load data\n",
    "def add_noise(data, noise_level):\n",
    "    noisy_data = data + np.random.normal(scale=noise_level, size=data.shape)\n",
    "    return noisy_data\n",
    "\n",
    "'''\n",
    "def add_gps_noise(GPS, noise_level):\n",
    "    GPS_noisy = np.zeros(GPS.shape)\n",
    "    GPS_noisy[:,:,0] = GPS[:,:,0] + np.random.normal(scale=noise_level, size=GPS[:,:,0].shape)\n",
    "    GPS_noisy[:,:,1] = GPS[:,:,1] + np.random.normal(scale=noise_level, size=GPS[:,:,1].shape)\n",
    "    return GPS_noisy\n",
    "'''\n",
    "\n",
    "df_train =  pd.read_csv('./ml_challenge_dev_multi_modal_v2.csv')\n",
    "index = df_train['unit1_beam'].values\n",
    "\n",
    "imagex = 150\n",
    "imagey = 150\n",
    "\n",
    "import cv2\n",
    "def rescale(data): #to rescale from 11143x5x210x360 to 11143,5,210,225\n",
    "    resized_data= np.zeros((data.shape[0],5,imagex,imagey))\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            resized_data[i, j] = cv2.resize(data[i, j], (imagey, imagex), interpolation=cv2.INTER_NEAREST)\n",
    "    return resized_data\n",
    "    \n",
    "data = np.load('vision_gray_11143x5x210x360.npz')\n",
    "vision = rescale(data['vision'])\n",
    "vision = add_noise(vision, 0.001)\n",
    "\n",
    "data = np.load('GPS_11143x5x210x360.npz')\n",
    "GPS = rescale(data['GPS'])\n",
    "GPS = add_noise(GPS, 0.05)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "multiModalData = np.zeros([11143,5,imagex,imagey,2])\n",
    "multiModalData[:,:,:,:,0] = vision\n",
    "multiModalData[:,:,:,:,1] = GPS\n",
    "multiModalData = tf.keras.utils.normalize(multiModalData.reshape([11143*5,-1]))  \n",
    "multiModalData = multiModalData.reshape([11143,5,imagex,imagey,2])\n",
    "\n",
    "del vision, GPS\n",
    "gc.collect()\n",
    "\n",
    "#Load beam predictions (categorical)\n",
    "classes = to_categorical(df_train['unit1_beam'].values - 1, num_classes = 64, dtype =\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%Model\n",
    "def build_convnet(shape=(imagex,imagey,2)):\n",
    "    momentum = .9\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(Conv2D(4, 3, input_shape=shape,padding='same', activation='relu'))\n",
    "    model.add(Conv2D(16, 3, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool2D(pool_size=3))\n",
    "    model.add(MaxPool2D(pool_size=3))\n",
    "    \n",
    "    model.add(Conv2D(16, 3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(32, 3, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool2D(pool_size=3))\n",
    "\n",
    "    model.add(Conv2D(128, 3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, 3, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool2D(pool_size=3))\n",
    "    \n",
    "    model.add(GlobalMaxPool2D())\n",
    "    return model\n",
    "\n",
    "def GRU_model(input_shape=(5, imagex, imagey, 2), nbout=64): \n",
    "    # Create our convnet with (112, 112, 3) input shape\n",
    "    convnet = build_convnet(input_shape[1:]) #all elements after shape[0] (not shape[0])\n",
    "    \n",
    "    # then create our final model\n",
    "    model = keras.Sequential()\n",
    "    # add the convnet with (5, 128,125,4) shape\n",
    "    model.add(TimeDistributed(convnet, input_shape=input_shape))\n",
    "    # here, you can also use GRU or LSTM\n",
    "    model.add(GRU(64))\n",
    "    # and finally, we make a decision network\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    #model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(nbout, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running model with seed 42\n",
      "Train Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 2683, NLoS samples count: 110\n",
      "scenario33 - LoS samples count: 3329, NLoS samples count: 120\n",
      "scenario34 - LoS samples count: 3691, NLoS samples count: 95\n",
      "\n",
      "Test Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 311, NLoS samples count: 11\n",
      "scenario33 - LoS samples count: 372, NLoS samples count: 16\n",
      "scenario34 - LoS samples count: 391, NLoS samples count: 14\n",
      "LoS Train Shape: (9703, 5, 150, 150, 2), LoS Test Shape: (1074, 5, 150, 150, 2)\n",
      "NLoS Train Shape: (325, 5, 150, 150, 2), NLoS Test Shape: (41, 5, 150, 150, 2)\n",
      "Train Labels Shape: (10028, 64)\n",
      "Test Labels Shape: (1115, 64)\n",
      "Train LoS Labels Shape: (9703, 64)\n",
      "Train NLoS Labels Shape: (325, 64)\n",
      "Test LoS Labels Shape: (1074, 64)\n",
      "Test NLoS Labels Shape: (41, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 16:55:44.889827: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-08-23 16:55:44.889862: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: edison\n",
      "2024-08-23 16:55:44.889867: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: edison\n",
      "2024-08-23 16:55:44.890008: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 560.35.3\n",
      "2024-08-23 16:55:44.890029: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: NOT_FOUND: could not find kernel module information in driver version file contents: \"NVRM version: NVIDIA UNIX Open Kernel Module for x86_64  560.35.03  Release Build  (dvs-builder@U16-I1-N07-12-3)  Fri Aug 16 21:42:42 UTC 2024\n",
      "GCC version:  gcc version 11.4.0 (Ubuntu 11.4.0-1ubuntu1~22.04) \n",
      "\"\n",
      "2024-08-23 16:55:44.892728: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDistr  (None, 5, 256)           341004    \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                61824     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 411,148\n",
      "Trainable params: 410,540\n",
      "Non-trainable params: 608\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.8226 - acc: 0.0934\n",
      "Epoch 1: val_acc improved from -inf to 0.13011, saving model to chkp/VG_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 84s 301ms/step - loss: 3.8226 - acc: 0.0934 - val_loss: 3.5747 - val_acc: 0.1301 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.4712 - acc: 0.1248\n",
      "Epoch 2: val_acc improved from 0.13011 to 0.16401, saving model to chkp/VG_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 78s 289ms/step - loss: 3.4712 - acc: 0.1248 - val_loss: 3.2564 - val_acc: 0.1640 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.1975 - acc: 0.1588\n",
      "Epoch 3: val_acc improved from 0.16401 to 0.17697, saving model to chkp/VG_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 3.1975 - acc: 0.1588 - val_loss: 2.9877 - val_acc: 0.1770 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.9553 - acc: 0.1836\n",
      "Epoch 4: val_acc improved from 0.17697 to 0.21585, saving model to chkp/VG_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 2.9553 - acc: 0.1836 - val_loss: 2.7548 - val_acc: 0.2159 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.7549 - acc: 0.2134\n",
      "Epoch 5: val_acc improved from 0.21585 to 0.21984, saving model to chkp/VG_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 2.7549 - acc: 0.2134 - val_loss: 2.6983 - val_acc: 0.2198 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.5765 - acc: 0.2484\n",
      "Epoch 6: val_acc improved from 0.21984 to 0.25872, saving model to chkp/VG_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 2.5765 - acc: 0.2484 - val_loss: 2.4644 - val_acc: 0.2587 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.4454 - acc: 0.2715\n",
      "Epoch 7: val_acc improved from 0.25872 to 0.28215, saving model to chkp/VG_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 2.4454 - acc: 0.2715 - val_loss: 2.4164 - val_acc: 0.2822 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.3444 - acc: 0.2949\n",
      "Epoch 8: val_acc improved from 0.28215 to 0.29611, saving model to chkp/VG_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 2.3444 - acc: 0.2949 - val_loss: 2.2640 - val_acc: 0.2961 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.2419 - acc: 0.3094\n",
      "Epoch 9: val_acc improved from 0.29611 to 0.31705, saving model to chkp/VG_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 2.2419 - acc: 0.3094 - val_loss: 2.1510 - val_acc: 0.3170 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.1527 - acc: 0.3296\n",
      "Epoch 10: val_acc improved from 0.31705 to 0.33450, saving model to chkp/VG_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 2.1527 - acc: 0.3296 - val_loss: 2.0848 - val_acc: 0.3345 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.0786 - acc: 0.3437\n",
      "Epoch 11: val_acc improved from 0.33450 to 0.34646, saving model to chkp/VG_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 2.0786 - acc: 0.3437 - val_loss: 2.0069 - val_acc: 0.3465 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.0045 - acc: 0.3558\n",
      "Epoch 12: val_acc improved from 0.34646 to 0.35793, saving model to chkp/VG_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 2.0045 - acc: 0.3558 - val_loss: 1.9438 - val_acc: 0.3579 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.9366 - acc: 0.3761\n",
      "Epoch 13: val_acc improved from 0.35793 to 0.38235, saving model to chkp/VG_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.9366 - acc: 0.3761 - val_loss: 1.9268 - val_acc: 0.3824 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.9130 - acc: 0.3844\n",
      "Epoch 14: val_acc did not improve from 0.38235\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.9130 - acc: 0.3844 - val_loss: 1.9443 - val_acc: 0.3649 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8473 - acc: 0.4039\n",
      "Epoch 15: val_acc did not improve from 0.38235\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.8473 - acc: 0.4039 - val_loss: 1.8631 - val_acc: 0.3764 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8276 - acc: 0.4001\n",
      "Epoch 16: val_acc did not improve from 0.38235\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.8276 - acc: 0.4001 - val_loss: 1.9283 - val_acc: 0.3789 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7935 - acc: 0.4031\n",
      "Epoch 17: val_acc did not improve from 0.38235\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.7935 - acc: 0.4031 - val_loss: 1.8402 - val_acc: 0.3759 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7391 - acc: 0.4212\n",
      "Epoch 18: val_acc improved from 0.38235 to 0.40179, saving model to chkp/VG_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.7391 - acc: 0.4212 - val_loss: 1.8258 - val_acc: 0.4018 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7161 - acc: 0.4208\n",
      "Epoch 19: val_acc did not improve from 0.40179\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.7161 - acc: 0.4208 - val_loss: 1.8586 - val_acc: 0.4013 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6894 - acc: 0.4246\n",
      "Epoch 20: val_acc did not improve from 0.40179\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.6894 - acc: 0.4246 - val_loss: 1.8150 - val_acc: 0.3898 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6552 - acc: 0.4313\n",
      "Epoch 21: val_acc improved from 0.40179 to 0.41276, saving model to chkp/VG_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.6552 - acc: 0.4313 - val_loss: 1.8187 - val_acc: 0.4128 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6395 - acc: 0.4434\n",
      "Epoch 22: val_acc improved from 0.41276 to 0.41625, saving model to chkp/VG_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.6395 - acc: 0.4434 - val_loss: 1.8153 - val_acc: 0.4163 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6023 - acc: 0.4503\n",
      "Epoch 23: val_acc did not improve from 0.41625\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.6023 - acc: 0.4503 - val_loss: 1.7922 - val_acc: 0.3993 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5819 - acc: 0.4545\n",
      "Epoch 24: val_acc did not improve from 0.41625\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.5819 - acc: 0.4545 - val_loss: 1.8103 - val_acc: 0.4033 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5690 - acc: 0.4521\n",
      "Epoch 25: val_acc did not improve from 0.41625\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.5690 - acc: 0.4521 - val_loss: 1.8608 - val_acc: 0.3973 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5633 - acc: 0.4577\n",
      "Epoch 26: val_acc did not improve from 0.41625\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.5633 - acc: 0.4577 - val_loss: 1.8600 - val_acc: 0.3968 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5236 - acc: 0.4646\n",
      "Epoch 27: val_acc did not improve from 0.41625\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.5236 - acc: 0.4646 - val_loss: 1.7998 - val_acc: 0.4148 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4950 - acc: 0.4695\n",
      "Epoch 28: val_acc improved from 0.41625 to 0.41924, saving model to chkp/VG_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.4950 - acc: 0.4695 - val_loss: 1.8129 - val_acc: 0.4192 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4820 - acc: 0.4708\n",
      "Epoch 29: val_acc did not improve from 0.41924\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.4820 - acc: 0.4708 - val_loss: 1.8218 - val_acc: 0.4143 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4838 - acc: 0.4746\n",
      "Epoch 30: val_acc did not improve from 0.41924\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.4838 - acc: 0.4746 - val_loss: 1.8258 - val_acc: 0.4128 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4541 - acc: 0.4837\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 31: val_acc improved from 0.41924 to 0.42722, saving model to chkp/VG_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.4541 - acc: 0.4837 - val_loss: 1.8048 - val_acc: 0.4272 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3518 - acc: 0.5150\n",
      "Epoch 32: val_acc improved from 0.42722 to 0.44018, saving model to chkp/VG_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.3518 - acc: 0.5150 - val_loss: 1.7849 - val_acc: 0.4402 - lr: 1.0000e-04\n",
      "Epoch 33/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3092 - acc: 0.5212\n",
      "Epoch 33: val_acc improved from 0.44018 to 0.44417, saving model to chkp/VG_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.3092 - acc: 0.5212 - val_loss: 1.7868 - val_acc: 0.4442 - lr: 1.0000e-04\n",
      "Epoch 34/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2740 - acc: 0.5323\n",
      "Epoch 34: val_acc did not improve from 0.44417\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.2740 - acc: 0.5323 - val_loss: 1.7983 - val_acc: 0.4367 - lr: 1.0000e-04\n",
      "Epoch 35/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2505 - acc: 0.5505\n",
      "Epoch 35: val_acc did not improve from 0.44417\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.2505 - acc: 0.5505 - val_loss: 1.8097 - val_acc: 0.4372 - lr: 1.0000e-04\n",
      "Epoch 36/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2287 - acc: 0.5482\n",
      "Epoch 36: val_acc did not improve from 0.44417\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.2287 - acc: 0.5482 - val_loss: 1.8125 - val_acc: 0.4397 - lr: 1.0000e-04\n",
      "Epoch 37/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2072 - acc: 0.5613\n",
      "Epoch 37: val_acc improved from 0.44417 to 0.44516, saving model to chkp/VG_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.2072 - acc: 0.5613 - val_loss: 1.8212 - val_acc: 0.4452 - lr: 1.0000e-04\n",
      "Epoch 38/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2026 - acc: 0.5668\n",
      "Epoch 38: val_acc did not improve from 0.44516\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.2026 - acc: 0.5668 - val_loss: 1.8247 - val_acc: 0.4452 - lr: 1.0000e-04\n",
      "Epoch 39/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1864 - acc: 0.5656\n",
      "Epoch 39: val_acc did not improve from 0.44516\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.1864 - acc: 0.5656 - val_loss: 1.8495 - val_acc: 0.4417 - lr: 1.0000e-04\n",
      "Epoch 40/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1743 - acc: 0.5739\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 40: val_acc did not improve from 0.44516\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.1743 - acc: 0.5739 - val_loss: 1.8524 - val_acc: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 41/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1516 - acc: 0.5885\n",
      "Epoch 41: val_acc did not improve from 0.44516\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.1516 - acc: 0.5885 - val_loss: 1.8497 - val_acc: 0.4367 - lr: 1.0000e-05\n",
      "Epoch 42/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1487 - acc: 0.5812\n",
      "Epoch 42: val_acc did not improve from 0.44516\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.1487 - acc: 0.5812 - val_loss: 1.8567 - val_acc: 0.4342 - lr: 1.0000e-05\n",
      "Epoch 43/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1465 - acc: 0.5848\n",
      "Epoch 43: val_acc did not improve from 0.44516\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.1465 - acc: 0.5848 - val_loss: 1.8481 - val_acc: 0.4347 - lr: 1.0000e-05\n",
      "Epoch 44/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1455 - acc: 0.5848\n",
      "Epoch 44: val_acc did not improve from 0.44516\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.1455 - acc: 0.5848 - val_loss: 1.8589 - val_acc: 0.4357 - lr: 1.0000e-05\n",
      "Epoch 45/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1476 - acc: 0.5809\n",
      "Epoch 45: val_acc did not improve from 0.44516\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.1476 - acc: 0.5809 - val_loss: 1.8622 - val_acc: 0.4317 - lr: 1.0000e-05\n",
      "Epoch 46/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1485 - acc: 0.5820\n",
      "Epoch 46: val_acc did not improve from 0.44516\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.1485 - acc: 0.5820 - val_loss: 1.8602 - val_acc: 0.4367 - lr: 1.0000e-05\n",
      "Epoch 47/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1402 - acc: 0.5864\n",
      "Epoch 47: val_acc did not improve from 0.44516\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.1402 - acc: 0.5864 - val_loss: 1.8638 - val_acc: 0.4397 - lr: 1.0000e-05\n",
      "Epoch 48/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1406 - acc: 0.5823\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 48: val_acc did not improve from 0.44516\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.1406 - acc: 0.5823 - val_loss: 1.8638 - val_acc: 0.4377 - lr: 1.0000e-05\n",
      "Epoch 49/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1395 - acc: 0.5851\n",
      "Epoch 49: val_acc did not improve from 0.44516\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.1395 - acc: 0.5851 - val_loss: 1.8637 - val_acc: 0.4382 - lr: 1.0000e-06\n",
      "Epoch 50/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1315 - acc: 0.5889\n",
      "Epoch 50: val_acc did not improve from 0.44516\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.1315 - acc: 0.5889 - val_loss: 1.8632 - val_acc: 0.4387 - lr: 1.0000e-06\n",
      "Epoch 51/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1337 - acc: 0.5964\n",
      "Epoch 51: val_acc did not improve from 0.44516\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.1337 - acc: 0.5964 - val_loss: 1.8617 - val_acc: 0.4367 - lr: 1.0000e-06\n",
      "Epoch 52/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1418 - acc: 0.5843\n",
      "Epoch 52: val_acc did not improve from 0.44516\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.1418 - acc: 0.5843 - val_loss: 1.8688 - val_acc: 0.4402 - lr: 1.0000e-06\n",
      "Epoch 52: early stopping\n",
      "\n",
      "Running model with seed 123\n",
      "Train Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 2729, NLoS samples count: 109\n",
      "scenario33 - LoS samples count: 3322, NLoS samples count: 119\n",
      "scenario34 - LoS samples count: 3652, NLoS samples count: 97\n",
      "\n",
      "Test Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 265, NLoS samples count: 12\n",
      "scenario33 - LoS samples count: 379, NLoS samples count: 17\n",
      "scenario34 - LoS samples count: 430, NLoS samples count: 12\n",
      "LoS Train Shape: (9703, 5, 150, 150, 2), LoS Test Shape: (1074, 5, 150, 150, 2)\n",
      "NLoS Train Shape: (325, 5, 150, 150, 2), NLoS Test Shape: (41, 5, 150, 150, 2)\n",
      "Train Labels Shape: (10028, 64)\n",
      "Test Labels Shape: (1115, 64)\n",
      "Train LoS Labels Shape: (9703, 64)\n",
      "Train NLoS Labels Shape: (325, 64)\n",
      "Test LoS Labels Shape: (1074, 64)\n",
      "Test NLoS Labels Shape: (41, 64)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_1 (TimeDis  (None, 5, 256)           341004    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 64)                61824     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 411,148\n",
      "Trainable params: 410,540\n",
      "Non-trainable params: 608\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.8238 - acc: 0.0944\n",
      "Epoch 1: val_acc improved from -inf to 0.13210, saving model to chkp/VG_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 82s 298ms/step - loss: 3.8238 - acc: 0.0944 - val_loss: 3.5495 - val_acc: 0.1321 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.4337 - acc: 0.1334\n",
      "Epoch 2: val_acc improved from 0.13210 to 0.16999, saving model to chkp/VG_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 3.4337 - acc: 0.1334 - val_loss: 3.1655 - val_acc: 0.1700 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.1037 - acc: 0.1756\n",
      "Epoch 3: val_acc improved from 0.16999 to 0.20788, saving model to chkp/VG_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 3.1037 - acc: 0.1756 - val_loss: 2.8607 - val_acc: 0.2079 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.8268 - acc: 0.2104\n",
      "Epoch 4: val_acc improved from 0.20788 to 0.24327, saving model to chkp/VG_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 78s 289ms/step - loss: 2.8268 - acc: 0.2104 - val_loss: 2.6332 - val_acc: 0.2433 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.5978 - acc: 0.2467\n",
      "Epoch 5: val_acc improved from 0.24327 to 0.25274, saving model to chkp/VG_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 2.5978 - acc: 0.2467 - val_loss: 2.4993 - val_acc: 0.2527 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.4086 - acc: 0.2755\n",
      "Epoch 6: val_acc improved from 0.25274 to 0.29412, saving model to chkp/VG_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 2.4086 - acc: 0.2755 - val_loss: 2.2782 - val_acc: 0.2941 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.2597 - acc: 0.3106\n",
      "Epoch 7: val_acc improved from 0.29412 to 0.31206, saving model to chkp/VG_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 2.2597 - acc: 0.3106 - val_loss: 2.1680 - val_acc: 0.3121 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.1594 - acc: 0.3250\n",
      "Epoch 8: val_acc improved from 0.31206 to 0.34347, saving model to chkp/VG_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 2.1594 - acc: 0.3250 - val_loss: 2.0459 - val_acc: 0.3435 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.0467 - acc: 0.3467\n",
      "Epoch 9: val_acc improved from 0.34347 to 0.36092, saving model to chkp/VG_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 2.0467 - acc: 0.3467 - val_loss: 1.9797 - val_acc: 0.3609 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.9751 - acc: 0.3626\n",
      "Epoch 10: val_acc improved from 0.36092 to 0.36889, saving model to chkp/VG_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.9751 - acc: 0.3626 - val_loss: 1.9850 - val_acc: 0.3689 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.9059 - acc: 0.3798\n",
      "Epoch 11: val_acc improved from 0.36889 to 0.38335, saving model to chkp/VG_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.9059 - acc: 0.3798 - val_loss: 1.9198 - val_acc: 0.3833 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8647 - acc: 0.3881\n",
      "Epoch 12: val_acc improved from 0.38335 to 0.39133, saving model to chkp/VG_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.8647 - acc: 0.3881 - val_loss: 1.8960 - val_acc: 0.3913 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8003 - acc: 0.4040\n",
      "Epoch 13: val_acc did not improve from 0.39133\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.8003 - acc: 0.4040 - val_loss: 1.8780 - val_acc: 0.3888 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7565 - acc: 0.4142\n",
      "Epoch 14: val_acc improved from 0.39133 to 0.40329, saving model to chkp/VG_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.7565 - acc: 0.4142 - val_loss: 1.8512 - val_acc: 0.4033 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7158 - acc: 0.4211\n",
      "Epoch 15: val_acc improved from 0.40329 to 0.41226, saving model to chkp/VG_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.7158 - acc: 0.4211 - val_loss: 1.8270 - val_acc: 0.4123 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6860 - acc: 0.4337\n",
      "Epoch 16: val_acc did not improve from 0.41226\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.6860 - acc: 0.4337 - val_loss: 1.8649 - val_acc: 0.3973 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6756 - acc: 0.4317\n",
      "Epoch 17: val_acc did not improve from 0.41226\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.6756 - acc: 0.4317 - val_loss: 1.8607 - val_acc: 0.3918 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6298 - acc: 0.4429\n",
      "Epoch 18: val_acc did not improve from 0.41226\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.6298 - acc: 0.4429 - val_loss: 1.8456 - val_acc: 0.4103 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5938 - acc: 0.4555\n",
      "Epoch 19: val_acc improved from 0.41226 to 0.41725, saving model to chkp/VG_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.5938 - acc: 0.4555 - val_loss: 1.7892 - val_acc: 0.4172 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5768 - acc: 0.4611\n",
      "Epoch 20: val_acc improved from 0.41725 to 0.42074, saving model to chkp/VG_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 77s 286ms/step - loss: 1.5768 - acc: 0.4611 - val_loss: 1.7925 - val_acc: 0.4207 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5555 - acc: 0.4646\n",
      "Epoch 21: val_acc improved from 0.42074 to 0.43968, saving model to chkp/VG_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.5555 - acc: 0.4646 - val_loss: 1.7912 - val_acc: 0.4397 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5228 - acc: 0.4642\n",
      "Epoch 22: val_acc did not improve from 0.43968\n",
      "268/268 [==============================] - 77s 286ms/step - loss: 1.5228 - acc: 0.4642 - val_loss: 1.7827 - val_acc: 0.4327 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5071 - acc: 0.4635\n",
      "Epoch 23: val_acc did not improve from 0.43968\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.5071 - acc: 0.4635 - val_loss: 1.9105 - val_acc: 0.4103 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4883 - acc: 0.4720\n",
      "Epoch 24: val_acc did not improve from 0.43968\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.4883 - acc: 0.4720 - val_loss: 1.8037 - val_acc: 0.4357 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4629 - acc: 0.4825\n",
      "Epoch 25: val_acc did not improve from 0.43968\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.4629 - acc: 0.4825 - val_loss: 1.8714 - val_acc: 0.4172 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4341 - acc: 0.4872\n",
      "Epoch 26: val_acc did not improve from 0.43968\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.4341 - acc: 0.4872 - val_loss: 1.8383 - val_acc: 0.4232 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4549 - acc: 0.4865\n",
      "Epoch 27: val_acc did not improve from 0.43968\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.4549 - acc: 0.4865 - val_loss: 1.8272 - val_acc: 0.4242 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4081 - acc: 0.4984\n",
      "Epoch 28: val_acc did not improve from 0.43968\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.4081 - acc: 0.4984 - val_loss: 1.8897 - val_acc: 0.4187 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3930 - acc: 0.4995\n",
      "Epoch 29: val_acc did not improve from 0.43968\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.3930 - acc: 0.4995 - val_loss: 1.8563 - val_acc: 0.4163 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3800 - acc: 0.5039\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 30: val_acc did not improve from 0.43968\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.3800 - acc: 0.5039 - val_loss: 1.9662 - val_acc: 0.3968 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2663 - acc: 0.5466\n",
      "Epoch 31: val_acc improved from 0.43968 to 0.44317, saving model to chkp/VG_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.2663 - acc: 0.5466 - val_loss: 1.8281 - val_acc: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 32/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2148 - acc: 0.5606\n",
      "Epoch 32: val_acc improved from 0.44317 to 0.44616, saving model to chkp/VG_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 77s 286ms/step - loss: 1.2148 - acc: 0.5606 - val_loss: 1.8336 - val_acc: 0.4462 - lr: 1.0000e-04\n",
      "Epoch 33/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1814 - acc: 0.5724\n",
      "Epoch 33: val_acc improved from 0.44616 to 0.44816, saving model to chkp/VG_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.1814 - acc: 0.5724 - val_loss: 1.8405 - val_acc: 0.4482 - lr: 1.0000e-04\n",
      "Epoch 34/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1653 - acc: 0.5714\n",
      "Epoch 34: val_acc did not improve from 0.44816\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.1653 - acc: 0.5714 - val_loss: 1.8573 - val_acc: 0.4382 - lr: 1.0000e-04\n",
      "Epoch 35/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1478 - acc: 0.5850\n",
      "Epoch 35: val_acc did not improve from 0.44816\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.1478 - acc: 0.5850 - val_loss: 1.8698 - val_acc: 0.4397 - lr: 1.0000e-04\n",
      "Epoch 36/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1300 - acc: 0.5915\n",
      "Epoch 36: val_acc did not improve from 0.44816\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.1300 - acc: 0.5915 - val_loss: 1.8753 - val_acc: 0.4427 - lr: 1.0000e-04\n",
      "Epoch 37/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1196 - acc: 0.5909\n",
      "Epoch 37: val_acc did not improve from 0.44816\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.1196 - acc: 0.5909 - val_loss: 1.8984 - val_acc: 0.4397 - lr: 1.0000e-04\n",
      "Epoch 38/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1099 - acc: 0.5960\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 38: val_acc did not improve from 0.44816\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.1099 - acc: 0.5960 - val_loss: 1.9101 - val_acc: 0.4417 - lr: 1.0000e-04\n",
      "Epoch 39/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0731 - acc: 0.6136\n",
      "Epoch 39: val_acc did not improve from 0.44816\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.0731 - acc: 0.6136 - val_loss: 1.9140 - val_acc: 0.4402 - lr: 1.0000e-05\n",
      "Epoch 40/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0763 - acc: 0.6148\n",
      "Epoch 40: val_acc did not improve from 0.44816\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.0763 - acc: 0.6148 - val_loss: 1.9137 - val_acc: 0.4412 - lr: 1.0000e-05\n",
      "Epoch 41/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0791 - acc: 0.6082\n",
      "Epoch 41: val_acc did not improve from 0.44816\n",
      "268/268 [==============================] - 77s 286ms/step - loss: 1.0791 - acc: 0.6082 - val_loss: 1.9139 - val_acc: 0.4387 - lr: 1.0000e-05\n",
      "Epoch 42/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0770 - acc: 0.6109\n",
      "Epoch 42: val_acc did not improve from 0.44816\n",
      "268/268 [==============================] - 77s 286ms/step - loss: 1.0770 - acc: 0.6109 - val_loss: 1.9096 - val_acc: 0.4377 - lr: 1.0000e-05\n",
      "Epoch 42: early stopping\n",
      "\n",
      "Running model with seed 456\n",
      "Train Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 2711, NLoS samples count: 107\n",
      "scenario33 - LoS samples count: 3317, NLoS samples count: 121\n",
      "scenario34 - LoS samples count: 3676, NLoS samples count: 96\n",
      "\n",
      "Test Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 283, NLoS samples count: 14\n",
      "scenario33 - LoS samples count: 384, NLoS samples count: 15\n",
      "scenario34 - LoS samples count: 406, NLoS samples count: 13\n",
      "LoS Train Shape: (9704, 5, 150, 150, 2), LoS Test Shape: (1073, 5, 150, 150, 2)\n",
      "NLoS Train Shape: (324, 5, 150, 150, 2), NLoS Test Shape: (42, 5, 150, 150, 2)\n",
      "Train Labels Shape: (10028, 64)\n",
      "Test Labels Shape: (1115, 64)\n",
      "Train LoS Labels Shape: (9704, 64)\n",
      "Train NLoS Labels Shape: (324, 64)\n",
      "Test LoS Labels Shape: (1073, 64)\n",
      "Test NLoS Labels Shape: (42, 64)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_2 (TimeDis  (None, 5, 256)           341004    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 64)                61824     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 411,148\n",
      "Trainable params: 410,540\n",
      "Non-trainable params: 608\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.7431 - acc: 0.0996\n",
      "Epoch 1: val_acc improved from -inf to 0.13460, saving model to chkp/VG_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 83s 299ms/step - loss: 3.7431 - acc: 0.0996 - val_loss: 3.3695 - val_acc: 0.1346 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.3990 - acc: 0.1313\n",
      "Epoch 2: val_acc improved from 0.13460 to 0.16700, saving model to chkp/VG_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 3.3990 - acc: 0.1313 - val_loss: 3.1850 - val_acc: 0.1670 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.1439 - acc: 0.1663\n",
      "Epoch 3: val_acc improved from 0.16700 to 0.20788, saving model to chkp/VG_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 3.1439 - acc: 0.1663 - val_loss: 2.8382 - val_acc: 0.2079 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.8527 - acc: 0.2102\n",
      "Epoch 4: val_acc improved from 0.20788 to 0.26670, saving model to chkp/VG_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 2.8527 - acc: 0.2102 - val_loss: 2.5426 - val_acc: 0.2667 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.6334 - acc: 0.2479\n",
      "Epoch 5: val_acc improved from 0.26670 to 0.29362, saving model to chkp/VG_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 2.6334 - acc: 0.2479 - val_loss: 2.3399 - val_acc: 0.2936 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.4428 - acc: 0.2779\n",
      "Epoch 6: val_acc improved from 0.29362 to 0.29711, saving model to chkp/VG_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 2.4428 - acc: 0.2779 - val_loss: 2.2480 - val_acc: 0.2971 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.3000 - acc: 0.3040\n",
      "Epoch 7: val_acc improved from 0.29711 to 0.32702, saving model to chkp/VG_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 2.3000 - acc: 0.3040 - val_loss: 2.1187 - val_acc: 0.3270 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.1813 - acc: 0.3280\n",
      "Epoch 8: val_acc improved from 0.32702 to 0.34148, saving model to chkp/VG_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 2.1813 - acc: 0.3280 - val_loss: 1.9810 - val_acc: 0.3415 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.0814 - acc: 0.3448\n",
      "Epoch 9: val_acc improved from 0.34148 to 0.36042, saving model to chkp/VG_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 2.0814 - acc: 0.3448 - val_loss: 1.9309 - val_acc: 0.3604 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.0087 - acc: 0.3553\n",
      "Epoch 10: val_acc improved from 0.36042 to 0.36640, saving model to chkp/VG_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 2.0087 - acc: 0.3553 - val_loss: 1.9297 - val_acc: 0.3664 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.9623 - acc: 0.3711\n",
      "Epoch 11: val_acc improved from 0.36640 to 0.36989, saving model to chkp/VG_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.9623 - acc: 0.3711 - val_loss: 1.9040 - val_acc: 0.3699 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8741 - acc: 0.3910\n",
      "Epoch 12: val_acc improved from 0.36989 to 0.39133, saving model to chkp/VG_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.8741 - acc: 0.3910 - val_loss: 1.8066 - val_acc: 0.3913 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8190 - acc: 0.4025\n",
      "Epoch 13: val_acc did not improve from 0.39133\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.8190 - acc: 0.4025 - val_loss: 1.9626 - val_acc: 0.3684 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7882 - acc: 0.4071\n",
      "Epoch 14: val_acc improved from 0.39133 to 0.40329, saving model to chkp/VG_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.7882 - acc: 0.4071 - val_loss: 1.7274 - val_acc: 0.4033 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7403 - acc: 0.4160\n",
      "Epoch 15: val_acc improved from 0.40329 to 0.42423, saving model to chkp/VG_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.7403 - acc: 0.4160 - val_loss: 1.6787 - val_acc: 0.4242 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7079 - acc: 0.4262\n",
      "Epoch 16: val_acc did not improve from 0.42423\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.7079 - acc: 0.4262 - val_loss: 1.7027 - val_acc: 0.4123 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6645 - acc: 0.4329\n",
      "Epoch 17: val_acc did not improve from 0.42423\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.6645 - acc: 0.4329 - val_loss: 1.6647 - val_acc: 0.4158 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6289 - acc: 0.4440\n",
      "Epoch 18: val_acc improved from 0.42423 to 0.42971, saving model to chkp/VG_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.6289 - acc: 0.4440 - val_loss: 1.7120 - val_acc: 0.4297 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6162 - acc: 0.4470\n",
      "Epoch 19: val_acc did not improve from 0.42971\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.6162 - acc: 0.4470 - val_loss: 1.6809 - val_acc: 0.4118 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5782 - acc: 0.4585\n",
      "Epoch 20: val_acc improved from 0.42971 to 0.43569, saving model to chkp/VG_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.5782 - acc: 0.4585 - val_loss: 1.6511 - val_acc: 0.4357 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5620 - acc: 0.4658\n",
      "Epoch 21: val_acc did not improve from 0.43569\n",
      "268/268 [==============================] - 77s 286ms/step - loss: 1.5620 - acc: 0.4658 - val_loss: 1.7208 - val_acc: 0.4287 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5292 - acc: 0.4685\n",
      "Epoch 22: val_acc improved from 0.43569 to 0.43868, saving model to chkp/VG_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.5292 - acc: 0.4685 - val_loss: 1.6692 - val_acc: 0.4387 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5007 - acc: 0.4762\n",
      "Epoch 23: val_acc did not improve from 0.43868\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.5007 - acc: 0.4762 - val_loss: 1.6833 - val_acc: 0.4322 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4644 - acc: 0.4893\n",
      "Epoch 24: val_acc did not improve from 0.43868\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.4644 - acc: 0.4893 - val_loss: 1.6968 - val_acc: 0.4227 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4560 - acc: 0.4888\n",
      "Epoch 25: val_acc did not improve from 0.43868\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.4560 - acc: 0.4888 - val_loss: 1.6628 - val_acc: 0.4317 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4359 - acc: 0.4890\n",
      "Epoch 26: val_acc did not improve from 0.43868\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.4359 - acc: 0.4890 - val_loss: 1.8344 - val_acc: 0.4003 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4118 - acc: 0.4931\n",
      "Epoch 27: val_acc did not improve from 0.43868\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.4118 - acc: 0.4931 - val_loss: 1.6829 - val_acc: 0.4217 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4266 - acc: 0.4990\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 28: val_acc did not improve from 0.43868\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.4266 - acc: 0.4990 - val_loss: 1.6815 - val_acc: 0.4297 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3205 - acc: 0.5226\n",
      "Epoch 29: val_acc improved from 0.43868 to 0.44417, saving model to chkp/VG_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.3205 - acc: 0.5226 - val_loss: 1.6394 - val_acc: 0.4442 - lr: 1.0000e-04\n",
      "Epoch 30/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2542 - acc: 0.5462\n",
      "Epoch 30: val_acc improved from 0.44417 to 0.44915, saving model to chkp/VG_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.2542 - acc: 0.5462 - val_loss: 1.6331 - val_acc: 0.4492 - lr: 1.0000e-04\n",
      "Epoch 31/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2129 - acc: 0.5658\n",
      "Epoch 31: val_acc did not improve from 0.44915\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.2129 - acc: 0.5658 - val_loss: 1.6437 - val_acc: 0.4482 - lr: 1.0000e-04\n",
      "Epoch 32/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1754 - acc: 0.5768\n",
      "Epoch 32: val_acc did not improve from 0.44915\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.1754 - acc: 0.5768 - val_loss: 1.6544 - val_acc: 0.4477 - lr: 1.0000e-04\n",
      "Epoch 33/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1643 - acc: 0.5757\n",
      "Epoch 33: val_acc improved from 0.44915 to 0.45015, saving model to chkp/VG_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.1643 - acc: 0.5757 - val_loss: 1.6658 - val_acc: 0.4501 - lr: 1.0000e-04\n",
      "Epoch 34/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1460 - acc: 0.5829\n",
      "Epoch 34: val_acc improved from 0.45015 to 0.45214, saving model to chkp/VG_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.1460 - acc: 0.5829 - val_loss: 1.6818 - val_acc: 0.4521 - lr: 1.0000e-04\n",
      "Epoch 35/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1313 - acc: 0.5910\n",
      "Epoch 35: val_acc did not improve from 0.45214\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.1313 - acc: 0.5910 - val_loss: 1.6783 - val_acc: 0.4477 - lr: 1.0000e-04\n",
      "Epoch 36/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1144 - acc: 0.5970\n",
      "Epoch 36: val_acc did not improve from 0.45214\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.1144 - acc: 0.5970 - val_loss: 1.6853 - val_acc: 0.4487 - lr: 1.0000e-04\n",
      "Epoch 37/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0955 - acc: 0.6090\n",
      "Epoch 37: val_acc did not improve from 0.45214\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.0955 - acc: 0.6090 - val_loss: 1.6987 - val_acc: 0.4497 - lr: 1.0000e-04\n",
      "Epoch 38/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0916 - acc: 0.6109\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 38: val_acc did not improve from 0.45214\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.0916 - acc: 0.6109 - val_loss: 1.7191 - val_acc: 0.4457 - lr: 1.0000e-04\n",
      "Epoch 39/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0714 - acc: 0.6161\n",
      "Epoch 39: val_acc did not improve from 0.45214\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.0714 - acc: 0.6161 - val_loss: 1.7137 - val_acc: 0.4452 - lr: 1.0000e-05\n",
      "Epoch 40/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0613 - acc: 0.6101\n",
      "Epoch 40: val_acc did not improve from 0.45214\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.0613 - acc: 0.6101 - val_loss: 1.7137 - val_acc: 0.4437 - lr: 1.0000e-05\n",
      "Epoch 41/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0607 - acc: 0.6148\n",
      "Epoch 41: val_acc did not improve from 0.45214\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.0607 - acc: 0.6148 - val_loss: 1.7114 - val_acc: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 42/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0543 - acc: 0.6177\n",
      "Epoch 42: val_acc did not improve from 0.45214\n",
      "268/268 [==============================] - 77s 286ms/step - loss: 1.0543 - acc: 0.6177 - val_loss: 1.7144 - val_acc: 0.4422 - lr: 1.0000e-05\n",
      "Epoch 43/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0501 - acc: 0.6214\n",
      "Epoch 43: val_acc did not improve from 0.45214\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.0501 - acc: 0.6214 - val_loss: 1.7106 - val_acc: 0.4447 - lr: 1.0000e-05\n",
      "Epoch 44/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0487 - acc: 0.6208\n",
      "Epoch 44: val_acc did not improve from 0.45214\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.0487 - acc: 0.6208 - val_loss: 1.7121 - val_acc: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 45/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0472 - acc: 0.6233\n",
      "Epoch 45: val_acc did not improve from 0.45214\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.0472 - acc: 0.6233 - val_loss: 1.7241 - val_acc: 0.4452 - lr: 1.0000e-05\n",
      "Epoch 46/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0500 - acc: 0.6161\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 46: val_acc did not improve from 0.45214\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.0500 - acc: 0.6161 - val_loss: 1.7170 - val_acc: 0.4487 - lr: 1.0000e-05\n",
      "Epoch 47/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0490 - acc: 0.6263\n",
      "Epoch 47: val_acc did not improve from 0.45214\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.0490 - acc: 0.6263 - val_loss: 1.7234 - val_acc: 0.4472 - lr: 1.0000e-06\n",
      "Epoch 48/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0326 - acc: 0.6290\n",
      "Epoch 48: val_acc did not improve from 0.45214\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.0326 - acc: 0.6290 - val_loss: 1.7209 - val_acc: 0.4447 - lr: 1.0000e-06\n",
      "Epoch 49/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0468 - acc: 0.6209\n",
      "Epoch 49: val_acc did not improve from 0.45214\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.0468 - acc: 0.6209 - val_loss: 1.7178 - val_acc: 0.4467 - lr: 1.0000e-06\n",
      "Epoch 50/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0392 - acc: 0.6247\n",
      "Epoch 50: val_acc did not improve from 0.45214\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.0392 - acc: 0.6247 - val_loss: 1.7224 - val_acc: 0.4467 - lr: 1.0000e-06\n",
      "Epoch 50: early stopping\n",
      "\n",
      "Running model with seed 789\n",
      "Train Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 2706, NLoS samples count: 105\n",
      "scenario33 - LoS samples count: 3343, NLoS samples count: 126\n",
      "scenario34 - LoS samples count: 3652, NLoS samples count: 96\n",
      "\n",
      "Test Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 288, NLoS samples count: 16\n",
      "scenario33 - LoS samples count: 358, NLoS samples count: 10\n",
      "scenario34 - LoS samples count: 430, NLoS samples count: 13\n",
      "LoS Train Shape: (9701, 5, 150, 150, 2), LoS Test Shape: (1076, 5, 150, 150, 2)\n",
      "NLoS Train Shape: (327, 5, 150, 150, 2), NLoS Test Shape: (39, 5, 150, 150, 2)\n",
      "Train Labels Shape: (10028, 64)\n",
      "Test Labels Shape: (1115, 64)\n",
      "Train LoS Labels Shape: (9701, 64)\n",
      "Train NLoS Labels Shape: (327, 64)\n",
      "Test LoS Labels Shape: (1076, 64)\n",
      "Test NLoS Labels Shape: (39, 64)\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_3 (TimeDis  (None, 5, 256)           341004    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 64)                61824     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 411,148\n",
      "Trainable params: 410,540\n",
      "Non-trainable params: 608\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.8060 - acc: 0.0975\n",
      "Epoch 1: val_acc improved from -inf to 0.13410, saving model to chkp/VG_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 82s 296ms/step - loss: 3.8060 - acc: 0.0975 - val_loss: 3.5359 - val_acc: 0.1341 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.4625 - acc: 0.1301\n",
      "Epoch 2: val_acc improved from 0.13410 to 0.15005, saving model to chkp/VG_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 78s 290ms/step - loss: 3.4625 - acc: 0.1301 - val_loss: 3.2052 - val_acc: 0.1500 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.1842 - acc: 0.1535\n",
      "Epoch 3: val_acc improved from 0.15005 to 0.17448, saving model to chkp/VG_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 3.1842 - acc: 0.1535 - val_loss: 2.9497 - val_acc: 0.1745 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.9264 - acc: 0.1926\n",
      "Epoch 4: val_acc improved from 0.17448 to 0.23180, saving model to chkp/VG_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 2.9264 - acc: 0.1926 - val_loss: 2.6721 - val_acc: 0.2318 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.6675 - acc: 0.2325\n",
      "Epoch 5: val_acc improved from 0.23180 to 0.24776, saving model to chkp/VG_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 2.6675 - acc: 0.2325 - val_loss: 2.4702 - val_acc: 0.2478 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.4714 - acc: 0.2730\n",
      "Epoch 6: val_acc improved from 0.24776 to 0.29811, saving model to chkp/VG_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 2.4714 - acc: 0.2730 - val_loss: 2.2925 - val_acc: 0.2981 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.3094 - acc: 0.3008\n",
      "Epoch 7: val_acc improved from 0.29811 to 0.32951, saving model to chkp/VG_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 2.3094 - acc: 0.3008 - val_loss: 2.1312 - val_acc: 0.3295 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.1867 - acc: 0.3267\n",
      "Epoch 8: val_acc improved from 0.32951 to 0.35394, saving model to chkp/VG_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 2.1867 - acc: 0.3267 - val_loss: 2.1063 - val_acc: 0.3539 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.0665 - acc: 0.3530\n",
      "Epoch 9: val_acc improved from 0.35394 to 0.37139, saving model to chkp/VG_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 78s 289ms/step - loss: 2.0665 - acc: 0.3530 - val_loss: 1.9510 - val_acc: 0.3714 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.0162 - acc: 0.3581\n",
      "Epoch 10: val_acc improved from 0.37139 to 0.37936, saving model to chkp/VG_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 2.0162 - acc: 0.3581 - val_loss: 1.8795 - val_acc: 0.3794 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.9546 - acc: 0.3752\n",
      "Epoch 11: val_acc improved from 0.37936 to 0.38534, saving model to chkp/VG_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.9546 - acc: 0.3752 - val_loss: 1.8762 - val_acc: 0.3853 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8665 - acc: 0.3943\n",
      "Epoch 12: val_acc improved from 0.38534 to 0.39980, saving model to chkp/VG_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 78s 290ms/step - loss: 1.8665 - acc: 0.3943 - val_loss: 1.8489 - val_acc: 0.3998 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8312 - acc: 0.3939\n",
      "Epoch 13: val_acc did not improve from 0.39980\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.8312 - acc: 0.3939 - val_loss: 1.8018 - val_acc: 0.3948 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7797 - acc: 0.4076\n",
      "Epoch 14: val_acc improved from 0.39980 to 0.42223, saving model to chkp/VG_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.7797 - acc: 0.4076 - val_loss: 1.7566 - val_acc: 0.4222 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7323 - acc: 0.4171\n",
      "Epoch 15: val_acc did not improve from 0.42223\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.7323 - acc: 0.4171 - val_loss: 1.8624 - val_acc: 0.3809 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7115 - acc: 0.4346\n",
      "Epoch 16: val_acc did not improve from 0.42223\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.7115 - acc: 0.4346 - val_loss: 1.7580 - val_acc: 0.4138 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6801 - acc: 0.4384\n",
      "Epoch 17: val_acc improved from 0.42223 to 0.44018, saving model to chkp/VG_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 78s 290ms/step - loss: 1.6801 - acc: 0.4384 - val_loss: 1.7008 - val_acc: 0.4402 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6232 - acc: 0.4555\n",
      "Epoch 18: val_acc did not improve from 0.44018\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.6232 - acc: 0.4555 - val_loss: 1.9055 - val_acc: 0.3873 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6100 - acc: 0.4538\n",
      "Epoch 19: val_acc did not improve from 0.44018\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.6100 - acc: 0.4538 - val_loss: 1.7195 - val_acc: 0.4302 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5659 - acc: 0.4610\n",
      "Epoch 20: val_acc did not improve from 0.44018\n",
      "268/268 [==============================] - 78s 289ms/step - loss: 1.5659 - acc: 0.4610 - val_loss: 1.7250 - val_acc: 0.4172 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5655 - acc: 0.4616\n",
      "Epoch 21: val_acc did not improve from 0.44018\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.5655 - acc: 0.4616 - val_loss: 1.7216 - val_acc: 0.4262 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5541 - acc: 0.4619\n",
      "Epoch 22: val_acc did not improve from 0.44018\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.5541 - acc: 0.4619 - val_loss: 1.7265 - val_acc: 0.4113 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5099 - acc: 0.4729\n",
      "Epoch 23: val_acc did not improve from 0.44018\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.5099 - acc: 0.4729 - val_loss: 1.7013 - val_acc: 0.4382 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4875 - acc: 0.4762\n",
      "Epoch 24: val_acc did not improve from 0.44018\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.4875 - acc: 0.4762 - val_loss: 1.7010 - val_acc: 0.4277 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4779 - acc: 0.4769\n",
      "Epoch 25: val_acc did not improve from 0.44018\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.4779 - acc: 0.4769 - val_loss: 1.6972 - val_acc: 0.4337 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4485 - acc: 0.4880\n",
      "Epoch 26: val_acc did not improve from 0.44018\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.4485 - acc: 0.4880 - val_loss: 1.7582 - val_acc: 0.4187 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4430 - acc: 0.4862\n",
      "Epoch 27: val_acc improved from 0.44018 to 0.45165, saving model to chkp/VG_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 78s 290ms/step - loss: 1.4430 - acc: 0.4862 - val_loss: 1.7166 - val_acc: 0.4516 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4296 - acc: 0.4968\n",
      "Epoch 28: val_acc did not improve from 0.45165\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.4296 - acc: 0.4968 - val_loss: 1.7035 - val_acc: 0.4327 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4206 - acc: 0.5012\n",
      "Epoch 29: val_acc did not improve from 0.45165\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.4206 - acc: 0.5012 - val_loss: 1.7423 - val_acc: 0.4402 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3912 - acc: 0.5015\n",
      "Epoch 30: val_acc did not improve from 0.45165\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.3912 - acc: 0.5015 - val_loss: 1.7427 - val_acc: 0.4297 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3594 - acc: 0.5128\n",
      "Epoch 31: val_acc did not improve from 0.45165\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.3594 - acc: 0.5128 - val_loss: 1.7456 - val_acc: 0.4307 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3617 - acc: 0.5102\n",
      "Epoch 32: val_acc did not improve from 0.45165\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.3617 - acc: 0.5102 - val_loss: 1.7967 - val_acc: 0.4172 - lr: 0.0010\n",
      "Epoch 33/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3453 - acc: 0.5170\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 33: val_acc did not improve from 0.45165\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.3453 - acc: 0.5170 - val_loss: 1.7962 - val_acc: 0.4143 - lr: 0.0010\n",
      "Epoch 34/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2342 - acc: 0.5548\n",
      "Epoch 34: val_acc did not improve from 0.45165\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.2342 - acc: 0.5548 - val_loss: 1.7405 - val_acc: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 35/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1733 - acc: 0.5729\n",
      "Epoch 35: val_acc did not improve from 0.45165\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.1733 - acc: 0.5729 - val_loss: 1.7537 - val_acc: 0.4342 - lr: 1.0000e-04\n",
      "Epoch 36/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1401 - acc: 0.5848\n",
      "Epoch 36: val_acc did not improve from 0.45165\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.1401 - acc: 0.5848 - val_loss: 1.7623 - val_acc: 0.4347 - lr: 1.0000e-04\n",
      "Epoch 37/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1200 - acc: 0.5893\n",
      "Epoch 37: val_acc did not improve from 0.45165\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.1200 - acc: 0.5893 - val_loss: 1.7709 - val_acc: 0.4367 - lr: 1.0000e-04\n",
      "Epoch 38/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1045 - acc: 0.5994\n",
      "Epoch 38: val_acc did not improve from 0.45165\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.1045 - acc: 0.5994 - val_loss: 1.7847 - val_acc: 0.4397 - lr: 1.0000e-04\n",
      "Epoch 39/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0834 - acc: 0.6026\n",
      "Epoch 39: val_acc did not improve from 0.45165\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.0834 - acc: 0.6026 - val_loss: 1.7944 - val_acc: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 40/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0728 - acc: 0.6080\n",
      "Epoch 40: val_acc did not improve from 0.45165\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.0728 - acc: 0.6080 - val_loss: 1.8064 - val_acc: 0.4332 - lr: 1.0000e-04\n",
      "Epoch 41/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0540 - acc: 0.6202\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 41: val_acc did not improve from 0.45165\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.0540 - acc: 0.6202 - val_loss: 1.8273 - val_acc: 0.4382 - lr: 1.0000e-04\n",
      "Epoch 42/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0339 - acc: 0.6291\n",
      "Epoch 42: val_acc did not improve from 0.45165\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.0339 - acc: 0.6291 - val_loss: 1.8284 - val_acc: 0.4397 - lr: 1.0000e-05\n",
      "Epoch 43/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0373 - acc: 0.6274\n",
      "Epoch 43: val_acc did not improve from 0.45165\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.0373 - acc: 0.6274 - val_loss: 1.8298 - val_acc: 0.4372 - lr: 1.0000e-05\n",
      "Epoch 44/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0344 - acc: 0.6265\n",
      "Epoch 44: val_acc did not improve from 0.45165\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.0344 - acc: 0.6265 - val_loss: 1.8282 - val_acc: 0.4397 - lr: 1.0000e-05\n",
      "Epoch 45/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0334 - acc: 0.6275\n",
      "Epoch 45: val_acc did not improve from 0.45165\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.0334 - acc: 0.6275 - val_loss: 1.8282 - val_acc: 0.4347 - lr: 1.0000e-05\n",
      "Epoch 45: early stopping\n",
      "\n",
      "Running model with seed 101112\n",
      "Train Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 2692, NLoS samples count: 104\n",
      "scenario33 - LoS samples count: 3330, NLoS samples count: 120\n",
      "scenario34 - LoS samples count: 3684, NLoS samples count: 98\n",
      "\n",
      "Test Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 302, NLoS samples count: 17\n",
      "scenario33 - LoS samples count: 371, NLoS samples count: 16\n",
      "scenario34 - LoS samples count: 398, NLoS samples count: 11\n",
      "LoS Train Shape: (9706, 5, 150, 150, 2), LoS Test Shape: (1071, 5, 150, 150, 2)\n",
      "NLoS Train Shape: (322, 5, 150, 150, 2), NLoS Test Shape: (44, 5, 150, 150, 2)\n",
      "Train Labels Shape: (10028, 64)\n",
      "Test Labels Shape: (1115, 64)\n",
      "Train LoS Labels Shape: (9706, 64)\n",
      "Train NLoS Labels Shape: (322, 64)\n",
      "Test LoS Labels Shape: (1071, 64)\n",
      "Test NLoS Labels Shape: (44, 64)\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_4 (TimeDis  (None, 5, 256)           341004    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 64)                61824     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 411,148\n",
      "Trainable params: 410,540\n",
      "Non-trainable params: 608\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.7870 - acc: 0.1104\n",
      "Epoch 1: val_acc improved from -inf to 0.12662, saving model to chkp/VG_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 83s 300ms/step - loss: 3.7870 - acc: 0.1104 - val_loss: 3.5082 - val_acc: 0.1266 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.3973 - acc: 0.1482\n",
      "Epoch 2: val_acc improved from 0.12662 to 0.16600, saving model to chkp/VG_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 3.3973 - acc: 0.1482 - val_loss: 3.1256 - val_acc: 0.1660 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.0779 - acc: 0.1774\n",
      "Epoch 3: val_acc improved from 0.16600 to 0.21984, saving model to chkp/VG_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 3.0779 - acc: 0.1774 - val_loss: 2.8636 - val_acc: 0.2198 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.8002 - acc: 0.2112\n",
      "Epoch 4: val_acc improved from 0.21984 to 0.25324, saving model to chkp/VG_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 2.8002 - acc: 0.2112 - val_loss: 2.6029 - val_acc: 0.2532 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.5572 - acc: 0.2619\n",
      "Epoch 5: val_acc improved from 0.25324 to 0.27966, saving model to chkp/VG_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 2.5572 - acc: 0.2619 - val_loss: 2.4014 - val_acc: 0.2797 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.3773 - acc: 0.2878\n",
      "Epoch 6: val_acc improved from 0.27966 to 0.29860, saving model to chkp/VG_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 2.3773 - acc: 0.2878 - val_loss: 2.2827 - val_acc: 0.2986 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.2383 - acc: 0.3106\n",
      "Epoch 7: val_acc improved from 0.29860 to 0.31954, saving model to chkp/VG_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 2.2383 - acc: 0.3106 - val_loss: 2.1582 - val_acc: 0.3195 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.1305 - acc: 0.3378\n",
      "Epoch 8: val_acc did not improve from 0.31954\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 2.1305 - acc: 0.3378 - val_loss: 2.2521 - val_acc: 0.3170 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.0277 - acc: 0.3601\n",
      "Epoch 9: val_acc improved from 0.31954 to 0.35793, saving model to chkp/VG_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 2.0277 - acc: 0.3601 - val_loss: 2.0047 - val_acc: 0.3579 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.9621 - acc: 0.3687\n",
      "Epoch 10: val_acc did not improve from 0.35793\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.9621 - acc: 0.3687 - val_loss: 2.0507 - val_acc: 0.3495 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.9031 - acc: 0.3798\n",
      "Epoch 11: val_acc improved from 0.35793 to 0.38485, saving model to chkp/VG_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.9031 - acc: 0.3798 - val_loss: 1.9349 - val_acc: 0.3848 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8525 - acc: 0.3969\n",
      "Epoch 12: val_acc improved from 0.38485 to 0.39681, saving model to chkp/VG_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.8525 - acc: 0.3969 - val_loss: 1.8806 - val_acc: 0.3968 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7795 - acc: 0.4069\n",
      "Epoch 13: val_acc did not improve from 0.39681\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.7795 - acc: 0.4069 - val_loss: 1.8515 - val_acc: 0.3848 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7412 - acc: 0.4212\n",
      "Epoch 14: val_acc did not improve from 0.39681\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.7412 - acc: 0.4212 - val_loss: 1.8888 - val_acc: 0.3848 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7108 - acc: 0.4291\n",
      "Epoch 15: val_acc did not improve from 0.39681\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.7108 - acc: 0.4291 - val_loss: 1.8784 - val_acc: 0.3883 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6704 - acc: 0.4361\n",
      "Epoch 16: val_acc improved from 0.39681 to 0.41326, saving model to chkp/VG_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.6704 - acc: 0.4361 - val_loss: 1.8128 - val_acc: 0.4133 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6535 - acc: 0.4456\n",
      "Epoch 17: val_acc did not improve from 0.41326\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.6535 - acc: 0.4456 - val_loss: 1.8291 - val_acc: 0.4083 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6217 - acc: 0.4498\n",
      "Epoch 18: val_acc did not improve from 0.41326\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.6217 - acc: 0.4498 - val_loss: 1.8593 - val_acc: 0.3993 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5952 - acc: 0.4538\n",
      "Epoch 19: val_acc did not improve from 0.41326\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.5952 - acc: 0.4538 - val_loss: 1.7980 - val_acc: 0.4058 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5648 - acc: 0.4591\n",
      "Epoch 20: val_acc did not improve from 0.41326\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.5648 - acc: 0.4591 - val_loss: 1.8228 - val_acc: 0.4058 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5493 - acc: 0.4545\n",
      "Epoch 21: val_acc did not improve from 0.41326\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.5493 - acc: 0.4545 - val_loss: 1.8380 - val_acc: 0.4028 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5151 - acc: 0.4716\n",
      "Epoch 22: val_acc improved from 0.41326 to 0.41725, saving model to chkp/VG_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.5151 - acc: 0.4716 - val_loss: 1.8097 - val_acc: 0.4172 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4914 - acc: 0.4734\n",
      "Epoch 23: val_acc did not improve from 0.41725\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.4914 - acc: 0.4734 - val_loss: 1.9781 - val_acc: 0.3814 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4663 - acc: 0.4852\n",
      "Epoch 24: val_acc did not improve from 0.41725\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.4663 - acc: 0.4852 - val_loss: 1.8119 - val_acc: 0.4163 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4610 - acc: 0.4884\n",
      "Epoch 25: val_acc did not improve from 0.41725\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.4610 - acc: 0.4884 - val_loss: 1.8544 - val_acc: 0.4068 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4484 - acc: 0.4883\n",
      "Epoch 26: val_acc improved from 0.41725 to 0.42074, saving model to chkp/VG_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.4484 - acc: 0.4883 - val_loss: 1.8442 - val_acc: 0.4207 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4279 - acc: 0.4893\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 27: val_acc did not improve from 0.42074\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.4279 - acc: 0.4893 - val_loss: 1.8493 - val_acc: 0.4192 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3111 - acc: 0.5344\n",
      "Epoch 28: val_acc improved from 0.42074 to 0.44566, saving model to chkp/VG_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.3111 - acc: 0.5344 - val_loss: 1.7810 - val_acc: 0.4457 - lr: 1.0000e-04\n",
      "Epoch 29/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2426 - acc: 0.5550\n",
      "Epoch 29: val_acc did not improve from 0.44566\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.2426 - acc: 0.5550 - val_loss: 1.7874 - val_acc: 0.4442 - lr: 1.0000e-04\n",
      "Epoch 30/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2245 - acc: 0.5586\n",
      "Epoch 30: val_acc improved from 0.44566 to 0.44666, saving model to chkp/VG_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.2245 - acc: 0.5586 - val_loss: 1.7871 - val_acc: 0.4467 - lr: 1.0000e-04\n",
      "Epoch 31/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2045 - acc: 0.5635\n",
      "Epoch 31: val_acc did not improve from 0.44666\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.2045 - acc: 0.5635 - val_loss: 1.7936 - val_acc: 0.4427 - lr: 1.0000e-04\n",
      "Epoch 32/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1878 - acc: 0.5733\n",
      "Epoch 32: val_acc did not improve from 0.44666\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.1878 - acc: 0.5733 - val_loss: 1.7963 - val_acc: 0.4402 - lr: 1.0000e-04\n",
      "Epoch 33/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1691 - acc: 0.5783\n",
      "Epoch 33: val_acc did not improve from 0.44666\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.1691 - acc: 0.5783 - val_loss: 1.8099 - val_acc: 0.4412 - lr: 1.0000e-04\n",
      "Epoch 34/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1476 - acc: 0.5835\n",
      "Epoch 34: val_acc improved from 0.44666 to 0.44766, saving model to chkp/VG_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.1476 - acc: 0.5835 - val_loss: 1.8109 - val_acc: 0.4477 - lr: 1.0000e-04\n",
      "Epoch 35/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1399 - acc: 0.5956\n",
      "Epoch 35: val_acc did not improve from 0.44766\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.1399 - acc: 0.5956 - val_loss: 1.8271 - val_acc: 0.4457 - lr: 1.0000e-04\n",
      "Epoch 36/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1141 - acc: 0.5992\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 36: val_acc did not improve from 0.44766\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.1141 - acc: 0.5992 - val_loss: 1.8271 - val_acc: 0.4457 - lr: 1.0000e-04\n",
      "Epoch 37/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1008 - acc: 0.6109\n",
      "Epoch 37: val_acc improved from 0.44766 to 0.44915, saving model to chkp/VG_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 77s 286ms/step - loss: 1.1008 - acc: 0.6109 - val_loss: 1.8211 - val_acc: 0.4492 - lr: 1.0000e-05\n",
      "Epoch 38/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1006 - acc: 0.6093\n",
      "Epoch 38: val_acc did not improve from 0.44915\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.1006 - acc: 0.6093 - val_loss: 1.8282 - val_acc: 0.4462 - lr: 1.0000e-05\n",
      "Epoch 39/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1041 - acc: 0.6062\n",
      "Epoch 39: val_acc did not improve from 0.44915\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.1041 - acc: 0.6062 - val_loss: 1.8321 - val_acc: 0.4462 - lr: 1.0000e-05\n",
      "Epoch 40/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1025 - acc: 0.6011\n",
      "Epoch 40: val_acc improved from 0.44915 to 0.44965, saving model to chkp/VG_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.1025 - acc: 0.6011 - val_loss: 1.8310 - val_acc: 0.4497 - lr: 1.0000e-05\n",
      "Epoch 41/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0927 - acc: 0.6132\n",
      "Epoch 41: val_acc improved from 0.44965 to 0.45065, saving model to chkp/VG_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.0927 - acc: 0.6132 - val_loss: 1.8356 - val_acc: 0.4506 - lr: 1.0000e-05\n",
      "Epoch 42/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0967 - acc: 0.6057\n",
      "Epoch 42: val_acc did not improve from 0.45065\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.0967 - acc: 0.6057 - val_loss: 1.8327 - val_acc: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 43/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0903 - acc: 0.6090\n",
      "Epoch 43: val_acc did not improve from 0.45065\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.0903 - acc: 0.6090 - val_loss: 1.8317 - val_acc: 0.4482 - lr: 1.0000e-05\n",
      "Epoch 44/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0913 - acc: 0.6136\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 44: val_acc did not improve from 0.45065\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.0913 - acc: 0.6136 - val_loss: 1.8326 - val_acc: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 45/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0816 - acc: 0.6164\n",
      "Epoch 45: val_acc did not improve from 0.45065\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.0816 - acc: 0.6164 - val_loss: 1.8318 - val_acc: 0.4506 - lr: 1.0000e-06\n",
      "Epoch 46/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0935 - acc: 0.6113\n",
      "Epoch 46: val_acc improved from 0.45065 to 0.45115, saving model to chkp/VG_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 77s 287ms/step - loss: 1.0935 - acc: 0.6113 - val_loss: 1.8377 - val_acc: 0.4511 - lr: 1.0000e-06\n",
      "Epoch 47/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0798 - acc: 0.6187\n",
      "Epoch 47: val_acc did not improve from 0.45115\n",
      "268/268 [==============================] - 77s 289ms/step - loss: 1.0798 - acc: 0.6187 - val_loss: 1.8348 - val_acc: 0.4487 - lr: 1.0000e-06\n",
      "Epoch 48/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0829 - acc: 0.6076\n",
      "Epoch 48: val_acc did not improve from 0.45115\n",
      "268/268 [==============================] - 77s 288ms/step - loss: 1.0829 - acc: 0.6076 - val_loss: 1.8331 - val_acc: 0.4482 - lr: 1.0000e-06\n",
      "Epoch 48: early stopping\n"
     ]
    }
   ],
   "source": [
    "seeds = [42, 123, 456, 789, 101112]\n",
    "\n",
    "results = []\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"\\nRunning model with seed {seed}\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "        multiModalData, classes, np.arange(len(multiModalData)), test_size=0.1, stratify=classes, random_state=seed)\n",
    "\n",
    "    #%% Scenarios and LoS NLoS analysis of train and test samples\n",
    "    df_train = pd.read_csv('./ml_challenge_dev_multi_modal_v3_all_scenarios_with_LoS_status.csv')\n",
    "\n",
    "    # Find LoS and NLoS samples in the train and test indices\n",
    "    train_los_indices = df_train[df_train['LoS_status'] == 'LoS'].index.intersection(train_indices)\n",
    "    train_nlos_indices = df_train[df_train['LoS_status'] == 'NLoS'].index.intersection(train_indices)\n",
    "    test_los_indices = df_train[df_train['LoS_status'] == 'LoS'].index.intersection(test_indices)\n",
    "    test_nlos_indices = df_train[df_train['LoS_status'] == 'NLoS'].index.intersection(test_indices)\n",
    "\n",
    "    # Verify that all train and test samples are classified\n",
    "    assert len(train_los_indices) + len(train_nlos_indices) == len(train_indices), \"Mismatch in total train samples\"\n",
    "    assert len(test_los_indices) + len(test_nlos_indices) == len(test_indices), \"Mismatch in total test samples\"\n",
    "\n",
    "    # Identify scenarios\n",
    "    scenario_path = df_train['unit2_loc_1']\n",
    "\n",
    "    # Function to count LoS and NLoS samples for a scenario\n",
    "    def count_scenario_samples(scenario_keyword, los_indices, nlos_indices):\n",
    "        scenario_indices = df_train[scenario_path.str.contains(scenario_keyword)].index\n",
    "        los_count = len(np.intersect1d(los_indices, scenario_indices))\n",
    "        nlos_count = len(np.intersect1d(nlos_indices, scenario_indices))\n",
    "        return los_count, nlos_count\n",
    "\n",
    "    # Count LoS and NLoS samples for each scenario in train and test sets\n",
    "    scenario_los_nlos_counts_train = {}\n",
    "    scenario_los_nlos_counts_test = {}\n",
    "    for scenario_keyword in ['scenario32', 'scenario33', 'scenario34']:\n",
    "        los_count_train, nlos_count_train = count_scenario_samples(scenario_keyword, train_los_indices, train_nlos_indices)\n",
    "        los_count_test, nlos_count_test = count_scenario_samples(scenario_keyword, test_los_indices, test_nlos_indices)\n",
    "        scenario_los_nlos_counts_train[scenario_keyword] = {'LoS': los_count_train, 'NLoS': nlos_count_train}\n",
    "        scenario_los_nlos_counts_test[scenario_keyword] = {'LoS': los_count_test, 'NLoS': nlos_count_test}\n",
    "\n",
    "    # Print the counts for each scenario in train and test sets\n",
    "    print(\"Train Data Scenario Counts:\")\n",
    "    for scenario, counts in scenario_los_nlos_counts_train.items():\n",
    "        print(f\"{scenario} - LoS samples count: {counts['LoS']}, NLoS samples count: {counts['NLoS']}\")\n",
    "\n",
    "    print(\"\\nTest Data Scenario Counts:\")\n",
    "    for scenario, counts in scenario_los_nlos_counts_test.items():\n",
    "        print(f\"{scenario} - LoS samples count: {counts['LoS']}, NLoS samples count: {counts['NLoS']}\")\n",
    "\n",
    "    # Extract LoS and NLoS samples from the modalities and classes\n",
    "    X_train_los = multiModalData[train_los_indices]\n",
    "    X_train_nlos = multiModalData[train_nlos_indices]\n",
    "    X_test_los = multiModalData[test_los_indices]\n",
    "    X_test_nlos = multiModalData[test_nlos_indices]\n",
    "    y_train_los = classes[train_los_indices]\n",
    "    y_train_nlos = classes[train_nlos_indices]\n",
    "    y_test_los = classes[test_los_indices]\n",
    "    y_test_nlos = classes[test_nlos_indices]\n",
    "\n",
    "    # Print shapes of train and test datasets for each modality\n",
    "    print(f'LoS Train Shape: {X_train_los.shape}, LoS Test Shape: {X_test_los.shape}')\n",
    "    print(f'NLoS Train Shape: {X_train_nlos.shape}, NLoS Test Shape: {X_test_nlos.shape}')\n",
    "\n",
    "    # Print shapes of train and test labels\n",
    "    print(f'Train Labels Shape: {y_train.shape}')\n",
    "    print(f'Test Labels Shape: {y_test.shape}')\n",
    "    print(f'Train LoS Labels Shape: {y_train_los.shape}')\n",
    "    print(f'Train NLoS Labels Shape: {y_train_nlos.shape}')\n",
    "    print(f'Test LoS Labels Shape: {y_test_los.shape}')\n",
    "    print(f'Test NLoS Labels Shape: {y_test_nlos.shape}')\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    # some global params\n",
    "    NBFRAME = 5\n",
    "    N_CLASSES = 64\n",
    "    INSHAPE = (5,imagex,imagey,2)\n",
    "    model = GRU_model(INSHAPE, N_CLASSES)\n",
    "    optimizer = keras.optimizers.Adam(0.001) \n",
    "    model.compile(optimizer, 'categorical_crossentropy', metrics=['acc'])\n",
    "    print(model.summary())\n",
    "\n",
    "    #Run the training\n",
    "    EPOCHS=300\n",
    "    BS = 30\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, mode='min', verbose=1),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=8, mode='min', verbose=1),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            f'chkp/{model_name}_seed_{seed}.hdf5', \n",
    "            monitor='val_acc',  # Monitor validation accuracy\n",
    "            save_best_only  = True,\n",
    "            mode='max',  # Maximize the monitored quantity\n",
    "            verbose=1),\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        validation_split = 0.2, #0\n",
    "        #validation_data=(X_val, y_val),\n",
    "        verbose=1,\n",
    "        #verbose='auto', #auto\n",
    "        epochs=EPOCHS,\n",
    "        batch_size =BS,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model with seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 01:19:58.264821: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-08-25 01:19:58.264854: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: edison\n",
      "2024-08-25 01:19:58.264859: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: edison\n",
      "2024-08-25 01:19:58.264997: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 560.35.3\n",
      "2024-08-25 01:19:58.265016: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: NOT_FOUND: could not find kernel module information in driver version file contents: \"NVRM version: NVIDIA UNIX Open Kernel Module for x86_64  560.35.03  Release Build  (dvs-builder@U16-I1-N07-12-3)  Fri Aug 16 21:42:42 UTC 2024\n",
      "GCC version:  gcc version 11.4.0 (Ubuntu 11.4.0-1ubuntu1~22.04) \n",
      "\"\n",
      "2024-08-25 01:19:58.267693: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 27s 82ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 3s 81ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 43ms/step\n",
      "\n",
      "Evaluating model with seed 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 26s 82ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 3s 85ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 35ms/step\n",
      "\n",
      "Evaluating model with seed 456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 26s 82ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 3s 82ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 46ms/step\n",
      "\n",
      "Evaluating model with seed 789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 26s 81ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 3s 82ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 38ms/step\n",
      "\n",
      "Evaluating model with seed 101112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 26s 81ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 3s 85ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 39ms/step\n",
      "\n",
      "Average Results Across All Seeds:\n",
      "Type: Train - Avg Accuracies: [0.59634 0.90552 0.96274] ± [0.03624106 0.0189466  0.00811877], Avg Score: 0.9199999999999999 ± 0.010954451150103333, top31_beam: 0.882 ± 0.017204650534085267, top33_beam: 0.9780000000000001 ± 0.0040000000000000036, PF1_mean: 0.9800000000000001 ± 1.1102230246251565e-16, PF2_mean: 0.99 ± 0.0, PF3_mean: 0.998 ± 0.0040000000000000036, Recall: 0.596 ± 0.03720215047547654, Precision: 0.5940000000000001 ± 0.04454211490264017\n",
      "Type: Test_LoS - Avg Accuracies: [0.46406 0.83122 0.9398 ] ± [0.02125273 0.01174298 0.0080491 ], Avg Score: 0.89 ± 0.006324555320336764, top31_beam: 0.85 ± 0.014142135623730963, top33_beam: 0.97 ± 0.006324555320336764, PF1_mean: 0.9780000000000001 ± 0.0040000000000000036, PF2_mean: 0.99 ± 0.0, PF3_mean: 0.992 ± 0.0040000000000000036, Recall: 0.46399999999999997 ± 0.019595917942265416, Precision: 0.42000000000000004 ± 0.025298221281347028\n",
      "Type: Test_NLoS - Avg Accuracies: [0.0354  0.11762 0.16188] ± [0.04766584 0.04694194 0.06438948], Avg Score: 0.15799999999999997 ± 0.05418486873657627, top31_beam: 0.2740000000000001 ± 0.08822698000045111, top33_beam: 0.4739999999999999 ± 0.06621178142898741, PF1_mean: 0.9040000000000001 ± 0.008000000000000007, PF2_mean: 0.9200000000000002 ± 0.006324555320336764, PF3_mean: 0.932 ± 0.007483314773547842, Recall: 0.034 ± 0.04882622246293482, Precision: 0.06599999999999999 ± 0.08935323161475471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10514"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% Test on all scens together\n",
    "#%%Test on Train and Test data (top-1,2,3)\n",
    "\n",
    "# Model evaluation and prediction\n",
    "def evaluate_model(model, X_data, y_data, pwrs_array, data_type, result_list, sample_indices):\n",
    "    predictions = model.predict(X_data)\n",
    "    y_pred = np.argsort(predictions, axis=1)[:, ::-1]\n",
    "    save_pred_to_csv(sample_indices, y_pred, top_k=[1,2,3], target_csv=f'preds_{model_name}_{data_type}.csv')\n",
    "    true = np.argmax(y_data, axis=1).reshape(-1, 1)\n",
    "    acc = compute_acc(y_pred, true, top_k=[1, 3, 5])\n",
    "    score = compute_DBA_score(y_pred, true, max_k=3, delta=5)\n",
    "    recall = recall_score(true, y_pred[:, 0], average='weighted')\n",
    "    precision = precision_score(true, y_pred[:, 0], average='weighted')\n",
    "    PF_mean = compute_powerfactor(y_pred, pwrs_array, k=3)\n",
    "    top_beams = calculate_top_beams(predictions, pwrs_array)\n",
    "   \n",
    "    result_list.append({\n",
    "        'type': data_type,\n",
    "        'acc': acc,\n",
    "        'score': round(score, 2),\n",
    "        'top31_beam': top_beams[0],\n",
    "        'top33_beam': top_beams[1],\n",
    "        'PF1_mean': PF_mean[0],\n",
    "        'PF2_mean': PF_mean[1],\n",
    "        'PF3_mean': PF_mean[2],\n",
    "        'recall': round(recall, 2),\n",
    "        'precision': round(precision, 2)\n",
    "    })\n",
    "\n",
    "\n",
    "# Define the seeds used for training\n",
    "seeds = [42, 123, 456, 789, 101112]\n",
    "\n",
    "# Placeholder for storing results from all seeds\n",
    "all_results = []\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"\\nEvaluating model with seed {seed}\")\n",
    "\n",
    "    # Train-Test Split with the current seed\n",
    "    X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "        multiModalData, classes, np.arange(len(multiModalData)), test_size=0.1, stratify=classes, random_state=seed)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    # Reload the scenario data\n",
    "    df_train = pd.read_csv('./ml_challenge_dev_multi_modal_v3_all_scenarios_with_LoS_status.csv')\n",
    "\n",
    "    # Find LoS and NLoS samples in the train and test indices\n",
    "    train_los_indices = df_train[df_train['LoS_status'] == 'LoS'].index.intersection(train_indices)\n",
    "    train_nlos_indices = df_train[df_train['LoS_status'] == 'NLoS'].index.intersection(train_indices)\n",
    "    test_los_indices = df_train[df_train['LoS_status'] == 'LoS'].index.intersection(test_indices)\n",
    "    test_nlos_indices = df_train[df_train['LoS_status'] == 'NLoS'].index.intersection(test_indices)\n",
    "\n",
    "    # Extract LoS and NLoS samples from the data and classes\n",
    "    X_test_los = multiModalData[test_los_indices]\n",
    "    X_test_nlos = multiModalData[test_nlos_indices]\n",
    "    y_test_los = classes[test_los_indices]\n",
    "    y_test_nlos = classes[test_nlos_indices]\n",
    "\n",
    "    # Power analysis - make sure to get the correct power arrays for each seed\n",
    "    N_CLASSES = 64\n",
    "    pwrs_array = np.zeros((df_train.shape[0], N_CLASSES))\n",
    "    for sample_idx in range(df_train.shape[0]):\n",
    "        pwr_abs_path = df_train['unit1_pwr_60ghz'].values[sample_idx]\n",
    "        pwrs_array[sample_idx] = np.loadtxt(pwr_abs_path)\n",
    "\n",
    "    pwrs_array[np.isnan(pwrs_array)] = 0\n",
    "    pwrs_array_train = pwrs_array[train_indices]\n",
    "    pwrs_array_test_los = pwrs_array[test_los_indices]\n",
    "    pwrs_array_test_nlos = pwrs_array[test_nlos_indices]\n",
    "\n",
    "    # Load the model corresponding to the current seed\n",
    "    model = load_model(f'chkp/{model_name}_seed_{seed}.hdf5')\n",
    "\n",
    "    # Initialize results list for the current seed\n",
    "    seed_results = []\n",
    "\n",
    "    # Evaluate on training data\n",
    "    evaluate_model(model, X_train, y_train, pwrs_array_train, 'Train', seed_results, train_indices)\n",
    "\n",
    "    # Evaluate on test data\n",
    "    evaluate_model(model, X_test_los, y_test_los, pwrs_array_test_los, 'Test_LoS', seed_results, test_los_indices)\n",
    "    evaluate_model(model, X_test_nlos, y_test_nlos, pwrs_array_test_nlos, 'Test_NLoS', seed_results, test_nlos_indices)\n",
    "\n",
    "    # Store the results of this seed in all_results\n",
    "    all_results.append(seed_results)\n",
    "\n",
    "# Function to average results across all seeds\n",
    "def average_results(all_results, metric):\n",
    "    averages = {}\n",
    "    types = ['Train', 'Test_LoS', 'Test_NLoS']\n",
    "    for data_type in types:\n",
    "        type_results = [res for seed_res in all_results for res in seed_res if res['type'] == data_type]\n",
    "        avg_metric = np.mean([res[metric] for res in type_results], axis=0)\n",
    "        std_metric = np.std([res[metric] for res in type_results], axis=0)\n",
    "        averages[data_type] = (avg_metric, std_metric)\n",
    "    return averages\n",
    "\n",
    "# Compute averages and standard deviations for each metric\n",
    "avg_accuracies = average_results(all_results, 'acc')\n",
    "avg_scores = average_results(all_results, 'score')\n",
    "avg_top31_beams = average_results(all_results, 'top31_beam')\n",
    "avg_top33_beams = average_results(all_results, 'top33_beam')\n",
    "avg_PF1_means = average_results(all_results, 'PF1_mean')\n",
    "avg_PF2_means = average_results(all_results, 'PF2_mean')\n",
    "avg_PF3_means = average_results(all_results, 'PF3_mean')\n",
    "avg_recalls = average_results(all_results, 'recall')\n",
    "avg_precisions = average_results(all_results, 'precision')\n",
    "\n",
    "# Print the average results across all seeds\n",
    "print(\"\\nAverage Results Across All Seeds:\")\n",
    "for data_type in avg_accuracies:\n",
    "    print(f\"Type: {data_type} - Avg Accuracies: {avg_accuracies[data_type][0]} ± {avg_accuracies[data_type][1]}, \"\n",
    "          f\"Avg Score: {avg_scores[data_type][0]} ± {avg_scores[data_type][1]}, \"\n",
    "          f\"top31_beam: {avg_top31_beams[data_type][0]} ± {avg_top31_beams[data_type][1]}, \"\n",
    "          f\"top33_beam: {avg_top33_beams[data_type][0]} ± {avg_top33_beams[data_type][1]}, \"\n",
    "          f\"PF1_mean: {avg_PF1_means[data_type][0]} ± {avg_PF1_means[data_type][1]}, \"\n",
    "          f\"PF2_mean: {avg_PF2_means[data_type][0]} ± {avg_PF2_means[data_type][1]}, \"\n",
    "          f\"PF3_mean: {avg_PF3_means[data_type][0]} ± {avg_PF3_means[data_type][1]}, \"\n",
    "          f\"Recall: {avg_recalls[data_type][0]} ± {avg_recalls[data_type][1]}, \"\n",
    "          f\"Precision: {avg_precisions[data_type][0]} ± {avg_precisions[data_type][1]}\")\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to CSV:\n",
      "        Type                                    Acc        Score   top31_beam  \\\n",
      "0      Train  0.60 ± 0.04, 0.91 ± 0.02, 0.96 ± 0.01  0.92 ± 0.01  0.88 ± 0.02   \n",
      "1   Test_LoS  0.46 ± 0.02, 0.83 ± 0.01, 0.94 ± 0.01  0.89 ± 0.01  0.85 ± 0.01   \n",
      "2  Test_NLoS  0.04 ± 0.05, 0.12 ± 0.05, 0.16 ± 0.06  0.16 ± 0.05  0.27 ± 0.09   \n",
      "\n",
      "    top33_beam     PF1_mean     PF2_mean     PF3_mean       Recall  \\\n",
      "0  0.98 ± 0.00  0.98 ± 0.00  0.99 ± 0.00  1.00 ± 0.00  0.60 ± 0.04   \n",
      "1  0.97 ± 0.01  0.98 ± 0.00  0.99 ± 0.00  0.99 ± 0.00  0.46 ± 0.02   \n",
      "2  0.47 ± 0.07  0.90 ± 0.01  0.92 ± 0.01  0.93 ± 0.01  0.03 ± 0.05   \n",
      "\n",
      "     Precision  \n",
      "0  0.59 ± 0.04  \n",
      "1  0.42 ± 0.03  \n",
      "2  0.07 ± 0.09  \n"
     ]
    }
   ],
   "source": [
    "# Define a function to format mean ± std\n",
    "def format_mean_std(mean, std):\n",
    "    return f\"{mean:.2f} ± {std:.2f}\"\n",
    "\n",
    "# Initialize the final results list\n",
    "formatted_results = []\n",
    "\n",
    "# Process the results for saving\n",
    "for data_type in avg_accuracies:\n",
    "    acc_means, acc_stds = avg_accuracies[data_type]\n",
    "    row = {\n",
    "        'Type': data_type,\n",
    "        'Acc': ', '.join([format_mean_std(m, s) for m, s in zip(acc_means, acc_stds)]),\n",
    "        'Score': format_mean_std(*avg_scores[data_type]),\n",
    "        'top31_beam': format_mean_std(*avg_top31_beams[data_type]),\n",
    "        'top33_beam': format_mean_std(*avg_top33_beams[data_type]),\n",
    "        'PF1_mean': format_mean_std(*avg_PF1_means[data_type]),\n",
    "        'PF2_mean': format_mean_std(*avg_PF2_means[data_type]),\n",
    "        'PF3_mean': format_mean_std(*avg_PF3_means[data_type]),\n",
    "        'Recall': format_mean_std(*avg_recalls[data_type]),\n",
    "        'Precision': format_mean_std(*avg_precisions[data_type])\n",
    "    }\n",
    "    formatted_results.append(row)\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "df = pd.DataFrame(formatted_results)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(f'results_{model_name}_AllScens.csv', index=False)\n",
    "\n",
    "print(\"Results saved to CSV:\")\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
