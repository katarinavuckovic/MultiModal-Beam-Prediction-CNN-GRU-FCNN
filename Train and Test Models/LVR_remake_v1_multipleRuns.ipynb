{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Apr 19 13:55:28 2023\n",
    "\n",
    "@author: Saba\n",
    "\"\"\"\n",
    "\n",
    "'''\n",
    "To change at each run with different models:\n",
    "    the name of the file in commands: \n",
    "        result.to_csv\n",
    "    the name of ckpt in:\n",
    "        callbacks      \n",
    "        \n",
    "This is Lidar_Transformed plus Vision data to be trained with CNN to make a multimodal network.\n",
    "Image (Vision) is transformed from RGB to gray.\n",
    "'''\n",
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Conv1D, Conv2D, BatchNormalization, MaxPool1D, MaxPool2D, GlobalMaxPool1D, GlobalMaxPool2D\n",
    "from keras.layers import TimeDistributed, GRU, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.lines as mlines\n",
    "import utm\n",
    "from collections import Counter\n",
    "import random\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import math\n",
    "import pickle \n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)  # Set TensorFlow seed as well\n",
    "     \n",
    "#%% Main                \n",
    "#Score function\n",
    "def compute_acc(y_pred, y_true, top_k=[1,3,5]):\n",
    "    \"\"\" Computes top-k accuracy given prediction and ground truth labels.\"\"\"\n",
    "    n_top_k = len(top_k)\n",
    "    total_hits = np.zeros(n_top_k)\n",
    "    \n",
    "    n_test_samples = len(y_true)\n",
    "    if len(y_pred) != n_test_samples:\n",
    "        raise Exception('Number of predicted beams does not match number of labels.')\n",
    "    \n",
    "    # For each test sample, count times where true beam is in k top guesses\n",
    "    for samp_idx in range(len(y_true)):\n",
    "        for k_idx in range(n_top_k):\n",
    "            hit = np.any(y_pred[samp_idx,:top_k[k_idx]] == y_true[samp_idx, -1])\n",
    "            total_hits[k_idx] += 1 if hit else 0\n",
    "    \n",
    "    # Average the number of correct guesses (over the total samples)\n",
    "    return np.round(total_hits / len(y_true), 4)\n",
    "\n",
    "def save_pred_to_csv(sample_index, y_pred, top_k=[1,2,3], target_csv='beam_pred.csv'):\n",
    "    \"\"\" \n",
    "    Saves the predicted beam results to a csv file. \n",
    "    Expects y_pred: n_samples x N_BEAMS, and saves the top_k columns only. \n",
    "    \"\"\"\n",
    "    \n",
    "    cols = [f'top-{i} beam' for i in top_k]\n",
    "    df = pd.DataFrame(data=y_pred[:, np.array(top_k)-1], columns=cols)\n",
    "    df.index.name = 'index'\n",
    "    df['sample_index'] = sample_index\n",
    "    df.to_csv(target_csv)\n",
    "\n",
    "def compute_DBA_score(y_pred, y_true, max_k=3, delta=5):\n",
    "    \"\"\" \n",
    "    The top-k MBD (Minimum Beam Distance) as the minimum distance\n",
    "    of any beam in the top-k set of predicted beams to the ground truth beam. \n",
    "    \n",
    "    Then we take the average across all samples.\n",
    "    \n",
    "    Then we average that number over all the considered Ks.\n",
    "    \"\"\"\n",
    "    n_samples = y_pred.shape[0]\n",
    "    #n_beams = y_pred.shape[-1] \n",
    "    \n",
    "    yk = np.zeros(max_k)\n",
    "    for k in range(max_k):\n",
    "        acc_avg_min_beam_dist = 0\n",
    "        idxs_up_to_k = np.arange(k+1)\n",
    "        for i in range(n_samples):\n",
    "            aux1 = np.abs(y_pred[i, idxs_up_to_k] - y_true[i]) / delta\n",
    "            # Compute min between beam diff and 1\n",
    "            aux2 = np.min(np.stack((aux1, np.zeros_like(aux1)+1), axis=0), axis=0)\n",
    "            acc_avg_min_beam_dist += np.min(aux2)\n",
    "            \n",
    "        yk[k] = 1 - acc_avg_min_beam_dist / n_samples\n",
    "    \n",
    "    return np.mean(yk)\n",
    "\n",
    "#%% Power factor\n",
    "def compute_powerfactor(y_pred, pwrs_array, k=3):\n",
    "    '''\n",
    "    Calculate the maximum power factor for top-1 to top-k predictions.\n",
    "    \n",
    "    Args:\n",
    "    y_pred (numpy array): Sorted predictions (n_samples, 64), indices of beams sorted by probability.\n",
    "    pwrs_array (numpy array): Power values for beams (n_samples, 64).\n",
    "    k (int): The top-k predictions to consider.\n",
    "    \n",
    "    Returns:\n",
    "    numpy array: Array of average max PFs from top-1 to top-k.\n",
    "    '''\n",
    "    max_Pr = np.max(pwrs_array, axis=1)  # Maximum power across all beams for each sample\n",
    "    PF_max_k = np.zeros(k)  # Array to store the average of maximum PFs for each top-k\n",
    "    #PF_max_k_stds = np.zeros(k)  # Array to store the standard deviation of maximum PFs for each top-k\n",
    "    \n",
    "    for i in range(1, k+1):\n",
    "        max_PF = np.zeros(pwrs_array.shape[0])  # Array to hold the max PF for each sample for current top-i\n",
    "        for j in range(pwrs_array.shape[0]):  # Iterate over each sample\n",
    "            # Calculate PFs for the top-i predictions and find the maximum\n",
    "            top_k_PFs = pwrs_array[j, y_pred[j, :i]] / max_Pr[j]\n",
    "            max_PF[j] = np.max(top_k_PFs)  # Maximum PF for this sample among top-i\n",
    "        PF_max_k[i-1] = np.round(np.mean(max_PF), 2)  # Average of maximum PFs across all samples for top-i\n",
    "        #PF_max_k_stds[i-1] = np.round(np.std(max_PF), 2)  # Standard deviation of maximum PFs for top-i\n",
    "\n",
    "    return PF_max_k #, PF_max_k_stds\n",
    "\n",
    "def calculate_top_beams(predictions, truths):\n",
    "    correct_top1_count = 0\n",
    "    correct_top3_count = 0\n",
    "    total_count = len(predictions)  # Assuming predictions and truths are lists of numpy arrays\n",
    "    \n",
    "    for pred, true in zip(predictions, truths):\n",
    "        # Find the index of the highest value in the predicted array\n",
    "        top_pred_index = np.argmax(pred)\n",
    "        \n",
    "        # Find the indices of the top 3 highest values in the true array\n",
    "        top_true_indices = np.argsort(true)[-3:]\n",
    "        \n",
    "        # Check if the top predicted index is among the top 3 true indices for top-1 accuracy\n",
    "        if top_pred_index in top_true_indices:\n",
    "            correct_top1_count += 1\n",
    "        \n",
    "        # Find the indices of the top 3 highest values in the predicted array\n",
    "        top_pred_indices = np.argsort(pred)[-3:]\n",
    "        \n",
    "        # Check if there is any intersection between the top 3 predicted indices and the top 3 true indices for top-3 accuracy\n",
    "        if set(top_pred_indices) & set(top_true_indices):\n",
    "            correct_top3_count += 1\n",
    "    \n",
    "    # Calculate the percentage of correct predictions for top-1 and top-3 accuracies\n",
    "    top1_accuracy = (correct_top1_count / total_count)\n",
    "    top3_accuracy = (correct_top3_count / total_count) \n",
    "    top1_accuracy  = round(top1_accuracy, 2)\n",
    "    top3_accuracy  = round(top3_accuracy, 2)\n",
    "    return [top1_accuracy,top3_accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#%% GPU optimization\n",
    "#\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "        \n",
    "#\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\" #to allow automatic assignment of operations to different GPUs to prevent OOM issue\n",
    "'''   \n",
    "\n",
    "# Set environment variables to disable GPU usage and use CPU instead\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # This line disables GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% some global params\n",
    "model_name = \"LVR_remake_v1_multipleRuns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 225.6\n",
      "-0.0 255.01\n",
      "0.34 190.18\n",
      "0.34 145.74\n",
      "0.33 145.74\n"
     ]
    }
   ],
   "source": [
    "#%%Load data\n",
    "def add_noise(data, noise_level):\n",
    "    noisy_data = data + np.random.normal(scale=noise_level, size=data.shape)\n",
    "    return noisy_data\n",
    "\n",
    "'''\n",
    "def add_gps_noise(GPS, noise_level):\n",
    "    GPS_noisy = np.zeros(GPS.shape)\n",
    "    GPS_noisy[:,:,0] = GPS[:,:,0] + np.random.normal(scale=noise_level, size=GPS[:,:,0].shape)\n",
    "    GPS_noisy[:,:,1] = GPS[:,:,1] + np.random.normal(scale=noise_level, size=GPS[:,:,1].shape)\n",
    "    return GPS_noisy\n",
    "'''\n",
    "\n",
    "df_train =  pd.read_csv('./ml_challenge_dev_multi_modal_v2.csv')\n",
    "index = df_train['unit1_beam'].values\n",
    "\n",
    "imagex = 150\n",
    "imagey = 150\n",
    "\n",
    "import cv2\n",
    "def rescale(data): #to rescale from 11143x5x210x360 to 11143,5,210,225\n",
    "    resized_data= np.zeros((data.shape[0],5,imagex,imagey))\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            resized_data[i, j] = cv2.resize(data[i, j], (imagey, imagex), interpolation=cv2.INTER_NEAREST)\n",
    "    return resized_data\n",
    "    \n",
    "data = np.load('lidar_DepthInten_11143x5x210x360_v2.npz') \n",
    "lidar = rescale(data['Lidar'])\n",
    "print(round(np.min(lidar), 2),round(np.max(lidar), 2))\n",
    "\n",
    "data = np.load('vision_gray_11143x5x210x360.npz')\n",
    "vision = rescale(data['vision'])\n",
    "vision = add_noise(vision, 0.001)\n",
    "print(round(np.min(vision), 2),round(np.max(vision), 2))\n",
    "\n",
    "'''\n",
    "data = np.load('radar_11143x5x210x360.npz') \n",
    "radar = rescale(data['radar'])\n",
    "radar = add_noise(radar, 0.0025)\n",
    "'''\n",
    "os.chdir(r'/home/sa457043/Multimodal_beam_prediction/')\n",
    "radar = np.load('radar_11143x5x256x64.npz')['radar'] \n",
    "print(round(np.min(radar), 2),round(np.max(radar), 2))\n",
    "radar = rescale(radar)\n",
    "print(round(np.min(radar), 2),round(np.max(radar), 2))\n",
    "radar = add_noise(radar, 0.0025)\n",
    "print(round(np.min(radar), 2),round(np.max(radar), 2))\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "multiModalData = np.zeros([11143,5,imagex,imagey,3])\n",
    "multiModalData[:,:,:,:,0] = lidar\n",
    "multiModalData[:,:,:,:,1] = vision\n",
    "multiModalData[:,:,:,:,2] = radar\n",
    "multiModalData = tf.keras.utils.normalize(multiModalData.reshape([11143*5,-1]))  \n",
    "multiModalData = multiModalData.reshape([11143,5,imagex,imagey,3])\n",
    "\n",
    "del lidar, vision, radar\n",
    "gc.collect()\n",
    "\n",
    "classes = to_categorical(df_train['unit1_beam'].values - 1, num_classes = 64, dtype =\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%Model\n",
    "def build_convnet(shape=(imagex,imagey,3)):\n",
    "    momentum = .9\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(Conv2D(4, 3, input_shape=shape,padding='same', activation='relu'))\n",
    "    model.add(Conv2D(16, 3, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool2D(pool_size=3))\n",
    "    model.add(MaxPool2D(pool_size=3))\n",
    "    \n",
    "    model.add(Conv2D(16, 3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(32, 3, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool2D(pool_size=3))\n",
    "\n",
    "    model.add(Conv2D(128, 3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, 3, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool2D(pool_size=3))\n",
    "    \n",
    "    model.add(GlobalMaxPool2D())\n",
    "    return model\n",
    "\n",
    "def GRU_model(input_shape=(5, imagex, imagey, 3), nbout=64): \n",
    "    # Create our convnet with (112, 112, 3) input shape\n",
    "    convnet = build_convnet(input_shape[1:]) #all elements after shape[0] (not shape[0])\n",
    "    \n",
    "    # then create our final model\n",
    "    model = keras.Sequential()\n",
    "    # add the convnet with (5, 128,125,4) shape\n",
    "    model.add(TimeDistributed(convnet, input_shape=input_shape))\n",
    "    # here, you can also use GRU or LSTM\n",
    "    model.add(GRU(64))\n",
    "    # and finally, we make a decision network\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    #model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(nbout, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running model with seed 42\n",
      "Train Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 2683, NLoS samples count: 110\n",
      "scenario33 - LoS samples count: 3329, NLoS samples count: 120\n",
      "scenario34 - LoS samples count: 3691, NLoS samples count: 95\n",
      "\n",
      "Test Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 311, NLoS samples count: 11\n",
      "scenario33 - LoS samples count: 372, NLoS samples count: 16\n",
      "scenario34 - LoS samples count: 391, NLoS samples count: 14\n",
      "LoS Train Shape: (9703, 5, 150, 150, 3), LoS Test Shape: (1074, 5, 150, 150, 3)\n",
      "NLoS Train Shape: (325, 5, 150, 150, 3), NLoS Test Shape: (41, 5, 150, 150, 3)\n",
      "Train Labels Shape: (10028, 64)\n",
      "Test Labels Shape: (1115, 64)\n",
      "Train LoS Labels Shape: (9703, 64)\n",
      "Train NLoS Labels Shape: (325, 64)\n",
      "Test LoS Labels Shape: (1074, 64)\n",
      "Test NLoS Labels Shape: (41, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 22:08:37.861099: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-08-22 22:08:37.861126: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: edison\n",
      "2024-08-22 22:08:37.861131: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: edison\n",
      "2024-08-22 22:08:37.861265: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 560.28.3\n",
      "2024-08-22 22:08:37.861285: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: NOT_FOUND: could not find kernel module information in driver version file contents: \"NVRM version: NVIDIA UNIX Open Kernel Module for x86_64  560.28.03  Release Build  (dvs-builder@U16-A24-27-4)  Thu Jul 18 20:46:24 UTC 2024\n",
      "GCC version:  gcc version 11.4.0 (Ubuntu 11.4.0-1ubuntu1~22.04) \n",
      "\"\n",
      "2024-08-22 22:08:37.861546: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDistr  (None, 5, 256)           341040    \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                61824     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 411,184\n",
      "Trainable params: 410,576\n",
      "Non-trainable params: 608\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.8378 - acc: 0.0945\n",
      "Epoch 1: val_acc improved from -inf to 0.13659, saving model to chkp/LVR_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 90s 324ms/step - loss: 3.8378 - acc: 0.0945 - val_loss: 3.5787 - val_acc: 0.1366 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.5326 - acc: 0.1265\n",
      "Epoch 2: val_acc improved from 0.13659 to 0.15753, saving model to chkp/LVR_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 81s 303ms/step - loss: 3.5326 - acc: 0.1265 - val_loss: 3.2597 - val_acc: 0.1575 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.2086 - acc: 0.1601\n",
      "Epoch 3: val_acc improved from 0.15753 to 0.18295, saving model to chkp/LVR_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 3.2086 - acc: 0.1601 - val_loss: 2.9728 - val_acc: 0.1830 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.9323 - acc: 0.1912\n",
      "Epoch 4: val_acc improved from 0.18295 to 0.22084, saving model to chkp/LVR_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 81s 301ms/step - loss: 2.9323 - acc: 0.1912 - val_loss: 2.7734 - val_acc: 0.2208 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.7077 - acc: 0.2277\n",
      "Epoch 5: val_acc improved from 0.22084 to 0.24078, saving model to chkp/LVR_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 81s 301ms/step - loss: 2.7077 - acc: 0.2277 - val_loss: 2.5450 - val_acc: 0.2408 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.4921 - acc: 0.2604\n",
      "Epoch 6: val_acc improved from 0.24078 to 0.27468, saving model to chkp/LVR_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 81s 301ms/step - loss: 2.4921 - acc: 0.2604 - val_loss: 2.3600 - val_acc: 0.2747 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.3251 - acc: 0.2997\n",
      "Epoch 7: val_acc improved from 0.27468 to 0.31206, saving model to chkp/LVR_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 2.3251 - acc: 0.2997 - val_loss: 2.2442 - val_acc: 0.3121 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.2200 - acc: 0.3165\n",
      "Epoch 8: val_acc did not improve from 0.31206\n",
      "268/268 [==============================] - 81s 301ms/step - loss: 2.2200 - acc: 0.3165 - val_loss: 2.1993 - val_acc: 0.3026 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.0907 - acc: 0.3454\n",
      "Epoch 9: val_acc improved from 0.31206 to 0.34048, saving model to chkp/LVR_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 2.0907 - acc: 0.3454 - val_loss: 2.1065 - val_acc: 0.3405 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.0168 - acc: 0.3614\n",
      "Epoch 10: val_acc improved from 0.34048 to 0.35194, saving model to chkp/LVR_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 2.0168 - acc: 0.3614 - val_loss: 2.0587 - val_acc: 0.3519 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.9414 - acc: 0.3858\n",
      "Epoch 11: val_acc improved from 0.35194 to 0.38385, saving model to chkp/LVR_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 81s 301ms/step - loss: 1.9414 - acc: 0.3858 - val_loss: 1.8991 - val_acc: 0.3838 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.9006 - acc: 0.3934\n",
      "Epoch 12: val_acc did not improve from 0.38385\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.9006 - acc: 0.3934 - val_loss: 1.8963 - val_acc: 0.3669 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8351 - acc: 0.3993\n",
      "Epoch 13: val_acc did not improve from 0.38385\n",
      "268/268 [==============================] - 80s 300ms/step - loss: 1.8351 - acc: 0.3993 - val_loss: 1.9221 - val_acc: 0.3764 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8028 - acc: 0.4085\n",
      "Epoch 14: val_acc improved from 0.38385 to 0.38684, saving model to chkp/LVR_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 81s 301ms/step - loss: 1.8028 - acc: 0.4085 - val_loss: 1.8746 - val_acc: 0.3868 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7423 - acc: 0.4196\n",
      "Epoch 15: val_acc improved from 0.38684 to 0.39133, saving model to chkp/LVR_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 80s 300ms/step - loss: 1.7423 - acc: 0.4196 - val_loss: 1.8505 - val_acc: 0.3913 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7170 - acc: 0.4211\n",
      "Epoch 16: val_acc improved from 0.39133 to 0.40329, saving model to chkp/LVR_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 81s 301ms/step - loss: 1.7170 - acc: 0.4211 - val_loss: 1.8250 - val_acc: 0.4033 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6829 - acc: 0.4324\n",
      "Epoch 17: val_acc did not improve from 0.40329\n",
      "268/268 [==============================] - 81s 301ms/step - loss: 1.6829 - acc: 0.4324 - val_loss: 1.8616 - val_acc: 0.3933 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6626 - acc: 0.4412\n",
      "Epoch 18: val_acc improved from 0.40329 to 0.40578, saving model to chkp/LVR_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 1.6626 - acc: 0.4412 - val_loss: 1.7928 - val_acc: 0.4058 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6178 - acc: 0.4447\n",
      "Epoch 19: val_acc did not improve from 0.40578\n",
      "268/268 [==============================] - 80s 300ms/step - loss: 1.6178 - acc: 0.4447 - val_loss: 1.8220 - val_acc: 0.3953 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5773 - acc: 0.4530\n",
      "Epoch 20: val_acc did not improve from 0.40578\n",
      "268/268 [==============================] - 81s 301ms/step - loss: 1.5773 - acc: 0.4530 - val_loss: 2.0758 - val_acc: 0.3500 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5809 - acc: 0.4577\n",
      "Epoch 21: val_acc did not improve from 0.40578\n",
      "268/268 [==============================] - 81s 301ms/step - loss: 1.5809 - acc: 0.4577 - val_loss: 1.8632 - val_acc: 0.4008 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5465 - acc: 0.4592\n",
      "Epoch 22: val_acc improved from 0.40578 to 0.41226, saving model to chkp/LVR_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 81s 301ms/step - loss: 1.5465 - acc: 0.4592 - val_loss: 1.7760 - val_acc: 0.4123 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5116 - acc: 0.4693\n",
      "Epoch 23: val_acc did not improve from 0.41226\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 1.5116 - acc: 0.4693 - val_loss: 1.9489 - val_acc: 0.3848 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5021 - acc: 0.4749\n",
      "Epoch 24: val_acc improved from 0.41226 to 0.41974, saving model to chkp/LVR_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 1.5021 - acc: 0.4749 - val_loss: 1.7840 - val_acc: 0.4197 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4899 - acc: 0.4819\n",
      "Epoch 25: val_acc did not improve from 0.41974\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 1.4899 - acc: 0.4819 - val_loss: 1.7790 - val_acc: 0.4163 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4640 - acc: 0.4789\n",
      "Epoch 26: val_acc did not improve from 0.41974\n",
      "268/268 [==============================] - 81s 301ms/step - loss: 1.4640 - acc: 0.4789 - val_loss: 1.7823 - val_acc: 0.4172 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4365 - acc: 0.4888\n",
      "Epoch 27: val_acc did not improve from 0.41974\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 1.4365 - acc: 0.4888 - val_loss: 1.8626 - val_acc: 0.4023 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4233 - acc: 0.4938\n",
      "Epoch 28: val_acc did not improve from 0.41974\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 1.4233 - acc: 0.4938 - val_loss: 1.8369 - val_acc: 0.4088 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4084 - acc: 0.5064\n",
      "Epoch 29: val_acc did not improve from 0.41974\n",
      "268/268 [==============================] - 81s 301ms/step - loss: 1.4084 - acc: 0.5064 - val_loss: 1.9723 - val_acc: 0.4023 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3782 - acc: 0.5025\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 30: val_acc did not improve from 0.41974\n",
      "268/268 [==============================] - 81s 301ms/step - loss: 1.3782 - acc: 0.5025 - val_loss: 1.8369 - val_acc: 0.4143 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2722 - acc: 0.5441\n",
      "Epoch 31: val_acc improved from 0.41974 to 0.43669, saving model to chkp/LVR_remake_v1_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 1.2722 - acc: 0.5441 - val_loss: 1.7844 - val_acc: 0.4367 - lr: 1.0000e-04\n",
      "Epoch 32/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2091 - acc: 0.5637\n",
      "Epoch 32: val_acc did not improve from 0.43669\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 1.2091 - acc: 0.5637 - val_loss: 1.7962 - val_acc: 0.4337 - lr: 1.0000e-04\n",
      "Epoch 33/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1802 - acc: 0.5706\n",
      "Epoch 33: val_acc did not improve from 0.43669\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 1.1802 - acc: 0.5706 - val_loss: 1.8059 - val_acc: 0.4302 - lr: 1.0000e-04\n",
      "Epoch 34/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1622 - acc: 0.5810\n",
      "Epoch 34: val_acc did not improve from 0.43669\n",
      "268/268 [==============================] - 81s 301ms/step - loss: 1.1622 - acc: 0.5810 - val_loss: 1.8238 - val_acc: 0.4327 - lr: 1.0000e-04\n",
      "Epoch 35/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1377 - acc: 0.5864\n",
      "Epoch 35: val_acc did not improve from 0.43669\n",
      "268/268 [==============================] - 81s 301ms/step - loss: 1.1377 - acc: 0.5864 - val_loss: 1.8314 - val_acc: 0.4357 - lr: 1.0000e-04\n",
      "Epoch 36/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1253 - acc: 0.5903\n",
      "Epoch 36: val_acc did not improve from 0.43669\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 1.1253 - acc: 0.5903 - val_loss: 1.8485 - val_acc: 0.4342 - lr: 1.0000e-04\n",
      "Epoch 37/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1057 - acc: 0.6002\n",
      "Epoch 37: val_acc did not improve from 0.43669\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 1.1057 - acc: 0.6002 - val_loss: 1.8636 - val_acc: 0.4322 - lr: 1.0000e-04\n",
      "Epoch 38/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1030 - acc: 0.5997\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 38: val_acc did not improve from 0.43669\n",
      "268/268 [==============================] - 81s 301ms/step - loss: 1.1030 - acc: 0.5997 - val_loss: 1.8635 - val_acc: 0.4307 - lr: 1.0000e-04\n",
      "Epoch 39/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0766 - acc: 0.6102\n",
      "Epoch 39: val_acc did not improve from 0.43669\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 1.0766 - acc: 0.6102 - val_loss: 1.8749 - val_acc: 0.4297 - lr: 1.0000e-05\n",
      "Epoch 40/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0686 - acc: 0.6178\n",
      "Epoch 40: val_acc did not improve from 0.43669\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 1.0686 - acc: 0.6178 - val_loss: 1.8759 - val_acc: 0.4337 - lr: 1.0000e-05\n",
      "Epoch 41/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0780 - acc: 0.6103\n",
      "Epoch 41: val_acc did not improve from 0.43669\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 1.0780 - acc: 0.6103 - val_loss: 1.8694 - val_acc: 0.4322 - lr: 1.0000e-05\n",
      "Epoch 42/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0644 - acc: 0.6114\n",
      "Epoch 42: val_acc did not improve from 0.43669\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 1.0644 - acc: 0.6114 - val_loss: 1.8748 - val_acc: 0.4327 - lr: 1.0000e-05\n",
      "Epoch 42: early stopping\n",
      "\n",
      "Running model with seed 123\n",
      "Train Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 2729, NLoS samples count: 109\n",
      "scenario33 - LoS samples count: 3322, NLoS samples count: 119\n",
      "scenario34 - LoS samples count: 3652, NLoS samples count: 97\n",
      "\n",
      "Test Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 265, NLoS samples count: 12\n",
      "scenario33 - LoS samples count: 379, NLoS samples count: 17\n",
      "scenario34 - LoS samples count: 430, NLoS samples count: 12\n",
      "LoS Train Shape: (9703, 5, 150, 150, 3), LoS Test Shape: (1074, 5, 150, 150, 3)\n",
      "NLoS Train Shape: (325, 5, 150, 150, 3), NLoS Test Shape: (41, 5, 150, 150, 3)\n",
      "Train Labels Shape: (10028, 64)\n",
      "Test Labels Shape: (1115, 64)\n",
      "Train LoS Labels Shape: (9703, 64)\n",
      "Train NLoS Labels Shape: (325, 64)\n",
      "Test LoS Labels Shape: (1074, 64)\n",
      "Test NLoS Labels Shape: (41, 64)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_1 (TimeDis  (None, 5, 256)           341040    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 64)                61824     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 411,184\n",
      "Trainable params: 410,576\n",
      "Non-trainable params: 608\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.8189 - acc: 0.0990\n",
      "Epoch 1: val_acc improved from -inf to 0.12313, saving model to chkp/LVR_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 86s 312ms/step - loss: 3.8189 - acc: 0.0990 - val_loss: 3.5423 - val_acc: 0.1231 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.4432 - acc: 0.1255\n",
      "Epoch 2: val_acc improved from 0.12313 to 0.16301, saving model to chkp/LVR_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 3.4432 - acc: 0.1255 - val_loss: 3.2159 - val_acc: 0.1630 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.1371 - acc: 0.1581\n",
      "Epoch 3: val_acc improved from 0.16301 to 0.20788, saving model to chkp/LVR_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 3.1371 - acc: 0.1581 - val_loss: 2.9054 - val_acc: 0.2079 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.8548 - acc: 0.2064\n",
      "Epoch 4: val_acc improved from 0.20788 to 0.22283, saving model to chkp/LVR_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 2.8548 - acc: 0.2064 - val_loss: 2.7777 - val_acc: 0.2228 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.6090 - acc: 0.2473\n",
      "Epoch 5: val_acc improved from 0.22283 to 0.29761, saving model to chkp/LVR_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 2.6090 - acc: 0.2473 - val_loss: 2.3835 - val_acc: 0.2976 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.4067 - acc: 0.2794\n",
      "Epoch 6: val_acc improved from 0.29761 to 0.30010, saving model to chkp/LVR_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 81s 302ms/step - loss: 2.4067 - acc: 0.2794 - val_loss: 2.2491 - val_acc: 0.3001 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.2707 - acc: 0.3084\n",
      "Epoch 7: val_acc improved from 0.30010 to 0.32253, saving model to chkp/LVR_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 81s 301ms/step - loss: 2.2707 - acc: 0.3084 - val_loss: 2.1199 - val_acc: 0.3225 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.1616 - acc: 0.3303\n",
      "Epoch 8: val_acc improved from 0.32253 to 0.34247, saving model to chkp/LVR_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 80s 300ms/step - loss: 2.1616 - acc: 0.3303 - val_loss: 2.0875 - val_acc: 0.3425 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.0379 - acc: 0.3561\n",
      "Epoch 9: val_acc improved from 0.34247 to 0.34297, saving model to chkp/LVR_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 2.0379 - acc: 0.3561 - val_loss: 2.0590 - val_acc: 0.3430 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.9784 - acc: 0.3736\n",
      "Epoch 10: val_acc improved from 0.34297 to 0.36540, saving model to chkp/LVR_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.9784 - acc: 0.3736 - val_loss: 1.9331 - val_acc: 0.3654 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.9201 - acc: 0.3886\n",
      "Epoch 11: val_acc improved from 0.36540 to 0.38086, saving model to chkp/LVR_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.9201 - acc: 0.3886 - val_loss: 1.9323 - val_acc: 0.3809 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8515 - acc: 0.3984\n",
      "Epoch 12: val_acc improved from 0.38086 to 0.38335, saving model to chkp/LVR_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.8515 - acc: 0.3984 - val_loss: 1.9007 - val_acc: 0.3833 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8038 - acc: 0.4059\n",
      "Epoch 13: val_acc improved from 0.38335 to 0.39482, saving model to chkp/LVR_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.8038 - acc: 0.4059 - val_loss: 1.8378 - val_acc: 0.3948 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7508 - acc: 0.4182\n",
      "Epoch 14: val_acc improved from 0.39482 to 0.39880, saving model to chkp/LVR_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.7508 - acc: 0.4182 - val_loss: 1.8213 - val_acc: 0.3988 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7045 - acc: 0.4326\n",
      "Epoch 15: val_acc improved from 0.39880 to 0.41725, saving model to chkp/LVR_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.7045 - acc: 0.4326 - val_loss: 1.7945 - val_acc: 0.4172 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6768 - acc: 0.4317\n",
      "Epoch 16: val_acc did not improve from 0.41725\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.6768 - acc: 0.4317 - val_loss: 1.8017 - val_acc: 0.4118 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6524 - acc: 0.4377\n",
      "Epoch 17: val_acc did not improve from 0.41725\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.6524 - acc: 0.4377 - val_loss: 1.8135 - val_acc: 0.4078 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6184 - acc: 0.4474\n",
      "Epoch 18: val_acc did not improve from 0.41725\n",
      "268/268 [==============================] - 80s 299ms/step - loss: 1.6184 - acc: 0.4474 - val_loss: 1.7935 - val_acc: 0.4123 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5996 - acc: 0.4516\n",
      "Epoch 19: val_acc did not improve from 0.41725\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.5996 - acc: 0.4516 - val_loss: 1.7848 - val_acc: 0.4013 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5504 - acc: 0.4665\n",
      "Epoch 20: val_acc did not improve from 0.41725\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.5504 - acc: 0.4665 - val_loss: 1.7867 - val_acc: 0.4103 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5225 - acc: 0.4746\n",
      "Epoch 21: val_acc improved from 0.41725 to 0.42423, saving model to chkp/LVR_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.5225 - acc: 0.4746 - val_loss: 1.8111 - val_acc: 0.4242 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5080 - acc: 0.4758\n",
      "Epoch 22: val_acc did not improve from 0.42423\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.5080 - acc: 0.4758 - val_loss: 1.8491 - val_acc: 0.3973 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5001 - acc: 0.4793\n",
      "Epoch 23: val_acc did not improve from 0.42423\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.5001 - acc: 0.4793 - val_loss: 1.8536 - val_acc: 0.4103 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4670 - acc: 0.4874\n",
      "Epoch 24: val_acc improved from 0.42423 to 0.43320, saving model to chkp/LVR_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.4670 - acc: 0.4874 - val_loss: 1.7898 - val_acc: 0.4332 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4464 - acc: 0.4903\n",
      "Epoch 25: val_acc did not improve from 0.43320\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.4464 - acc: 0.4903 - val_loss: 1.8049 - val_acc: 0.4292 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4138 - acc: 0.5024\n",
      "Epoch 26: val_acc did not improve from 0.43320\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.4138 - acc: 0.5024 - val_loss: 1.8118 - val_acc: 0.4187 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4132 - acc: 0.5027\n",
      "Epoch 27: val_acc did not improve from 0.43320\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.4132 - acc: 0.5027 - val_loss: 1.7827 - val_acc: 0.4227 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3837 - acc: 0.4985\n",
      "Epoch 28: val_acc did not improve from 0.43320\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.3837 - acc: 0.4985 - val_loss: 2.4720 - val_acc: 0.3729 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3694 - acc: 0.5140\n",
      "Epoch 29: val_acc did not improve from 0.43320\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.3694 - acc: 0.5140 - val_loss: 1.8195 - val_acc: 0.4202 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3442 - acc: 0.5140\n",
      "Epoch 30: val_acc improved from 0.43320 to 0.43719, saving model to chkp/LVR_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.3442 - acc: 0.5140 - val_loss: 1.8307 - val_acc: 0.4372 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3090 - acc: 0.5167\n",
      "Epoch 31: val_acc improved from 0.43719 to 0.45115, saving model to chkp/LVR_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.3090 - acc: 0.5167 - val_loss: 1.8565 - val_acc: 0.4511 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3149 - acc: 0.5262\n",
      "Epoch 32: val_acc did not improve from 0.45115\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.3149 - acc: 0.5262 - val_loss: 1.8861 - val_acc: 0.4247 - lr: 0.0010\n",
      "Epoch 33/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2921 - acc: 0.5293\n",
      "Epoch 33: val_acc did not improve from 0.45115\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.2921 - acc: 0.5293 - val_loss: 1.8495 - val_acc: 0.4153 - lr: 0.0010\n",
      "Epoch 34/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2795 - acc: 0.5340\n",
      "Epoch 34: val_acc did not improve from 0.45115\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.2795 - acc: 0.5340 - val_loss: 1.8942 - val_acc: 0.4392 - lr: 0.0010\n",
      "Epoch 35/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2608 - acc: 0.5454\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 35: val_acc did not improve from 0.45115\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.2608 - acc: 0.5454 - val_loss: 1.9358 - val_acc: 0.4257 - lr: 0.0010\n",
      "Epoch 36/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1458 - acc: 0.5848\n",
      "Epoch 36: val_acc did not improve from 0.45115\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.1458 - acc: 0.5848 - val_loss: 1.8704 - val_acc: 0.4487 - lr: 1.0000e-04\n",
      "Epoch 37/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0890 - acc: 0.5960\n",
      "Epoch 37: val_acc improved from 0.45115 to 0.45264, saving model to chkp/LVR_remake_v1_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.0890 - acc: 0.5960 - val_loss: 1.8951 - val_acc: 0.4526 - lr: 1.0000e-04\n",
      "Epoch 38/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0613 - acc: 0.6076\n",
      "Epoch 38: val_acc did not improve from 0.45264\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.0613 - acc: 0.6076 - val_loss: 1.9043 - val_acc: 0.4487 - lr: 1.0000e-04\n",
      "Epoch 39/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0241 - acc: 0.6238\n",
      "Epoch 39: val_acc did not improve from 0.45264\n",
      "268/268 [==============================] - 79s 296ms/step - loss: 1.0241 - acc: 0.6238 - val_loss: 1.9330 - val_acc: 0.4467 - lr: 1.0000e-04\n",
      "Epoch 40/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0250 - acc: 0.6202\n",
      "Epoch 40: val_acc did not improve from 0.45264\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.0250 - acc: 0.6202 - val_loss: 1.9481 - val_acc: 0.4482 - lr: 1.0000e-04\n",
      "Epoch 41/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 0.9951 - acc: 0.6340\n",
      "Epoch 41: val_acc did not improve from 0.45264\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 0.9951 - acc: 0.6340 - val_loss: 1.9607 - val_acc: 0.4472 - lr: 1.0000e-04\n",
      "Epoch 42/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 0.9854 - acc: 0.6402\n",
      "Epoch 42: val_acc did not improve from 0.45264\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 0.9854 - acc: 0.6402 - val_loss: 1.9717 - val_acc: 0.4457 - lr: 1.0000e-04\n",
      "Epoch 43/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 0.9607 - acc: 0.6532\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 43: val_acc did not improve from 0.45264\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 0.9607 - acc: 0.6532 - val_loss: 1.9985 - val_acc: 0.4506 - lr: 1.0000e-04\n",
      "Epoch 44/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 0.9464 - acc: 0.6566\n",
      "Epoch 44: val_acc did not improve from 0.45264\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 0.9464 - acc: 0.6566 - val_loss: 1.9861 - val_acc: 0.4497 - lr: 1.0000e-05\n",
      "Epoch 45/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 0.9396 - acc: 0.6613\n",
      "Epoch 45: val_acc did not improve from 0.45264\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 0.9396 - acc: 0.6613 - val_loss: 2.0012 - val_acc: 0.4506 - lr: 1.0000e-05\n",
      "Epoch 46/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 0.9473 - acc: 0.6579\n",
      "Epoch 46: val_acc did not improve from 0.45264\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 0.9473 - acc: 0.6579 - val_loss: 2.0049 - val_acc: 0.4516 - lr: 1.0000e-05\n",
      "Epoch 47/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 0.9369 - acc: 0.6693\n",
      "Epoch 47: val_acc did not improve from 0.45264\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 0.9369 - acc: 0.6693 - val_loss: 2.0077 - val_acc: 0.4521 - lr: 1.0000e-05\n",
      "Epoch 47: early stopping\n",
      "\n",
      "Running model with seed 456\n",
      "Train Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 2711, NLoS samples count: 107\n",
      "scenario33 - LoS samples count: 3317, NLoS samples count: 121\n",
      "scenario34 - LoS samples count: 3676, NLoS samples count: 96\n",
      "\n",
      "Test Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 283, NLoS samples count: 14\n",
      "scenario33 - LoS samples count: 384, NLoS samples count: 15\n",
      "scenario34 - LoS samples count: 406, NLoS samples count: 13\n",
      "LoS Train Shape: (9704, 5, 150, 150, 3), LoS Test Shape: (1073, 5, 150, 150, 3)\n",
      "NLoS Train Shape: (324, 5, 150, 150, 3), NLoS Test Shape: (42, 5, 150, 150, 3)\n",
      "Train Labels Shape: (10028, 64)\n",
      "Test Labels Shape: (1115, 64)\n",
      "Train LoS Labels Shape: (9704, 64)\n",
      "Train NLoS Labels Shape: (324, 64)\n",
      "Test LoS Labels Shape: (1073, 64)\n",
      "Test NLoS Labels Shape: (42, 64)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_2 (TimeDis  (None, 5, 256)           341040    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 64)                61824     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 411,184\n",
      "Trainable params: 410,576\n",
      "Non-trainable params: 608\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.8011 - acc: 0.1090\n",
      "Epoch 1: val_acc improved from -inf to 0.14257, saving model to chkp/LVR_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 86s 310ms/step - loss: 3.8011 - acc: 0.1090 - val_loss: 3.4368 - val_acc: 0.1426 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.3642 - acc: 0.1457\n",
      "Epoch 2: val_acc improved from 0.14257 to 0.19641, saving model to chkp/LVR_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 80s 299ms/step - loss: 3.3642 - acc: 0.1457 - val_loss: 2.9853 - val_acc: 0.1964 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.0103 - acc: 0.1880\n",
      "Epoch 3: val_acc improved from 0.19641 to 0.22383, saving model to chkp/LVR_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 80s 299ms/step - loss: 3.0103 - acc: 0.1880 - val_loss: 2.7627 - val_acc: 0.2238 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.7542 - acc: 0.2295\n",
      "Epoch 4: val_acc improved from 0.22383 to 0.26919, saving model to chkp/LVR_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 2.7542 - acc: 0.2295 - val_loss: 2.4895 - val_acc: 0.2692 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.5396 - acc: 0.2635\n",
      "Epoch 5: val_acc improved from 0.26919 to 0.30957, saving model to chkp/LVR_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 2.5396 - acc: 0.2635 - val_loss: 2.2713 - val_acc: 0.3096 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.3637 - acc: 0.2966\n",
      "Epoch 6: val_acc improved from 0.30957 to 0.32652, saving model to chkp/LVR_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 2.3637 - acc: 0.2966 - val_loss: 2.1056 - val_acc: 0.3265 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.2087 - acc: 0.3241\n",
      "Epoch 7: val_acc did not improve from 0.32652\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 2.2087 - acc: 0.3241 - val_loss: 2.0684 - val_acc: 0.3220 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.0992 - acc: 0.3538\n",
      "Epoch 8: val_acc improved from 0.32652 to 0.37338, saving model to chkp/LVR_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 2.0992 - acc: 0.3538 - val_loss: 1.8955 - val_acc: 0.3734 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.9917 - acc: 0.3691\n",
      "Epoch 9: val_acc did not improve from 0.37338\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.9917 - acc: 0.3691 - val_loss: 1.9381 - val_acc: 0.3679 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.9248 - acc: 0.3807\n",
      "Epoch 10: val_acc improved from 0.37338 to 0.38933, saving model to chkp/LVR_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.9248 - acc: 0.3807 - val_loss: 1.8211 - val_acc: 0.3893 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8687 - acc: 0.3912\n",
      "Epoch 11: val_acc did not improve from 0.38933\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.8687 - acc: 0.3912 - val_loss: 1.7650 - val_acc: 0.3863 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7924 - acc: 0.4099\n",
      "Epoch 12: val_acc improved from 0.38933 to 0.39432, saving model to chkp/LVR_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.7924 - acc: 0.4099 - val_loss: 1.7374 - val_acc: 0.3943 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7427 - acc: 0.4192\n",
      "Epoch 13: val_acc improved from 0.39432 to 0.42223, saving model to chkp/LVR_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.7427 - acc: 0.4192 - val_loss: 1.7156 - val_acc: 0.4222 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7105 - acc: 0.4216\n",
      "Epoch 14: val_acc did not improve from 0.42223\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.7105 - acc: 0.4216 - val_loss: 1.7195 - val_acc: 0.4167 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6582 - acc: 0.4365\n",
      "Epoch 15: val_acc did not improve from 0.42223\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.6582 - acc: 0.4365 - val_loss: 1.6807 - val_acc: 0.4217 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6222 - acc: 0.4484\n",
      "Epoch 16: val_acc did not improve from 0.42223\n",
      "268/268 [==============================] - 79s 296ms/step - loss: 1.6222 - acc: 0.4484 - val_loss: 1.6941 - val_acc: 0.4113 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6155 - acc: 0.4494\n",
      "Epoch 17: val_acc did not improve from 0.42223\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.6155 - acc: 0.4494 - val_loss: 1.7043 - val_acc: 0.4182 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6051 - acc: 0.4535\n",
      "Epoch 18: val_acc did not improve from 0.42223\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.6051 - acc: 0.4535 - val_loss: 1.7389 - val_acc: 0.3968 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5495 - acc: 0.4638\n",
      "Epoch 19: val_acc did not improve from 0.42223\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.5495 - acc: 0.4638 - val_loss: 1.6590 - val_acc: 0.4158 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5526 - acc: 0.4585\n",
      "Epoch 20: val_acc did not improve from 0.42223\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.5526 - acc: 0.4585 - val_loss: 1.6700 - val_acc: 0.4163 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5132 - acc: 0.4748\n",
      "Epoch 21: val_acc improved from 0.42223 to 0.42772, saving model to chkp/LVR_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.5132 - acc: 0.4748 - val_loss: 1.6910 - val_acc: 0.4277 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4710 - acc: 0.4858\n",
      "Epoch 22: val_acc improved from 0.42772 to 0.44267, saving model to chkp/LVR_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.4710 - acc: 0.4858 - val_loss: 1.6872 - val_acc: 0.4427 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4583 - acc: 0.4859\n",
      "Epoch 23: val_acc did not improve from 0.44267\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.4583 - acc: 0.4859 - val_loss: 1.7728 - val_acc: 0.4133 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4522 - acc: 0.4838\n",
      "Epoch 24: val_acc did not improve from 0.44267\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.4522 - acc: 0.4838 - val_loss: 1.6832 - val_acc: 0.4267 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4138 - acc: 0.4989\n",
      "Epoch 25: val_acc improved from 0.44267 to 0.44766, saving model to chkp/LVR_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 79s 297ms/step - loss: 1.4138 - acc: 0.4989 - val_loss: 1.6878 - val_acc: 0.4477 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3930 - acc: 0.4964\n",
      "Epoch 26: val_acc did not improve from 0.44766\n",
      "268/268 [==============================] - 79s 297ms/step - loss: 1.3930 - acc: 0.4964 - val_loss: 1.6887 - val_acc: 0.4317 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3624 - acc: 0.5126\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 27: val_acc did not improve from 0.44766\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.3624 - acc: 0.5126 - val_loss: 1.6816 - val_acc: 0.4312 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2496 - acc: 0.5510\n",
      "Epoch 28: val_acc did not improve from 0.44766\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.2496 - acc: 0.5510 - val_loss: 1.6456 - val_acc: 0.4477 - lr: 1.0000e-04\n",
      "Epoch 29/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1932 - acc: 0.5677\n",
      "Epoch 29: val_acc did not improve from 0.44766\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.1932 - acc: 0.5677 - val_loss: 1.6549 - val_acc: 0.4477 - lr: 1.0000e-04\n",
      "Epoch 30/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1626 - acc: 0.5764\n",
      "Epoch 30: val_acc improved from 0.44766 to 0.45314, saving model to chkp/LVR_remake_v1_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.1626 - acc: 0.5764 - val_loss: 1.6605 - val_acc: 0.4531 - lr: 1.0000e-04\n",
      "Epoch 31/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1463 - acc: 0.5866\n",
      "Epoch 31: val_acc did not improve from 0.45314\n",
      "268/268 [==============================] - 79s 297ms/step - loss: 1.1463 - acc: 0.5866 - val_loss: 1.6796 - val_acc: 0.4417 - lr: 1.0000e-04\n",
      "Epoch 32/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1209 - acc: 0.5920\n",
      "Epoch 32: val_acc did not improve from 0.45314\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.1209 - acc: 0.5920 - val_loss: 1.6901 - val_acc: 0.4472 - lr: 1.0000e-04\n",
      "Epoch 33/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1122 - acc: 0.6022\n",
      "Epoch 33: val_acc did not improve from 0.45314\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.1122 - acc: 0.6022 - val_loss: 1.6980 - val_acc: 0.4506 - lr: 1.0000e-04\n",
      "Epoch 34/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0889 - acc: 0.6063\n",
      "Epoch 34: val_acc did not improve from 0.45314\n",
      "268/268 [==============================] - 79s 297ms/step - loss: 1.0889 - acc: 0.6063 - val_loss: 1.7082 - val_acc: 0.4427 - lr: 1.0000e-04\n",
      "Epoch 35/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0818 - acc: 0.6013\n",
      "Epoch 35: val_acc did not improve from 0.45314\n",
      "268/268 [==============================] - 79s 297ms/step - loss: 1.0818 - acc: 0.6013 - val_loss: 1.7226 - val_acc: 0.4472 - lr: 1.0000e-04\n",
      "Epoch 36/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0717 - acc: 0.6116\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 36: val_acc did not improve from 0.45314\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.0717 - acc: 0.6116 - val_loss: 1.7279 - val_acc: 0.4531 - lr: 1.0000e-04\n",
      "Epoch 37/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0425 - acc: 0.6310\n",
      "Epoch 37: val_acc did not improve from 0.45314\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.0425 - acc: 0.6310 - val_loss: 1.7285 - val_acc: 0.4506 - lr: 1.0000e-05\n",
      "Epoch 38/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0354 - acc: 0.6314\n",
      "Epoch 38: val_acc did not improve from 0.45314\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.0354 - acc: 0.6314 - val_loss: 1.7265 - val_acc: 0.4472 - lr: 1.0000e-05\n",
      "Epoch 39/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0493 - acc: 0.6262\n",
      "Epoch 39: val_acc did not improve from 0.45314\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.0493 - acc: 0.6262 - val_loss: 1.7273 - val_acc: 0.4487 - lr: 1.0000e-05\n",
      "Epoch 40/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0314 - acc: 0.6321\n",
      "Epoch 40: val_acc did not improve from 0.45314\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.0314 - acc: 0.6321 - val_loss: 1.7300 - val_acc: 0.4526 - lr: 1.0000e-05\n",
      "Epoch 41/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0284 - acc: 0.6269\n",
      "Epoch 41: val_acc did not improve from 0.45314\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.0284 - acc: 0.6269 - val_loss: 1.7273 - val_acc: 0.4501 - lr: 1.0000e-05\n",
      "Epoch 42/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0305 - acc: 0.6253\n",
      "Epoch 42: val_acc did not improve from 0.45314\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.0305 - acc: 0.6253 - val_loss: 1.7298 - val_acc: 0.4467 - lr: 1.0000e-05\n",
      "Epoch 43/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0272 - acc: 0.6374\n",
      "Epoch 43: val_acc did not improve from 0.45314\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.0272 - acc: 0.6374 - val_loss: 1.7353 - val_acc: 0.4501 - lr: 1.0000e-05\n",
      "Epoch 44/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0261 - acc: 0.6260\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 44: val_acc did not improve from 0.45314\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.0261 - acc: 0.6260 - val_loss: 1.7395 - val_acc: 0.4497 - lr: 1.0000e-05\n",
      "Epoch 45/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0257 - acc: 0.6321\n",
      "Epoch 45: val_acc did not improve from 0.45314\n",
      "268/268 [==============================] - 79s 297ms/step - loss: 1.0257 - acc: 0.6321 - val_loss: 1.7395 - val_acc: 0.4452 - lr: 1.0000e-06\n",
      "Epoch 46/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0233 - acc: 0.6323\n",
      "Epoch 46: val_acc did not improve from 0.45314\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.0233 - acc: 0.6323 - val_loss: 1.7343 - val_acc: 0.4492 - lr: 1.0000e-06\n",
      "Epoch 47/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0329 - acc: 0.6245\n",
      "Epoch 47: val_acc did not improve from 0.45314\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.0329 - acc: 0.6245 - val_loss: 1.7404 - val_acc: 0.4467 - lr: 1.0000e-06\n",
      "Epoch 48/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0234 - acc: 0.6273\n",
      "Epoch 48: val_acc did not improve from 0.45314\n",
      "268/268 [==============================] - 80s 299ms/step - loss: 1.0234 - acc: 0.6273 - val_loss: 1.7371 - val_acc: 0.4497 - lr: 1.0000e-06\n",
      "Epoch 48: early stopping\n",
      "\n",
      "Running model with seed 789\n",
      "Train Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 2706, NLoS samples count: 105\n",
      "scenario33 - LoS samples count: 3343, NLoS samples count: 126\n",
      "scenario34 - LoS samples count: 3652, NLoS samples count: 96\n",
      "\n",
      "Test Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 288, NLoS samples count: 16\n",
      "scenario33 - LoS samples count: 358, NLoS samples count: 10\n",
      "scenario34 - LoS samples count: 430, NLoS samples count: 13\n",
      "LoS Train Shape: (9701, 5, 150, 150, 3), LoS Test Shape: (1076, 5, 150, 150, 3)\n",
      "NLoS Train Shape: (327, 5, 150, 150, 3), NLoS Test Shape: (39, 5, 150, 150, 3)\n",
      "Train Labels Shape: (10028, 64)\n",
      "Test Labels Shape: (1115, 64)\n",
      "Train LoS Labels Shape: (9701, 64)\n",
      "Train NLoS Labels Shape: (327, 64)\n",
      "Test LoS Labels Shape: (1076, 64)\n",
      "Test NLoS Labels Shape: (39, 64)\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_3 (TimeDis  (None, 5, 256)           341040    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 64)                61824     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 411,184\n",
      "Trainable params: 410,576\n",
      "Non-trainable params: 608\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.8484 - acc: 0.0901\n",
      "Epoch 1: val_acc improved from -inf to 0.13410, saving model to chkp/LVR_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 86s 310ms/step - loss: 3.8484 - acc: 0.0901 - val_loss: 3.5222 - val_acc: 0.1341 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.4874 - acc: 0.1220\n",
      "Epoch 2: val_acc improved from 0.13410 to 0.18594, saving model to chkp/LVR_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 3.4874 - acc: 0.1220 - val_loss: 3.1611 - val_acc: 0.1859 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.1575 - acc: 0.1639\n",
      "Epoch 3: val_acc improved from 0.18594 to 0.20239, saving model to chkp/LVR_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 3.1575 - acc: 0.1639 - val_loss: 2.8337 - val_acc: 0.2024 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.8552 - acc: 0.2018\n",
      "Epoch 4: val_acc improved from 0.20239 to 0.26720, saving model to chkp/LVR_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 2.8552 - acc: 0.2018 - val_loss: 2.5541 - val_acc: 0.2672 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.6127 - acc: 0.2436\n",
      "Epoch 5: val_acc improved from 0.26720 to 0.28016, saving model to chkp/LVR_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 2.6127 - acc: 0.2436 - val_loss: 2.4161 - val_acc: 0.2802 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.4555 - acc: 0.2774\n",
      "Epoch 6: val_acc improved from 0.28016 to 0.29511, saving model to chkp/LVR_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 2.4555 - acc: 0.2774 - val_loss: 2.3128 - val_acc: 0.2951 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.3416 - acc: 0.2987\n",
      "Epoch 7: val_acc improved from 0.29511 to 0.30160, saving model to chkp/LVR_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 80s 299ms/step - loss: 2.3416 - acc: 0.2987 - val_loss: 2.3179 - val_acc: 0.3016 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.1784 - acc: 0.3210\n",
      "Epoch 8: val_acc improved from 0.30160 to 0.34945, saving model to chkp/LVR_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 2.1784 - acc: 0.3210 - val_loss: 2.0787 - val_acc: 0.3495 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.1003 - acc: 0.3442\n",
      "Epoch 9: val_acc improved from 0.34945 to 0.36889, saving model to chkp/LVR_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 2.1003 - acc: 0.3442 - val_loss: 1.9483 - val_acc: 0.3689 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.0299 - acc: 0.3573\n",
      "Epoch 10: val_acc did not improve from 0.36889\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 2.0299 - acc: 0.3573 - val_loss: 1.9788 - val_acc: 0.3569 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.9480 - acc: 0.3748\n",
      "Epoch 11: val_acc improved from 0.36889 to 0.38534, saving model to chkp/LVR_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.9480 - acc: 0.3748 - val_loss: 1.8982 - val_acc: 0.3853 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8935 - acc: 0.3881\n",
      "Epoch 12: val_acc improved from 0.38534 to 0.39880, saving model to chkp/LVR_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.8935 - acc: 0.3881 - val_loss: 1.8310 - val_acc: 0.3988 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8474 - acc: 0.3949\n",
      "Epoch 13: val_acc did not improve from 0.39880\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.8474 - acc: 0.3949 - val_loss: 2.4818 - val_acc: 0.3166 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8156 - acc: 0.3987\n",
      "Epoch 14: val_acc did not improve from 0.39880\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.8156 - acc: 0.3987 - val_loss: 2.7120 - val_acc: 0.3056 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7661 - acc: 0.4086\n",
      "Epoch 15: val_acc improved from 0.39880 to 0.42074, saving model to chkp/LVR_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.7661 - acc: 0.4086 - val_loss: 1.7486 - val_acc: 0.4207 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7426 - acc: 0.4248\n",
      "Epoch 16: val_acc did not improve from 0.42074\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.7426 - acc: 0.4248 - val_loss: 3.3586 - val_acc: 0.2238 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7030 - acc: 0.4289\n",
      "Epoch 17: val_acc did not improve from 0.42074\n",
      "268/268 [==============================] - 80s 299ms/step - loss: 1.7030 - acc: 0.4289 - val_loss: 2.0837 - val_acc: 0.3729 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6619 - acc: 0.4405\n",
      "Epoch 18: val_acc did not improve from 0.42074\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.6619 - acc: 0.4405 - val_loss: 1.7398 - val_acc: 0.4123 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6238 - acc: 0.4514\n",
      "Epoch 19: val_acc did not improve from 0.42074\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.6238 - acc: 0.4514 - val_loss: 1.8425 - val_acc: 0.3983 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6151 - acc: 0.4534\n",
      "Epoch 20: val_acc did not improve from 0.42074\n",
      "268/268 [==============================] - 80s 299ms/step - loss: 1.6151 - acc: 0.4534 - val_loss: 1.7794 - val_acc: 0.4038 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5887 - acc: 0.4584\n",
      "Epoch 21: val_acc improved from 0.42074 to 0.42423, saving model to chkp/LVR_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.5887 - acc: 0.4584 - val_loss: 1.7509 - val_acc: 0.4242 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5753 - acc: 0.4602\n",
      "Epoch 22: val_acc did not improve from 0.42423\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.5753 - acc: 0.4602 - val_loss: 1.7104 - val_acc: 0.4227 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5373 - acc: 0.4700\n",
      "Epoch 23: val_acc did not improve from 0.42423\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.5373 - acc: 0.4700 - val_loss: 1.7631 - val_acc: 0.4083 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5143 - acc: 0.4737\n",
      "Epoch 24: val_acc did not improve from 0.42423\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.5143 - acc: 0.4737 - val_loss: 1.7556 - val_acc: 0.4148 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5048 - acc: 0.4678\n",
      "Epoch 25: val_acc did not improve from 0.42423\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.5048 - acc: 0.4678 - val_loss: 4.1481 - val_acc: 0.2861 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4743 - acc: 0.4819\n",
      "Epoch 26: val_acc did not improve from 0.42423\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.4743 - acc: 0.4819 - val_loss: 2.2970 - val_acc: 0.3829 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4734 - acc: 0.4808\n",
      "Epoch 27: val_acc improved from 0.42423 to 0.42871, saving model to chkp/LVR_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.4734 - acc: 0.4808 - val_loss: 1.7400 - val_acc: 0.4287 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4587 - acc: 0.4948\n",
      "Epoch 28: val_acc did not improve from 0.42871\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.4587 - acc: 0.4948 - val_loss: 1.8081 - val_acc: 0.4078 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4178 - acc: 0.5017\n",
      "Epoch 29: val_acc improved from 0.42871 to 0.44018, saving model to chkp/LVR_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.4178 - acc: 0.5017 - val_loss: 1.7708 - val_acc: 0.4402 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3975 - acc: 0.4993\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 30: val_acc did not improve from 0.44018\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.3975 - acc: 0.4993 - val_loss: 1.7681 - val_acc: 0.4387 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2960 - acc: 0.5355\n",
      "Epoch 31: val_acc improved from 0.44018 to 0.45962, saving model to chkp/LVR_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.2960 - acc: 0.5355 - val_loss: 1.7053 - val_acc: 0.4596 - lr: 1.0000e-04\n",
      "Epoch 32/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2325 - acc: 0.5566\n",
      "Epoch 32: val_acc did not improve from 0.45962\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.2325 - acc: 0.5566 - val_loss: 1.7063 - val_acc: 0.4531 - lr: 1.0000e-04\n",
      "Epoch 33/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1932 - acc: 0.5696\n",
      "Epoch 33: val_acc did not improve from 0.45962\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.1932 - acc: 0.5696 - val_loss: 1.7212 - val_acc: 0.4561 - lr: 1.0000e-04\n",
      "Epoch 34/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1773 - acc: 0.5744\n",
      "Epoch 34: val_acc did not improve from 0.45962\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.1773 - acc: 0.5744 - val_loss: 1.7256 - val_acc: 0.4551 - lr: 1.0000e-04\n",
      "Epoch 35/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1537 - acc: 0.5836\n",
      "Epoch 35: val_acc did not improve from 0.45962\n",
      "268/268 [==============================] - 79s 297ms/step - loss: 1.1537 - acc: 0.5836 - val_loss: 1.7476 - val_acc: 0.4556 - lr: 1.0000e-04\n",
      "Epoch 36/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1419 - acc: 0.5917\n",
      "Epoch 36: val_acc did not improve from 0.45962\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.1419 - acc: 0.5917 - val_loss: 1.7597 - val_acc: 0.4581 - lr: 1.0000e-04\n",
      "Epoch 37/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1350 - acc: 0.5881\n",
      "Epoch 37: val_acc improved from 0.45962 to 0.46162, saving model to chkp/LVR_remake_v1_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 80s 299ms/step - loss: 1.1350 - acc: 0.5881 - val_loss: 1.7583 - val_acc: 0.4616 - lr: 1.0000e-04\n",
      "Epoch 38/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1178 - acc: 0.5942\n",
      "Epoch 38: val_acc did not improve from 0.46162\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.1178 - acc: 0.5942 - val_loss: 1.7701 - val_acc: 0.4596 - lr: 1.0000e-04\n",
      "Epoch 39/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1009 - acc: 0.5967\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 39: val_acc did not improve from 0.46162\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.1009 - acc: 0.5967 - val_loss: 1.7778 - val_acc: 0.4596 - lr: 1.0000e-04\n",
      "Epoch 40/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0855 - acc: 0.6167\n",
      "Epoch 40: val_acc did not improve from 0.46162\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.0855 - acc: 0.6167 - val_loss: 1.7857 - val_acc: 0.4591 - lr: 1.0000e-05\n",
      "Epoch 41/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0647 - acc: 0.6156\n",
      "Epoch 41: val_acc did not improve from 0.46162\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.0647 - acc: 0.6156 - val_loss: 1.7836 - val_acc: 0.4536 - lr: 1.0000e-05\n",
      "Epoch 42/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0786 - acc: 0.6132\n",
      "Epoch 42: val_acc did not improve from 0.46162\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.0786 - acc: 0.6132 - val_loss: 1.7880 - val_acc: 0.4591 - lr: 1.0000e-05\n",
      "Epoch 43/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0694 - acc: 0.6232\n",
      "Epoch 43: val_acc did not improve from 0.46162\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.0694 - acc: 0.6232 - val_loss: 1.7890 - val_acc: 0.4581 - lr: 1.0000e-05\n",
      "Epoch 44/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0796 - acc: 0.6133\n",
      "Epoch 44: val_acc did not improve from 0.46162\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.0796 - acc: 0.6133 - val_loss: 1.7856 - val_acc: 0.4546 - lr: 1.0000e-05\n",
      "Epoch 45/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0637 - acc: 0.6168\n",
      "Epoch 45: val_acc did not improve from 0.46162\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.0637 - acc: 0.6168 - val_loss: 1.7980 - val_acc: 0.4536 - lr: 1.0000e-05\n",
      "Epoch 46/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0760 - acc: 0.6118\n",
      "Epoch 46: val_acc did not improve from 0.46162\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.0760 - acc: 0.6118 - val_loss: 1.7901 - val_acc: 0.4616 - lr: 1.0000e-05\n",
      "Epoch 47/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0733 - acc: 0.6119\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 47: val_acc did not improve from 0.46162\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.0733 - acc: 0.6119 - val_loss: 1.7887 - val_acc: 0.4556 - lr: 1.0000e-05\n",
      "Epoch 48/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0647 - acc: 0.6156\n",
      "Epoch 48: val_acc did not improve from 0.46162\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.0647 - acc: 0.6156 - val_loss: 1.7964 - val_acc: 0.4536 - lr: 1.0000e-06\n",
      "Epoch 49/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0571 - acc: 0.6213\n",
      "Epoch 49: val_acc did not improve from 0.46162\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.0571 - acc: 0.6213 - val_loss: 1.7954 - val_acc: 0.4556 - lr: 1.0000e-06\n",
      "Epoch 50/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0667 - acc: 0.6154\n",
      "Epoch 50: val_acc did not improve from 0.46162\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.0667 - acc: 0.6154 - val_loss: 1.7951 - val_acc: 0.4576 - lr: 1.0000e-06\n",
      "Epoch 51/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0589 - acc: 0.6228\n",
      "Epoch 51: val_acc did not improve from 0.46162\n",
      "268/268 [==============================] - 79s 297ms/step - loss: 1.0589 - acc: 0.6228 - val_loss: 1.7945 - val_acc: 0.4541 - lr: 1.0000e-06\n",
      "Epoch 51: early stopping\n",
      "\n",
      "Running model with seed 101112\n",
      "Train Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 2692, NLoS samples count: 104\n",
      "scenario33 - LoS samples count: 3330, NLoS samples count: 120\n",
      "scenario34 - LoS samples count: 3684, NLoS samples count: 98\n",
      "\n",
      "Test Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 302, NLoS samples count: 17\n",
      "scenario33 - LoS samples count: 371, NLoS samples count: 16\n",
      "scenario34 - LoS samples count: 398, NLoS samples count: 11\n",
      "LoS Train Shape: (9706, 5, 150, 150, 3), LoS Test Shape: (1071, 5, 150, 150, 3)\n",
      "NLoS Train Shape: (322, 5, 150, 150, 3), NLoS Test Shape: (44, 5, 150, 150, 3)\n",
      "Train Labels Shape: (10028, 64)\n",
      "Test Labels Shape: (1115, 64)\n",
      "Train LoS Labels Shape: (9706, 64)\n",
      "Train NLoS Labels Shape: (322, 64)\n",
      "Test LoS Labels Shape: (1071, 64)\n",
      "Test NLoS Labels Shape: (44, 64)\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_4 (TimeDis  (None, 5, 256)           341040    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 64)                61824     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 411,184\n",
      "Trainable params: 410,576\n",
      "Non-trainable params: 608\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.7855 - acc: 0.0972\n",
      "Epoch 1: val_acc improved from -inf to 0.12463, saving model to chkp/LVR_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 85s 309ms/step - loss: 3.7855 - acc: 0.0972 - val_loss: 3.5197 - val_acc: 0.1246 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.3519 - acc: 0.1410\n",
      "Epoch 2: val_acc improved from 0.12463 to 0.16600, saving model to chkp/LVR_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 3.3519 - acc: 0.1410 - val_loss: 3.0537 - val_acc: 0.1660 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.0468 - acc: 0.1799\n",
      "Epoch 3: val_acc improved from 0.16600 to 0.21535, saving model to chkp/LVR_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 79s 296ms/step - loss: 3.0468 - acc: 0.1799 - val_loss: 2.8046 - val_acc: 0.2154 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.7708 - acc: 0.2155\n",
      "Epoch 4: val_acc improved from 0.21535 to 0.25274, saving model to chkp/LVR_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 2.7708 - acc: 0.2155 - val_loss: 2.5992 - val_acc: 0.2527 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.5802 - acc: 0.2461\n",
      "Epoch 5: val_acc improved from 0.25274 to 0.28814, saving model to chkp/LVR_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 2.5802 - acc: 0.2461 - val_loss: 2.3762 - val_acc: 0.2881 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.4148 - acc: 0.2791\n",
      "Epoch 6: val_acc did not improve from 0.28814\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 2.4148 - acc: 0.2791 - val_loss: 2.3160 - val_acc: 0.2861 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.2830 - acc: 0.2983\n",
      "Epoch 7: val_acc improved from 0.28814 to 0.32602, saving model to chkp/LVR_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 2.2830 - acc: 0.2983 - val_loss: 2.1397 - val_acc: 0.3260 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.1866 - acc: 0.3131\n",
      "Epoch 8: val_acc improved from 0.32602 to 0.34546, saving model to chkp/LVR_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 2.1866 - acc: 0.3131 - val_loss: 2.1087 - val_acc: 0.3455 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.0955 - acc: 0.3428\n",
      "Epoch 9: val_acc did not improve from 0.34546\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 2.0955 - acc: 0.3428 - val_loss: 2.0991 - val_acc: 0.3335 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.0115 - acc: 0.3570\n",
      "Epoch 10: val_acc improved from 0.34546 to 0.35693, saving model to chkp/LVR_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 2.0115 - acc: 0.3570 - val_loss: 2.0161 - val_acc: 0.3569 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.9483 - acc: 0.3667\n",
      "Epoch 11: val_acc improved from 0.35693 to 0.36790, saving model to chkp/LVR_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.9483 - acc: 0.3667 - val_loss: 1.9425 - val_acc: 0.3679 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8969 - acc: 0.3906\n",
      "Epoch 12: val_acc improved from 0.36790 to 0.39332, saving model to chkp/LVR_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.8969 - acc: 0.3906 - val_loss: 1.9014 - val_acc: 0.3933 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8458 - acc: 0.3988\n",
      "Epoch 13: val_acc did not improve from 0.39332\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.8458 - acc: 0.3988 - val_loss: 1.9388 - val_acc: 0.3794 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7784 - acc: 0.4090\n",
      "Epoch 14: val_acc did not improve from 0.39332\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.7784 - acc: 0.4090 - val_loss: 1.8837 - val_acc: 0.3739 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7533 - acc: 0.4176\n",
      "Epoch 15: val_acc did not improve from 0.39332\n",
      "268/268 [==============================] - 79s 296ms/step - loss: 1.7533 - acc: 0.4176 - val_loss: 1.8522 - val_acc: 0.3878 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7354 - acc: 0.4200\n",
      "Epoch 16: val_acc improved from 0.39332 to 0.40927, saving model to chkp/LVR_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.7354 - acc: 0.4200 - val_loss: 1.8682 - val_acc: 0.4093 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7012 - acc: 0.4250\n",
      "Epoch 17: val_acc improved from 0.40927 to 0.41326, saving model to chkp/LVR_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.7012 - acc: 0.4250 - val_loss: 1.8205 - val_acc: 0.4133 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6567 - acc: 0.4449\n",
      "Epoch 18: val_acc did not improve from 0.41326\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.6567 - acc: 0.4449 - val_loss: 1.8038 - val_acc: 0.4128 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6436 - acc: 0.4351\n",
      "Epoch 19: val_acc did not improve from 0.41326\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.6436 - acc: 0.4351 - val_loss: 1.8081 - val_acc: 0.4118 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6197 - acc: 0.4454\n",
      "Epoch 20: val_acc did not improve from 0.41326\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.6197 - acc: 0.4454 - val_loss: 1.8447 - val_acc: 0.4038 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5854 - acc: 0.4545\n",
      "Epoch 21: val_acc did not improve from 0.41326\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.5854 - acc: 0.4545 - val_loss: 1.8217 - val_acc: 0.4048 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5696 - acc: 0.4535\n",
      "Epoch 22: val_acc improved from 0.41326 to 0.42672, saving model to chkp/LVR_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.5696 - acc: 0.4535 - val_loss: 1.8138 - val_acc: 0.4267 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5529 - acc: 0.4590\n",
      "Epoch 23: val_acc did not improve from 0.42672\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.5529 - acc: 0.4590 - val_loss: 1.8312 - val_acc: 0.4093 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5187 - acc: 0.4667\n",
      "Epoch 24: val_acc did not improve from 0.42672\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.5187 - acc: 0.4667 - val_loss: 1.8459 - val_acc: 0.4187 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5041 - acc: 0.4766\n",
      "Epoch 25: val_acc did not improve from 0.42672\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.5041 - acc: 0.4766 - val_loss: 1.8472 - val_acc: 0.4153 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4868 - acc: 0.4726\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 26: val_acc did not improve from 0.42672\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.4868 - acc: 0.4726 - val_loss: 1.8367 - val_acc: 0.4163 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3740 - acc: 0.5051\n",
      "Epoch 27: val_acc improved from 0.42672 to 0.43021, saving model to chkp/LVR_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.3740 - acc: 0.5051 - val_loss: 1.8089 - val_acc: 0.4302 - lr: 1.0000e-04\n",
      "Epoch 28/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3260 - acc: 0.5252\n",
      "Epoch 28: val_acc improved from 0.43021 to 0.43320, saving model to chkp/LVR_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.3260 - acc: 0.5252 - val_loss: 1.8146 - val_acc: 0.4332 - lr: 1.0000e-04\n",
      "Epoch 29/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2972 - acc: 0.5323\n",
      "Epoch 29: val_acc improved from 0.43320 to 0.43519, saving model to chkp/LVR_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.2972 - acc: 0.5323 - val_loss: 1.8127 - val_acc: 0.4352 - lr: 1.0000e-04\n",
      "Epoch 30/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2823 - acc: 0.5450\n",
      "Epoch 30: val_acc improved from 0.43519 to 0.43868, saving model to chkp/LVR_remake_v1_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.2823 - acc: 0.5450 - val_loss: 1.8149 - val_acc: 0.4387 - lr: 1.0000e-04\n",
      "Epoch 31/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2597 - acc: 0.5491\n",
      "Epoch 31: val_acc did not improve from 0.43868\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.2597 - acc: 0.5491 - val_loss: 1.8222 - val_acc: 0.4372 - lr: 1.0000e-04\n",
      "Epoch 32/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2448 - acc: 0.5541\n",
      "Epoch 32: val_acc did not improve from 0.43868\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.2448 - acc: 0.5541 - val_loss: 1.8320 - val_acc: 0.4307 - lr: 1.0000e-04\n",
      "Epoch 33/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2324 - acc: 0.5646\n",
      "Epoch 33: val_acc did not improve from 0.43868\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.2324 - acc: 0.5646 - val_loss: 1.8392 - val_acc: 0.4347 - lr: 1.0000e-04\n",
      "Epoch 34/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2252 - acc: 0.5621\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 34: val_acc did not improve from 0.43868\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.2252 - acc: 0.5621 - val_loss: 1.8435 - val_acc: 0.4327 - lr: 1.0000e-04\n",
      "Epoch 35/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1951 - acc: 0.5770\n",
      "Epoch 35: val_acc did not improve from 0.43868\n",
      "268/268 [==============================] - 80s 297ms/step - loss: 1.1951 - acc: 0.5770 - val_loss: 1.8482 - val_acc: 0.4302 - lr: 1.0000e-05\n",
      "Epoch 36/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1793 - acc: 0.5851\n",
      "Epoch 36: val_acc did not improve from 0.43868\n",
      "268/268 [==============================] - 79s 296ms/step - loss: 1.1793 - acc: 0.5851 - val_loss: 1.8442 - val_acc: 0.4282 - lr: 1.0000e-05\n",
      "Epoch 37/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1821 - acc: 0.5714\n",
      "Epoch 37: val_acc did not improve from 0.43868\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.1821 - acc: 0.5714 - val_loss: 1.8474 - val_acc: 0.4342 - lr: 1.0000e-05\n",
      "Epoch 38/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1900 - acc: 0.5733\n",
      "Epoch 38: val_acc did not improve from 0.43868\n",
      "268/268 [==============================] - 80s 298ms/step - loss: 1.1900 - acc: 0.5733 - val_loss: 1.8437 - val_acc: 0.4322 - lr: 1.0000e-05\n",
      "Epoch 38: early stopping\n"
     ]
    }
   ],
   "source": [
    "seeds = [42, 123, 456, 789, 101112]\n",
    "\n",
    "results = []\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"\\nRunning model with seed {seed}\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "        multiModalData, classes, np.arange(len(multiModalData)), test_size=0.1, stratify=classes, random_state=seed)\n",
    "\n",
    "    #%% Scenarios and LoS NLoS analysis of train and test samples\n",
    "    df_train = pd.read_csv('./ml_challenge_dev_multi_modal_v3_all_scenarios_with_LoS_status.csv')\n",
    "\n",
    "    # Find LoS and NLoS samples in the train and test indices\n",
    "    train_los_indices = df_train[df_train['LoS_status'] == 'LoS'].index.intersection(train_indices)\n",
    "    train_nlos_indices = df_train[df_train['LoS_status'] == 'NLoS'].index.intersection(train_indices)\n",
    "    test_los_indices = df_train[df_train['LoS_status'] == 'LoS'].index.intersection(test_indices)\n",
    "    test_nlos_indices = df_train[df_train['LoS_status'] == 'NLoS'].index.intersection(test_indices)\n",
    "\n",
    "    # Verify that all train and test samples are classified\n",
    "    assert len(train_los_indices) + len(train_nlos_indices) == len(train_indices), \"Mismatch in total train samples\"\n",
    "    assert len(test_los_indices) + len(test_nlos_indices) == len(test_indices), \"Mismatch in total test samples\"\n",
    "\n",
    "    # Identify scenarios\n",
    "    scenario_path = df_train['unit2_loc_1']\n",
    "\n",
    "    # Function to count LoS and NLoS samples for a scenario\n",
    "    def count_scenario_samples(scenario_keyword, los_indices, nlos_indices):\n",
    "        scenario_indices = df_train[scenario_path.str.contains(scenario_keyword)].index\n",
    "        los_count = len(np.intersect1d(los_indices, scenario_indices))\n",
    "        nlos_count = len(np.intersect1d(nlos_indices, scenario_indices))\n",
    "        return los_count, nlos_count\n",
    "\n",
    "    # Count LoS and NLoS samples for each scenario in train and test sets\n",
    "    scenario_los_nlos_counts_train = {}\n",
    "    scenario_los_nlos_counts_test = {}\n",
    "    for scenario_keyword in ['scenario32', 'scenario33', 'scenario34']:\n",
    "        los_count_train, nlos_count_train = count_scenario_samples(scenario_keyword, train_los_indices, train_nlos_indices)\n",
    "        los_count_test, nlos_count_test = count_scenario_samples(scenario_keyword, test_los_indices, test_nlos_indices)\n",
    "        scenario_los_nlos_counts_train[scenario_keyword] = {'LoS': los_count_train, 'NLoS': nlos_count_train}\n",
    "        scenario_los_nlos_counts_test[scenario_keyword] = {'LoS': los_count_test, 'NLoS': nlos_count_test}\n",
    "\n",
    "    # Print the counts for each scenario in train and test sets\n",
    "    print(\"Train Data Scenario Counts:\")\n",
    "    for scenario, counts in scenario_los_nlos_counts_train.items():\n",
    "        print(f\"{scenario} - LoS samples count: {counts['LoS']}, NLoS samples count: {counts['NLoS']}\")\n",
    "\n",
    "    print(\"\\nTest Data Scenario Counts:\")\n",
    "    for scenario, counts in scenario_los_nlos_counts_test.items():\n",
    "        print(f\"{scenario} - LoS samples count: {counts['LoS']}, NLoS samples count: {counts['NLoS']}\")\n",
    "\n",
    "    # Extract LoS and NLoS samples from the modalities and classes\n",
    "    X_train_los = multiModalData[train_los_indices]\n",
    "    X_train_nlos = multiModalData[train_nlos_indices]\n",
    "    X_test_los = multiModalData[test_los_indices]\n",
    "    X_test_nlos = multiModalData[test_nlos_indices]\n",
    "    y_train_los = classes[train_los_indices]\n",
    "    y_train_nlos = classes[train_nlos_indices]\n",
    "    y_test_los = classes[test_los_indices]\n",
    "    y_test_nlos = classes[test_nlos_indices]\n",
    "\n",
    "    # Print shapes of train and test datasets for each modality\n",
    "    print(f'LoS Train Shape: {X_train_los.shape}, LoS Test Shape: {X_test_los.shape}')\n",
    "    print(f'NLoS Train Shape: {X_train_nlos.shape}, NLoS Test Shape: {X_test_nlos.shape}')\n",
    "\n",
    "    # Print shapes of train and test labels\n",
    "    print(f'Train Labels Shape: {y_train.shape}')\n",
    "    print(f'Test Labels Shape: {y_test.shape}')\n",
    "    print(f'Train LoS Labels Shape: {y_train_los.shape}')\n",
    "    print(f'Train NLoS Labels Shape: {y_train_nlos.shape}')\n",
    "    print(f'Test LoS Labels Shape: {y_test_los.shape}')\n",
    "    print(f'Test NLoS Labels Shape: {y_test_nlos.shape}')\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    # some global params\n",
    "    NBFRAME = 5\n",
    "    N_CLASSES = 64\n",
    "    INSHAPE = (5,imagex,imagey,3)\n",
    "    model = GRU_model(INSHAPE, N_CLASSES)\n",
    "    optimizer = keras.optimizers.Adam(0.001) \n",
    "    model.compile(optimizer, 'categorical_crossentropy', metrics=['acc'])\n",
    "    print(model.summary())\n",
    "\n",
    "    #Run the training\n",
    "    EPOCHS=300\n",
    "    BS = 30\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, mode='min', verbose=1),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=8, mode='min', verbose=1),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            f'chkp/{model_name}_seed_{seed}.hdf5', \n",
    "            monitor='val_acc',  # Monitor validation accuracy\n",
    "            save_best_only  = True,\n",
    "            mode='max',  # Maximize the monitored quantity\n",
    "            verbose=1),\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        validation_split = 0.2, #0\n",
    "        #validation_data=(X_val, y_val),\n",
    "        verbose=1,\n",
    "        #verbose='auto', #auto\n",
    "        epochs=EPOCHS,\n",
    "        batch_size =BS,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model with seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 00:49:42.597265: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-08-25 00:49:42.597307: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: edison\n",
      "2024-08-25 00:49:42.597327: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: edison\n",
      "2024-08-25 00:49:42.597493: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 560.35.3\n",
      "2024-08-25 00:49:42.597522: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: NOT_FOUND: could not find kernel module information in driver version file contents: \"NVRM version: NVIDIA UNIX Open Kernel Module for x86_64  560.35.03  Release Build  (dvs-builder@U16-I1-N07-12-3)  Fri Aug 16 21:42:42 UTC 2024\n",
      "GCC version:  gcc version 11.4.0 (Ubuntu 11.4.0-1ubuntu1~22.04) \n",
      "\"\n",
      "2024-08-25 00:49:42.597866: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 28s 88ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 3s 86ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 46ms/step\n",
      "\n",
      "Evaluating model with seed 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 28s 89ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 3s 88ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 35ms/step\n",
      "\n",
      "Evaluating model with seed 456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 28s 88ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 3s 86ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 48ms/step\n",
      "\n",
      "Evaluating model with seed 789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 28s 87ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 3s 85ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 40ms/step\n",
      "\n",
      "Evaluating model with seed 101112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 28s 88ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 3s 87ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 42ms/step\n",
      "\n",
      "Average Results Across All Seeds:\n",
      "Type: Train - Avg Accuracies: [0.60462 0.91006 0.96344] ± [0.02401761 0.01188926 0.00490331], Avg Score: 0.924 ± 0.008000000000000007, top31_beam: 0.8859999999999999 ± 0.01019803902718558, top33_beam: 0.976 ± 0.00489897948556636, PF1_mean: 0.9800000000000001 ± 1.1102230246251565e-16, PF2_mean: 0.99 ± 0.0, PF3_mean: 1.0 ± 0.0, Recall: 0.6039999999999999 ± 0.024979991993593614, Precision: 0.5940000000000001 ± 0.024979991993593586\n",
      "Type: Test_LoS - Avg Accuracies: [0.45792 0.83084 0.94412] ± [0.019477   0.01064605 0.00842411], Avg Score: 0.8880000000000001 ± 0.004000000000000004, top31_beam: 0.844 ± 0.01019803902718558, top33_beam: 0.97 ± 0.0, PF1_mean: 0.9780000000000001 ± 0.0040000000000000036, PF2_mean: 0.99 ± 0.0, PF3_mean: 0.99 ± 0.0, Recall: 0.458 ± 0.019390719429665308, Precision: 0.41200000000000003 ± 0.017204650534085247\n",
      "Type: Test_NLoS - Avg Accuracies: [0.04352 0.12732 0.1949 ] ± [0.00974216 0.06948661 0.06139091], Avg Score: 0.172 ± 0.036, top31_beam: 0.282 ± 0.07222188034107116, top33_beam: 0.48600000000000004 ± 0.06974238309665076, PF1_mean: 0.9020000000000001 ± 0.009797958971132722, PF2_mean: 0.924 ± 0.013564659966250496, PF3_mean: 0.9339999999999999 ± 0.01019803902718553, Recall: 0.044000000000000004 ± 0.012000000000000002, Precision: 0.092 ± 0.052687759489277966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10514"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% Test on all scens together\n",
    "#%%Test on Train and Test data (top-1,2,3)\n",
    "\n",
    "# Model evaluation and prediction\n",
    "def evaluate_model(model, X_data, y_data, pwrs_array, data_type, result_list, sample_indices):\n",
    "    predictions = model.predict(X_data)\n",
    "    y_pred = np.argsort(predictions, axis=1)[:, ::-1]\n",
    "    save_pred_to_csv(sample_indices, y_pred, top_k=[1,2,3], target_csv=f'preds_{model_name}_{data_type}.csv')\n",
    "    true = np.argmax(y_data, axis=1).reshape(-1, 1)\n",
    "    acc = compute_acc(y_pred, true, top_k=[1, 3, 5])\n",
    "    score = compute_DBA_score(y_pred, true, max_k=3, delta=5)\n",
    "    recall = recall_score(true, y_pred[:, 0], average='weighted')\n",
    "    precision = precision_score(true, y_pred[:, 0], average='weighted')\n",
    "    PF_mean = compute_powerfactor(y_pred, pwrs_array, k=3)\n",
    "    top_beams = calculate_top_beams(predictions, pwrs_array)\n",
    "   \n",
    "    result_list.append({\n",
    "        'type': data_type,\n",
    "        'acc': acc,\n",
    "        'score': round(score, 2),\n",
    "        'top31_beam': top_beams[0],\n",
    "        'top33_beam': top_beams[1],\n",
    "        'PF1_mean': PF_mean[0],\n",
    "        'PF2_mean': PF_mean[1],\n",
    "        'PF3_mean': PF_mean[2],\n",
    "        'recall': round(recall, 2),\n",
    "        'precision': round(precision, 2)\n",
    "    })\n",
    "\n",
    "\n",
    "# Define the seeds used for training\n",
    "seeds = [42, 123, 456, 789, 101112]\n",
    "\n",
    "# Placeholder for storing results from all seeds\n",
    "all_results = []\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"\\nEvaluating model with seed {seed}\")\n",
    "\n",
    "    # Train-Test Split with the current seed\n",
    "    X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "        multiModalData, classes, np.arange(len(multiModalData)), test_size=0.1, stratify=classes, random_state=seed)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    # Reload the scenario data\n",
    "    df_train = pd.read_csv('./ml_challenge_dev_multi_modal_v3_all_scenarios_with_LoS_status.csv')\n",
    "\n",
    "    # Find LoS and NLoS samples in the train and test indices\n",
    "    train_los_indices = df_train[df_train['LoS_status'] == 'LoS'].index.intersection(train_indices)\n",
    "    train_nlos_indices = df_train[df_train['LoS_status'] == 'NLoS'].index.intersection(train_indices)\n",
    "    test_los_indices = df_train[df_train['LoS_status'] == 'LoS'].index.intersection(test_indices)\n",
    "    test_nlos_indices = df_train[df_train['LoS_status'] == 'NLoS'].index.intersection(test_indices)\n",
    "\n",
    "    # Extract LoS and NLoS samples from the data and classes\n",
    "    X_test_los = multiModalData[test_los_indices]\n",
    "    X_test_nlos = multiModalData[test_nlos_indices]\n",
    "    y_test_los = classes[test_los_indices]\n",
    "    y_test_nlos = classes[test_nlos_indices]\n",
    "\n",
    "    # Power analysis - make sure to get the correct power arrays for each seed\n",
    "    N_CLASSES = 64\n",
    "    pwrs_array = np.zeros((df_train.shape[0], N_CLASSES))\n",
    "    for sample_idx in range(df_train.shape[0]):\n",
    "        pwr_abs_path = df_train['unit1_pwr_60ghz'].values[sample_idx]\n",
    "        pwrs_array[sample_idx] = np.loadtxt(pwr_abs_path)\n",
    "\n",
    "    pwrs_array[np.isnan(pwrs_array)] = 0\n",
    "    pwrs_array_train = pwrs_array[train_indices]\n",
    "    pwrs_array_test_los = pwrs_array[test_los_indices]\n",
    "    pwrs_array_test_nlos = pwrs_array[test_nlos_indices]\n",
    "\n",
    "    # Load the model corresponding to the current seed\n",
    "    model = load_model(f'chkp/{model_name}_seed_{seed}.hdf5')\n",
    "\n",
    "    # Initialize results list for the current seed\n",
    "    seed_results = []\n",
    "\n",
    "    # Evaluate on training data\n",
    "    evaluate_model(model, X_train, y_train, pwrs_array_train, 'Train', seed_results, train_indices)\n",
    "\n",
    "    # Evaluate on test data\n",
    "    evaluate_model(model, X_test_los, y_test_los, pwrs_array_test_los, 'Test_LoS', seed_results, test_los_indices)\n",
    "    evaluate_model(model, X_test_nlos, y_test_nlos, pwrs_array_test_nlos, 'Test_NLoS', seed_results, test_nlos_indices)\n",
    "\n",
    "    # Store the results of this seed in all_results\n",
    "    all_results.append(seed_results)\n",
    "\n",
    "# Function to average results across all seeds\n",
    "def average_results(all_results, metric):\n",
    "    averages = {}\n",
    "    types = ['Train', 'Test_LoS', 'Test_NLoS']\n",
    "    for data_type in types:\n",
    "        type_results = [res for seed_res in all_results for res in seed_res if res['type'] == data_type]\n",
    "        avg_metric = np.mean([res[metric] for res in type_results], axis=0)\n",
    "        std_metric = np.std([res[metric] for res in type_results], axis=0)\n",
    "        averages[data_type] = (avg_metric, std_metric)\n",
    "    return averages\n",
    "\n",
    "# Compute averages and standard deviations for each metric\n",
    "avg_accuracies = average_results(all_results, 'acc')\n",
    "avg_scores = average_results(all_results, 'score')\n",
    "avg_top31_beams = average_results(all_results, 'top31_beam')\n",
    "avg_top33_beams = average_results(all_results, 'top33_beam')\n",
    "avg_PF1_means = average_results(all_results, 'PF1_mean')\n",
    "avg_PF2_means = average_results(all_results, 'PF2_mean')\n",
    "avg_PF3_means = average_results(all_results, 'PF3_mean')\n",
    "avg_recalls = average_results(all_results, 'recall')\n",
    "avg_precisions = average_results(all_results, 'precision')\n",
    "\n",
    "# Print the average results across all seeds\n",
    "print(\"\\nAverage Results Across All Seeds:\")\n",
    "for data_type in avg_accuracies:\n",
    "    print(f\"Type: {data_type} - Avg Accuracies: {avg_accuracies[data_type][0]} ± {avg_accuracies[data_type][1]}, \"\n",
    "          f\"Avg Score: {avg_scores[data_type][0]} ± {avg_scores[data_type][1]}, \"\n",
    "          f\"top31_beam: {avg_top31_beams[data_type][0]} ± {avg_top31_beams[data_type][1]}, \"\n",
    "          f\"top33_beam: {avg_top33_beams[data_type][0]} ± {avg_top33_beams[data_type][1]}, \"\n",
    "          f\"PF1_mean: {avg_PF1_means[data_type][0]} ± {avg_PF1_means[data_type][1]}, \"\n",
    "          f\"PF2_mean: {avg_PF2_means[data_type][0]} ± {avg_PF2_means[data_type][1]}, \"\n",
    "          f\"PF3_mean: {avg_PF3_means[data_type][0]} ± {avg_PF3_means[data_type][1]}, \"\n",
    "          f\"Recall: {avg_recalls[data_type][0]} ± {avg_recalls[data_type][1]}, \"\n",
    "          f\"Precision: {avg_precisions[data_type][0]} ± {avg_precisions[data_type][1]}\")\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to CSV:\n",
      "        Type                                    Acc        Score   top31_beam  \\\n",
      "0      Train  0.60 ± 0.02, 0.91 ± 0.01, 0.96 ± 0.00  0.92 ± 0.01  0.89 ± 0.01   \n",
      "1   Test_LoS  0.46 ± 0.02, 0.83 ± 0.01, 0.94 ± 0.01  0.89 ± 0.00  0.84 ± 0.01   \n",
      "2  Test_NLoS  0.04 ± 0.01, 0.13 ± 0.07, 0.19 ± 0.06  0.17 ± 0.04  0.28 ± 0.07   \n",
      "\n",
      "    top33_beam     PF1_mean     PF2_mean     PF3_mean       Recall  \\\n",
      "0  0.98 ± 0.00  0.98 ± 0.00  0.99 ± 0.00  1.00 ± 0.00  0.60 ± 0.02   \n",
      "1  0.97 ± 0.00  0.98 ± 0.00  0.99 ± 0.00  0.99 ± 0.00  0.46 ± 0.02   \n",
      "2  0.49 ± 0.07  0.90 ± 0.01  0.92 ± 0.01  0.93 ± 0.01  0.04 ± 0.01   \n",
      "\n",
      "     Precision  \n",
      "0  0.59 ± 0.02  \n",
      "1  0.41 ± 0.02  \n",
      "2  0.09 ± 0.05  \n"
     ]
    }
   ],
   "source": [
    "# Define a function to format mean ± std\n",
    "def format_mean_std(mean, std):\n",
    "    return f\"{mean:.2f} ± {std:.2f}\"\n",
    "\n",
    "# Initialize the final results list\n",
    "formatted_results = []\n",
    "\n",
    "# Process the results for saving\n",
    "for data_type in avg_accuracies:\n",
    "    acc_means, acc_stds = avg_accuracies[data_type]\n",
    "    row = {\n",
    "        'Type': data_type,\n",
    "        'Acc': ', '.join([format_mean_std(m, s) for m, s in zip(acc_means, acc_stds)]),\n",
    "        'Score': format_mean_std(*avg_scores[data_type]),\n",
    "        'top31_beam': format_mean_std(*avg_top31_beams[data_type]),\n",
    "        'top33_beam': format_mean_std(*avg_top33_beams[data_type]),\n",
    "        'PF1_mean': format_mean_std(*avg_PF1_means[data_type]),\n",
    "        'PF2_mean': format_mean_std(*avg_PF2_means[data_type]),\n",
    "        'PF3_mean': format_mean_std(*avg_PF3_means[data_type]),\n",
    "        'Recall': format_mean_std(*avg_recalls[data_type]),\n",
    "        'Precision': format_mean_std(*avg_precisions[data_type])\n",
    "    }\n",
    "    formatted_results.append(row)\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "df = pd.DataFrame(formatted_results)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(f'results_{model_name}_AllScens.csv', index=False)\n",
    "\n",
    "print(\"Results saved to CSV:\")\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
