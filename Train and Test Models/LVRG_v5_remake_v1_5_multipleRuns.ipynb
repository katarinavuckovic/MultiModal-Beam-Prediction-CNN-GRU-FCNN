{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 01:24:47.505247: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-25 01:24:47.637244: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-25 01:24:48.649854: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sa457043/miniconda3/envs/tf_jupyter/lib/:/home/sa457043/lib/python3.10/site-packages/nvidia/cudnn/lib:\n",
      "2024-08-25 01:24:48.649917: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sa457043/miniconda3/envs/tf_jupyter/lib/:/home/sa457043/lib/python3.10/site-packages/nvidia/cudnn/lib:\n",
      "2024-08-25 01:24:48.649923: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Apr 19 13:55:28 2023\n",
    "\n",
    "@author: Saba\n",
    "\"\"\"\n",
    "\n",
    "'''\n",
    "To change at each run with different models:\n",
    "    the name of the file in commands: \n",
    "        result.to_csv\n",
    "    the name of ckpt in:\n",
    "        callbacks      \n",
    "        \n",
    "This is Lidar_Transformed plus Vision data to be trained with CNN to make a multimodal network.\n",
    "Image (Vision) is transformed from RGB to gray.\n",
    "'''\n",
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Conv2D, BatchNormalization, MaxPool2D, GlobalMaxPool2D\n",
    "from keras.layers import TimeDistributed, GRU, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.lines as mlines\n",
    "import utm\n",
    "from collections import Counter\n",
    "import random\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import math\n",
    "import pickle \n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)  # Set TensorFlow seed as well\n",
    "random.seed = 42\n",
    "     \n",
    "#%% Main                \n",
    "#Score function\n",
    "def compute_acc(y_pred, y_true, top_k=[1,3,5]):\n",
    "    \"\"\" Computes top-k accuracy given prediction and ground truth labels.\"\"\"\n",
    "    n_top_k = len(top_k)\n",
    "    total_hits = np.zeros(n_top_k)\n",
    "    \n",
    "    n_test_samples = len(y_true)\n",
    "    if len(y_pred) != n_test_samples:\n",
    "        raise Exception('Number of predicted beams does not match number of labels.')\n",
    "    \n",
    "    # For each test sample, count times where true beam is in k top guesses\n",
    "    for samp_idx in range(len(y_true)):\n",
    "        for k_idx in range(n_top_k):\n",
    "            hit = np.any(y_pred[samp_idx,:top_k[k_idx]] == y_true[samp_idx, -1])\n",
    "            total_hits[k_idx] += 1 if hit else 0\n",
    "    \n",
    "    # Average the number of correct guesses (over the total samples)\n",
    "    return np.round(total_hits / len(y_true), 4)\n",
    "\n",
    "def save_pred_to_csv(sample_index, y_pred, top_k=[1,2,3], target_csv='beam_pred.csv'):\n",
    "    \"\"\" \n",
    "    Saves the predicted beam results to a csv file. \n",
    "    Expects y_pred: n_samples x N_BEAMS, and saves the top_k columns only. \n",
    "    \"\"\"\n",
    "    \n",
    "    cols = [f'top-{i} beam' for i in top_k]\n",
    "    df = pd.DataFrame(data=y_pred[:, np.array(top_k)-1], columns=cols)\n",
    "    df.index.name = 'index'\n",
    "    df['sample_index'] = sample_index\n",
    "    df.to_csv(target_csv)\n",
    "\n",
    "def compute_DBA_score(y_pred, y_true, max_k=3, delta=5):\n",
    "    \"\"\" \n",
    "    The top-k MBD (Minimum Beam Distance) as the minimum distance\n",
    "    of any beam in the top-k set of predicted beams to the ground truth beam. \n",
    "    \n",
    "    Then we take the average across all samples.\n",
    "    \n",
    "    Then we average that number over all the considered Ks.\n",
    "    \"\"\"\n",
    "    n_samples = y_pred.shape[0]\n",
    "    #n_beams = y_pred.shape[-1] \n",
    "    \n",
    "    yk = np.zeros(max_k)\n",
    "    for k in range(max_k):\n",
    "        acc_avg_min_beam_dist = 0\n",
    "        idxs_up_to_k = np.arange(k+1)\n",
    "        for i in range(n_samples):\n",
    "            aux1 = np.abs(y_pred[i, idxs_up_to_k] - y_true[i]) / delta\n",
    "            # Compute min between beam diff and 1\n",
    "            aux2 = np.min(np.stack((aux1, np.zeros_like(aux1)+1), axis=0), axis=0)\n",
    "            acc_avg_min_beam_dist += np.min(aux2)\n",
    "            \n",
    "        yk[k] = 1 - acc_avg_min_beam_dist / n_samples\n",
    "    \n",
    "    return np.mean(yk)\n",
    "\n",
    "#%% Power factor\n",
    "def compute_powerfactor(y_pred, pwrs_array, k=3):\n",
    "    '''\n",
    "    Calculate the maximum power factor for top-1 to top-k predictions.\n",
    "    \n",
    "    Args:\n",
    "    y_pred (numpy array): Sorted predictions (n_samples, 64), indices of beams sorted by probability.\n",
    "    pwrs_array (numpy array): Power values for beams (n_samples, 64).\n",
    "    k (int): The top-k predictions to consider.\n",
    "    \n",
    "    Returns:\n",
    "    numpy array: Array of average max PFs from top-1 to top-k.\n",
    "    '''\n",
    "    max_Pr = np.max(pwrs_array, axis=1)  # Maximum power across all beams for each sample\n",
    "    PF_max_k = np.zeros(k)  # Array to store the average of maximum PFs for each top-k\n",
    "    #PF_max_k_stds = np.zeros(k)  # Array to store the standard deviation of maximum PFs for each top-k\n",
    "    \n",
    "    for i in range(1, k+1):\n",
    "        max_PF = np.zeros(pwrs_array.shape[0])  # Array to hold the max PF for each sample for current top-i\n",
    "        for j in range(pwrs_array.shape[0]):  # Iterate over each sample\n",
    "            # Calculate PFs for the top-i predictions and find the maximum\n",
    "            top_k_PFs = pwrs_array[j, y_pred[j, :i]] / max_Pr[j]\n",
    "            max_PF[j] = np.max(top_k_PFs)  # Maximum PF for this sample among top-i\n",
    "        PF_max_k[i-1] = np.round(np.mean(max_PF), 2)  # Average of maximum PFs across all samples for top-i\n",
    "        #PF_max_k_stds[i-1] = np.round(np.std(max_PF), 2)  # Standard deviation of maximum PFs for top-i\n",
    "\n",
    "    return PF_max_k #, PF_max_k_stds\n",
    "\n",
    "def calculate_top_beams(predictions, truths):\n",
    "    correct_top1_count = 0\n",
    "    correct_top3_count = 0\n",
    "    total_count = len(predictions)  # Assuming predictions and truths are lists of numpy arrays\n",
    "    \n",
    "    for pred, true in zip(predictions, truths):\n",
    "        # Find the index of the highest value in the predicted array\n",
    "        top_pred_index = np.argmax(pred)\n",
    "        \n",
    "        # Find the indices of the top 3 highest values in the true array\n",
    "        top_true_indices = np.argsort(true)[-3:]\n",
    "        \n",
    "        # Check if the top predicted index is among the top 3 true indices for top-1 accuracy\n",
    "        if top_pred_index in top_true_indices:\n",
    "            correct_top1_count += 1\n",
    "        \n",
    "        # Find the indices of the top 3 highest values in the predicted array\n",
    "        top_pred_indices = np.argsort(pred)[-3:]\n",
    "        \n",
    "        # Check if there is any intersection between the top 3 predicted indices and the top 3 true indices for top-3 accuracy\n",
    "        if set(top_pred_indices) & set(top_true_indices):\n",
    "            correct_top3_count += 1\n",
    "    \n",
    "    # Calculate the percentage of correct predictions for top-1 and top-3 accuracies\n",
    "    top1_accuracy = (correct_top1_count / total_count)\n",
    "    top3_accuracy = (correct_top3_count / total_count) \n",
    "    top1_accuracy  = round(top1_accuracy, 2)\n",
    "    top3_accuracy  = round(top3_accuracy, 2)\n",
    "    return [top1_accuracy,top3_accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#%% GPU optimization\n",
    "#\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "        \n",
    "#\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\" #to allow automatic assignment of operations to different GPUs to prevent OOM issue\n",
    "'''   \n",
    "\n",
    "# Set environment variables to disable GPU usage and use CPU instead\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # This line disables GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% some global params\n",
    "model_name = \"LVRG_v5_remake_v1_5_multipleRuns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11143\n"
     ]
    }
   ],
   "source": [
    "#%%Load data\n",
    "def add_noise(data, noise_level):\n",
    "    noisy_data = data + np.random.normal(scale=noise_level, size=data.shape)\n",
    "    return noisy_data\n",
    "\n",
    "'''\n",
    "def add_gps_noise(GPS, noise_level):\n",
    "    GPS_noisy = np.zeros(GPS.shape)\n",
    "    GPS_noisy[:,:,0] = GPS[:,:,0] + np.random.normal(scale=noise_level, size=GPS[:,:,0].shape)\n",
    "    GPS_noisy[:,:,1] = GPS[:,:,1] + np.random.normal(scale=noise_level, size=GPS[:,:,1].shape)\n",
    "    return GPS_noisy\n",
    "'''\n",
    "\n",
    "df_train =  pd.read_csv('./ml_challenge_dev_multi_modal_v2.csv')\n",
    "index = df_train['unit1_beam'].values\n",
    "print(len(index))\n",
    "\n",
    "imageX = 150\n",
    "imageY = 150\n",
    "\n",
    "import cv2\n",
    "def rescale(data): #to rescale from 11143x5x210x360 to 11143,5,210,225\n",
    "    resized_data= np.zeros((data.shape[0],5,imageX,imageY))\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            resized_data[i, j] = cv2.resize(data[i, j], (imageY, imageX), interpolation=cv2.INTER_NEAREST)\n",
    "    return resized_data\n",
    "    \n",
    "data = np.load('lidar_DepthInten_11143x5x210x360_v2.npz') \n",
    "lidar = rescale(data['Lidar'])\n",
    "\n",
    "data = np.load('vision_gray_11143x5x210x360.npz')\n",
    "vision = rescale(data['vision'])\n",
    "vision = add_noise(vision, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34 145.74\n",
      "0.33 145.74\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "data = np.load('radar_11143x5x210x360.npz') \n",
    "radar = rescale(data['radar'])\n",
    "radar = add_noise(radar, 0.0025)\n",
    "'''\n",
    "\n",
    "os.chdir(r'/home/sa457043/Multimodal_beam_prediction/')\n",
    "radar = np.load('radar_11143x5x256x64.npz')['radar'] \n",
    "\n",
    "'''\n",
    "# Iterate over each Lidar instance and resize\n",
    "resized_radar= np.zeros((11143,5,210,360))\n",
    "for i in range(radar.shape[0]):\n",
    "    for j in range(radar.shape[1]):\n",
    "        resized_radar[i, j] = cv2.resize(radar[i, j], (360, 210), interpolation=cv2.INTER_NEAREST)\n",
    "print('radar_rescaled.shape =', resized_radar.shape)\n",
    "radar = resized_radar\n",
    "del resized_radar\n",
    "'''\n",
    "\n",
    "radar = rescale(radar)\n",
    "print(round(np.min(radar), 2),round(np.max(radar), 2))\n",
    "radar = add_noise(radar, 0.0025)\n",
    "print(round(np.min(radar), 2),round(np.max(radar), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('GPS_11143x5x210x360.npz')\n",
    "GPS = rescale(data['GPS'])\n",
    "GPS = add_noise(GPS, 0.05)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "multiModalData = np.zeros([11143,5,imageX,imageY,4])\n",
    "multiModalData[:,:,:,:,0] = lidar\n",
    "multiModalData[:,:,:,:,1] = vision\n",
    "multiModalData[:,:,:,:,2] = radar\n",
    "multiModalData[:,:,:,:,3] = GPS\n",
    "multiModalData = tf.keras.utils.normalize(multiModalData.reshape([11143*5,-1]))  \n",
    "multiModalData = multiModalData.reshape([11143,5,imageX,imageY,4])\n",
    "\n",
    "del lidar, vision, radar, GPS\n",
    "gc.collect()\n",
    "\n",
    "classes = to_categorical(df_train['unit1_beam'].values - 1, num_classes = 64, dtype =\"int32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%Model\n",
    "def build_convnet(shape=(imageX,imageY,4)):\n",
    "    momentum = .9\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(Conv2D(4, 3, input_shape=shape,padding='same', activation='relu'))\n",
    "    model.add(Conv2D(16, 3, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool2D(pool_size=3))\n",
    "    model.add(MaxPool2D(pool_size=3))\n",
    "    \n",
    "    model.add(Conv2D(16, 3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(32, 3, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool2D(pool_size=3))\n",
    "\n",
    "    model.add(Conv2D(128, 3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, 3, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization(momentum=momentum))\n",
    "    model.add(MaxPool2D(pool_size=3))\n",
    "    \n",
    "    model.add(GlobalMaxPool2D())\n",
    "    return model\n",
    "\n",
    "def GRU_model(input_shape=(5, imageX, imageY, 4), nbout=64): \n",
    "    # Create our convnet with (112, 112, 3) input shape\n",
    "    convnet = build_convnet(input_shape[1:]) #all elements after shape[0] (not shape[0])\n",
    "    \n",
    "    # then create our final model\n",
    "    model = keras.Sequential()\n",
    "    # add the convnet with (5, 128,125,4) shape\n",
    "    model.add(TimeDistributed(convnet, input_shape=input_shape))\n",
    "    # here, you can also use GRU or LSTM\n",
    "    model.add(GRU(64))\n",
    "    # and finally, we make a decision network\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    #model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(nbout, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running model with seed 42\n",
      "Train Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 2683, NLoS samples count: 110\n",
      "scenario33 - LoS samples count: 3329, NLoS samples count: 120\n",
      "scenario34 - LoS samples count: 3691, NLoS samples count: 95\n",
      "\n",
      "Test Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 311, NLoS samples count: 11\n",
      "scenario33 - LoS samples count: 372, NLoS samples count: 16\n",
      "scenario34 - LoS samples count: 391, NLoS samples count: 14\n",
      "LoS Train Shape: (9703, 5, 150, 150, 4), LoS Test Shape: (1074, 5, 150, 150, 4)\n",
      "NLoS Train Shape: (325, 5, 150, 150, 4), NLoS Test Shape: (41, 5, 150, 150, 4)\n",
      "Train Labels Shape: (10028, 64)\n",
      "Test Labels Shape: (1115, 64)\n",
      "Train LoS Labels Shape: (9703, 64)\n",
      "Train NLoS Labels Shape: (325, 64)\n",
      "Test LoS Labels Shape: (1074, 64)\n",
      "Test NLoS Labels Shape: (41, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-21 16:35:25.075445: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-08-21 16:35:25.075905: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: edison\n",
      "2024-08-21 16:35:25.075911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: edison\n",
      "2024-08-21 16:35:25.076030: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 560.28.3\n",
      "2024-08-21 16:35:25.076484: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: NOT_FOUND: could not find kernel module information in driver version file contents: \"NVRM version: NVIDIA UNIX Open Kernel Module for x86_64  560.28.03  Release Build  (dvs-builder@U16-A24-27-4)  Thu Jul 18 20:46:24 UTC 2024\n",
      "GCC version:  gcc version 11.4.0 (Ubuntu 11.4.0-1ubuntu1~22.04) \n",
      "\"\n",
      "2024-08-21 16:35:25.078254: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDistr  (None, 5, 256)           341076    \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                61824     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 411,220\n",
      "Trainable params: 410,612\n",
      "Non-trainable params: 608\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.8053 - acc: 0.1001\n",
      "Epoch 1: val_acc improved from -inf to 0.13759, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 94s 337ms/step - loss: 3.8053 - acc: 0.1001 - val_loss: 3.4898 - val_acc: 0.1376 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.4186 - acc: 0.1321\n",
      "Epoch 2: val_acc improved from 0.13759 to 0.16849, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 3.4186 - acc: 0.1321 - val_loss: 3.1652 - val_acc: 0.1685 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.1227 - acc: 0.1650\n",
      "Epoch 3: val_acc improved from 0.16849 to 0.18295, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 3.1227 - acc: 0.1650 - val_loss: 2.9421 - val_acc: 0.1830 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.8841 - acc: 0.2023\n",
      "Epoch 4: val_acc improved from 0.18295 to 0.22233, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 2.8841 - acc: 0.2023 - val_loss: 2.6660 - val_acc: 0.2223 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.6478 - acc: 0.2393\n",
      "Epoch 5: val_acc improved from 0.22233 to 0.26271, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 2.6478 - acc: 0.2393 - val_loss: 2.4677 - val_acc: 0.2627 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.4373 - acc: 0.2747\n",
      "Epoch 6: val_acc improved from 0.26271 to 0.29262, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 2.4373 - acc: 0.2747 - val_loss: 2.3065 - val_acc: 0.2926 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.3025 - acc: 0.2979\n",
      "Epoch 7: val_acc improved from 0.29262 to 0.31406, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 2.3025 - acc: 0.2979 - val_loss: 2.1912 - val_acc: 0.3141 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.1789 - acc: 0.3227\n",
      "Epoch 8: val_acc improved from 0.31406 to 0.31954, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 2.1789 - acc: 0.3227 - val_loss: 2.1003 - val_acc: 0.3195 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.0973 - acc: 0.3433\n",
      "Epoch 9: val_acc improved from 0.31954 to 0.34247, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 2.0973 - acc: 0.3433 - val_loss: 2.0381 - val_acc: 0.3425 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.0268 - acc: 0.3517\n",
      "Epoch 10: val_acc improved from 0.34247 to 0.35793, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 82s 307ms/step - loss: 2.0268 - acc: 0.3517 - val_loss: 1.9707 - val_acc: 0.3579 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.9621 - acc: 0.3628\n",
      "Epoch 11: val_acc improved from 0.35793 to 0.35992, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.9621 - acc: 0.3628 - val_loss: 2.0084 - val_acc: 0.3599 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8767 - acc: 0.3889\n",
      "Epoch 12: val_acc improved from 0.35992 to 0.38485, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.8767 - acc: 0.3889 - val_loss: 1.8617 - val_acc: 0.3848 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8374 - acc: 0.3967\n",
      "Epoch 13: val_acc did not improve from 0.38485\n",
      "268/268 [==============================] - 82s 306ms/step - loss: 1.8374 - acc: 0.3967 - val_loss: 1.8570 - val_acc: 0.3819 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7888 - acc: 0.4109\n",
      "Epoch 14: val_acc improved from 0.38485 to 0.40578, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.7888 - acc: 0.4109 - val_loss: 1.8063 - val_acc: 0.4058 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7261 - acc: 0.4196\n",
      "Epoch 15: val_acc did not improve from 0.40578\n",
      "268/268 [==============================] - 82s 307ms/step - loss: 1.7261 - acc: 0.4196 - val_loss: 1.8119 - val_acc: 0.3998 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6965 - acc: 0.4270\n",
      "Epoch 16: val_acc did not improve from 0.40578\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.6965 - acc: 0.4270 - val_loss: 1.8150 - val_acc: 0.3903 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6821 - acc: 0.4297\n",
      "Epoch 17: val_acc improved from 0.40578 to 0.40977, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 82s 308ms/step - loss: 1.6821 - acc: 0.4297 - val_loss: 1.7417 - val_acc: 0.4098 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6348 - acc: 0.4496\n",
      "Epoch 18: val_acc did not improve from 0.40977\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.6348 - acc: 0.4496 - val_loss: 1.8314 - val_acc: 0.3858 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6134 - acc: 0.4486\n",
      "Epoch 19: val_acc did not improve from 0.40977\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.6134 - acc: 0.4486 - val_loss: 1.7555 - val_acc: 0.4033 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5858 - acc: 0.4597\n",
      "Epoch 20: val_acc did not improve from 0.40977\n",
      "268/268 [==============================] - 82s 307ms/step - loss: 1.5858 - acc: 0.4597 - val_loss: 1.8867 - val_acc: 0.3744 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5473 - acc: 0.4631\n",
      "Epoch 21: val_acc did not improve from 0.40977\n",
      "268/268 [==============================] - 82s 308ms/step - loss: 1.5473 - acc: 0.4631 - val_loss: 1.7354 - val_acc: 0.4053 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5370 - acc: 0.4672\n",
      "Epoch 22: val_acc improved from 0.40977 to 0.41575, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.5370 - acc: 0.4672 - val_loss: 1.7713 - val_acc: 0.4158 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4997 - acc: 0.4703\n",
      "Epoch 23: val_acc improved from 0.41575 to 0.43021, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 82s 306ms/step - loss: 1.4997 - acc: 0.4703 - val_loss: 1.7437 - val_acc: 0.4302 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4834 - acc: 0.4784\n",
      "Epoch 24: val_acc did not improve from 0.43021\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.4834 - acc: 0.4784 - val_loss: 2.4076 - val_acc: 0.3325 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4442 - acc: 0.4897\n",
      "Epoch 25: val_acc did not improve from 0.43021\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.4442 - acc: 0.4897 - val_loss: 1.7862 - val_acc: 0.4123 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4413 - acc: 0.4904\n",
      "Epoch 26: val_acc did not improve from 0.43021\n",
      "268/268 [==============================] - 82s 308ms/step - loss: 1.4413 - acc: 0.4904 - val_loss: 1.7426 - val_acc: 0.4242 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4081 - acc: 0.4920\n",
      "Epoch 27: val_acc did not improve from 0.43021\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.4081 - acc: 0.4920 - val_loss: 1.7687 - val_acc: 0.4227 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3900 - acc: 0.5070\n",
      "Epoch 28: val_acc did not improve from 0.43021\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.3900 - acc: 0.5070 - val_loss: 1.7184 - val_acc: 0.4262 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3739 - acc: 0.5115\n",
      "Epoch 29: val_acc did not improve from 0.43021\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.3739 - acc: 0.5115 - val_loss: 1.7865 - val_acc: 0.4277 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3699 - acc: 0.5118\n",
      "Epoch 30: val_acc did not improve from 0.43021\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.3699 - acc: 0.5118 - val_loss: 1.7490 - val_acc: 0.4123 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3537 - acc: 0.5132\n",
      "Epoch 31: val_acc improved from 0.43021 to 0.43420, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.3537 - acc: 0.5132 - val_loss: 1.8112 - val_acc: 0.4342 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3374 - acc: 0.5115\n",
      "Epoch 32: val_acc did not improve from 0.43420\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.3374 - acc: 0.5115 - val_loss: 1.8180 - val_acc: 0.4297 - lr: 0.0010\n",
      "Epoch 33/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3104 - acc: 0.5219\n",
      "Epoch 33: val_acc did not improve from 0.43420\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.3104 - acc: 0.5219 - val_loss: 1.8788 - val_acc: 0.4098 - lr: 0.0010\n",
      "Epoch 34/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2964 - acc: 0.5274\n",
      "Epoch 34: val_acc did not improve from 0.43420\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.2964 - acc: 0.5274 - val_loss: 1.8304 - val_acc: 0.4148 - lr: 0.0010\n",
      "Epoch 35/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2658 - acc: 0.5366\n",
      "Epoch 35: val_acc did not improve from 0.43420\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.2658 - acc: 0.5366 - val_loss: 1.8754 - val_acc: 0.4252 - lr: 0.0010\n",
      "Epoch 36/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2560 - acc: 0.5374\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 36: val_acc did not improve from 0.43420\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.2560 - acc: 0.5374 - val_loss: 2.1276 - val_acc: 0.3794 - lr: 0.0010\n",
      "Epoch 37/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1477 - acc: 0.5769\n",
      "Epoch 37: val_acc improved from 0.43420 to 0.43868, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.1477 - acc: 0.5769 - val_loss: 1.7996 - val_acc: 0.4387 - lr: 1.0000e-04\n",
      "Epoch 38/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0811 - acc: 0.6058\n",
      "Epoch 38: val_acc improved from 0.43868 to 0.43918, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.0811 - acc: 0.6058 - val_loss: 1.8059 - val_acc: 0.4392 - lr: 1.0000e-04\n",
      "Epoch 39/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0522 - acc: 0.6132\n",
      "Epoch 39: val_acc improved from 0.43918 to 0.43968, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 82s 308ms/step - loss: 1.0522 - acc: 0.6132 - val_loss: 1.8288 - val_acc: 0.4397 - lr: 1.0000e-04\n",
      "Epoch 40/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0226 - acc: 0.6227\n",
      "Epoch 40: val_acc improved from 0.43968 to 0.45065, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.0226 - acc: 0.6227 - val_loss: 1.8581 - val_acc: 0.4506 - lr: 1.0000e-04\n",
      "Epoch 41/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0049 - acc: 0.6262\n",
      "Epoch 41: val_acc did not improve from 0.45065\n",
      "268/268 [==============================] - 82s 307ms/step - loss: 1.0049 - acc: 0.6262 - val_loss: 1.8641 - val_acc: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 42/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 0.9836 - acc: 0.6351\n",
      "Epoch 42: val_acc improved from 0.45065 to 0.45364, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_42.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 0.9836 - acc: 0.6351 - val_loss: 1.8907 - val_acc: 0.4536 - lr: 1.0000e-04\n",
      "Epoch 43/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 0.9742 - acc: 0.6422\n",
      "Epoch 43: val_acc did not improve from 0.45364\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 0.9742 - acc: 0.6422 - val_loss: 1.9004 - val_acc: 0.4482 - lr: 1.0000e-04\n",
      "Epoch 44/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 0.9644 - acc: 0.6445\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 44: val_acc did not improve from 0.45364\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 0.9644 - acc: 0.6445 - val_loss: 1.9119 - val_acc: 0.4452 - lr: 1.0000e-04\n",
      "Epoch 45/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 0.9374 - acc: 0.6535\n",
      "Epoch 45: val_acc did not improve from 0.45364\n",
      "268/268 [==============================] - 82s 307ms/step - loss: 0.9374 - acc: 0.6535 - val_loss: 1.9079 - val_acc: 0.4531 - lr: 1.0000e-05\n",
      "Epoch 46/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 0.9311 - acc: 0.6611\n",
      "Epoch 46: val_acc did not improve from 0.45364\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 0.9311 - acc: 0.6611 - val_loss: 1.9137 - val_acc: 0.4506 - lr: 1.0000e-05\n",
      "Epoch 47/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 0.9254 - acc: 0.6606\n",
      "Epoch 47: val_acc did not improve from 0.45364\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 0.9254 - acc: 0.6606 - val_loss: 1.9227 - val_acc: 0.4497 - lr: 1.0000e-05\n",
      "Epoch 48/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 0.9291 - acc: 0.6597\n",
      "Epoch 48: val_acc did not improve from 0.45364\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 0.9291 - acc: 0.6597 - val_loss: 1.9197 - val_acc: 0.4506 - lr: 1.0000e-05\n",
      "Epoch 48: early stopping\n",
      "\n",
      "Running model with seed 123\n",
      "Train Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 2729, NLoS samples count: 109\n",
      "scenario33 - LoS samples count: 3322, NLoS samples count: 119\n",
      "scenario34 - LoS samples count: 3652, NLoS samples count: 97\n",
      "\n",
      "Test Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 265, NLoS samples count: 12\n",
      "scenario33 - LoS samples count: 379, NLoS samples count: 17\n",
      "scenario34 - LoS samples count: 430, NLoS samples count: 12\n",
      "LoS Train Shape: (9703, 5, 150, 150, 4), LoS Test Shape: (1074, 5, 150, 150, 4)\n",
      "NLoS Train Shape: (325, 5, 150, 150, 4), NLoS Test Shape: (41, 5, 150, 150, 4)\n",
      "Train Labels Shape: (10028, 64)\n",
      "Test Labels Shape: (1115, 64)\n",
      "Train LoS Labels Shape: (9703, 64)\n",
      "Train NLoS Labels Shape: (325, 64)\n",
      "Test LoS Labels Shape: (1074, 64)\n",
      "Test NLoS Labels Shape: (41, 64)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_1 (TimeDis  (None, 5, 256)           341076    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 64)                61824     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 411,220\n",
      "Trainable params: 410,612\n",
      "Non-trainable params: 608\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.8521 - acc: 0.0949\n",
      "Epoch 1: val_acc improved from -inf to 0.09870, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 91s 329ms/step - loss: 3.8521 - acc: 0.0949 - val_loss: 3.6626 - val_acc: 0.0987 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.5862 - acc: 0.1143\n",
      "Epoch 2: val_acc improved from 0.09870 to 0.13460, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 3.5862 - acc: 0.1143 - val_loss: 3.4691 - val_acc: 0.1346 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.3194 - acc: 0.1449\n",
      "Epoch 3: val_acc improved from 0.13460 to 0.16600, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 3.3194 - acc: 0.1449 - val_loss: 3.1782 - val_acc: 0.1660 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.0291 - acc: 0.1822\n",
      "Epoch 4: val_acc improved from 0.16600 to 0.20788, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 3.0291 - acc: 0.1822 - val_loss: 2.8267 - val_acc: 0.2079 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.7688 - acc: 0.2191\n",
      "Epoch 5: val_acc improved from 0.20788 to 0.22134, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 2.7688 - acc: 0.2191 - val_loss: 2.7161 - val_acc: 0.2213 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.5407 - acc: 0.2598\n",
      "Epoch 6: val_acc improved from 0.22134 to 0.28465, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 2.5407 - acc: 0.2598 - val_loss: 2.3724 - val_acc: 0.2846 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.3351 - acc: 0.3015\n",
      "Epoch 7: val_acc did not improve from 0.28465\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 2.3351 - acc: 0.3015 - val_loss: 2.3890 - val_acc: 0.2772 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.1999 - acc: 0.3204\n",
      "Epoch 8: val_acc improved from 0.28465 to 0.33549, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 2.1999 - acc: 0.3204 - val_loss: 2.1358 - val_acc: 0.3355 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.1072 - acc: 0.3398\n",
      "Epoch 9: val_acc improved from 0.33549 to 0.33948, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 2.1072 - acc: 0.3398 - val_loss: 2.0697 - val_acc: 0.3395 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.0068 - acc: 0.3553\n",
      "Epoch 10: val_acc improved from 0.33948 to 0.35793, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 2.0068 - acc: 0.3553 - val_loss: 1.9786 - val_acc: 0.3579 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.9246 - acc: 0.3813\n",
      "Epoch 11: val_acc improved from 0.35793 to 0.38335, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.9246 - acc: 0.3813 - val_loss: 1.9168 - val_acc: 0.3833 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8708 - acc: 0.3927\n",
      "Epoch 12: val_acc did not improve from 0.38335\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.8708 - acc: 0.3927 - val_loss: 1.9788 - val_acc: 0.3769 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8158 - acc: 0.4010\n",
      "Epoch 13: val_acc improved from 0.38335 to 0.38684, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.8158 - acc: 0.4010 - val_loss: 1.8865 - val_acc: 0.3868 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7846 - acc: 0.4100\n",
      "Epoch 14: val_acc improved from 0.38684 to 0.39880, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.7846 - acc: 0.4100 - val_loss: 1.8345 - val_acc: 0.3988 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7331 - acc: 0.4195\n",
      "Epoch 15: val_acc improved from 0.39880 to 0.40329, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.7331 - acc: 0.4195 - val_loss: 1.8350 - val_acc: 0.4033 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7012 - acc: 0.4358\n",
      "Epoch 16: val_acc improved from 0.40329 to 0.40778, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.7012 - acc: 0.4358 - val_loss: 1.8225 - val_acc: 0.4078 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6548 - acc: 0.4378\n",
      "Epoch 17: val_acc did not improve from 0.40778\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.6548 - acc: 0.4378 - val_loss: 1.8381 - val_acc: 0.3908 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6382 - acc: 0.4430\n",
      "Epoch 18: val_acc did not improve from 0.40778\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.6382 - acc: 0.4430 - val_loss: 1.8517 - val_acc: 0.3928 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6055 - acc: 0.4516\n",
      "Epoch 19: val_acc improved from 0.40778 to 0.41625, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.6055 - acc: 0.4516 - val_loss: 1.8109 - val_acc: 0.4163 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5670 - acc: 0.4550\n",
      "Epoch 20: val_acc improved from 0.41625 to 0.43071, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.5670 - acc: 0.4550 - val_loss: 1.7623 - val_acc: 0.4307 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5556 - acc: 0.4632\n",
      "Epoch 21: val_acc did not improve from 0.43071\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.5556 - acc: 0.4632 - val_loss: 1.8070 - val_acc: 0.4252 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5262 - acc: 0.4710\n",
      "Epoch 22: val_acc did not improve from 0.43071\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.5262 - acc: 0.4710 - val_loss: 1.7914 - val_acc: 0.4207 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5064 - acc: 0.4692\n",
      "Epoch 23: val_acc did not improve from 0.43071\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.5064 - acc: 0.4692 - val_loss: 1.8504 - val_acc: 0.4148 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4969 - acc: 0.4752\n",
      "Epoch 24: val_acc did not improve from 0.43071\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.4969 - acc: 0.4752 - val_loss: 1.8658 - val_acc: 0.4138 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4738 - acc: 0.4833\n",
      "Epoch 25: val_acc did not improve from 0.43071\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.4738 - acc: 0.4833 - val_loss: 1.8764 - val_acc: 0.4128 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4363 - acc: 0.4909\n",
      "Epoch 26: val_acc did not improve from 0.43071\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.4363 - acc: 0.4909 - val_loss: 1.8720 - val_acc: 0.4103 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4086 - acc: 0.5004\n",
      "Epoch 27: val_acc did not improve from 0.43071\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.4086 - acc: 0.5004 - val_loss: 1.8187 - val_acc: 0.4232 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3936 - acc: 0.5025\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 28: val_acc did not improve from 0.43071\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.3936 - acc: 0.5025 - val_loss: 1.8443 - val_acc: 0.4163 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2696 - acc: 0.5352\n",
      "Epoch 29: val_acc improved from 0.43071 to 0.43669, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.2696 - acc: 0.5352 - val_loss: 1.7989 - val_acc: 0.4367 - lr: 1.0000e-04\n",
      "Epoch 30/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2239 - acc: 0.5556\n",
      "Epoch 30: val_acc improved from 0.43669 to 0.44267, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.2239 - acc: 0.5556 - val_loss: 1.8099 - val_acc: 0.4427 - lr: 1.0000e-04\n",
      "Epoch 31/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1888 - acc: 0.5706\n",
      "Epoch 31: val_acc did not improve from 0.44267\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.1888 - acc: 0.5706 - val_loss: 1.8158 - val_acc: 0.4402 - lr: 1.0000e-04\n",
      "Epoch 32/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1675 - acc: 0.5757\n",
      "Epoch 32: val_acc did not improve from 0.44267\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.1675 - acc: 0.5757 - val_loss: 1.8199 - val_acc: 0.4407 - lr: 1.0000e-04\n",
      "Epoch 33/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1451 - acc: 0.5836\n",
      "Epoch 33: val_acc improved from 0.44267 to 0.44616, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.1451 - acc: 0.5836 - val_loss: 1.8304 - val_acc: 0.4462 - lr: 1.0000e-04\n",
      "Epoch 34/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1354 - acc: 0.5884\n",
      "Epoch 34: val_acc did not improve from 0.44616\n",
      "268/268 [==============================] - 82s 308ms/step - loss: 1.1354 - acc: 0.5884 - val_loss: 1.8526 - val_acc: 0.4437 - lr: 1.0000e-04\n",
      "Epoch 35/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1252 - acc: 0.5883\n",
      "Epoch 35: val_acc did not improve from 0.44616\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.1252 - acc: 0.5883 - val_loss: 1.8529 - val_acc: 0.4412 - lr: 1.0000e-04\n",
      "Epoch 36/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1038 - acc: 0.5926\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 36: val_acc improved from 0.44616 to 0.44965, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.1038 - acc: 0.5926 - val_loss: 1.8722 - val_acc: 0.4497 - lr: 1.0000e-04\n",
      "Epoch 37/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0849 - acc: 0.6077\n",
      "Epoch 37: val_acc did not improve from 0.44965\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.0849 - acc: 0.6077 - val_loss: 1.8680 - val_acc: 0.4432 - lr: 1.0000e-05\n",
      "Epoch 38/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0767 - acc: 0.6098\n",
      "Epoch 38: val_acc did not improve from 0.44965\n",
      "268/268 [==============================] - 82s 307ms/step - loss: 1.0767 - acc: 0.6098 - val_loss: 1.8677 - val_acc: 0.4437 - lr: 1.0000e-05\n",
      "Epoch 39/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0665 - acc: 0.6177\n",
      "Epoch 39: val_acc improved from 0.44965 to 0.45065, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_123.hdf5\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.0665 - acc: 0.6177 - val_loss: 1.8689 - val_acc: 0.4506 - lr: 1.0000e-05\n",
      "Epoch 40/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0759 - acc: 0.6123\n",
      "Epoch 40: val_acc did not improve from 0.45065\n",
      "268/268 [==============================] - 82s 306ms/step - loss: 1.0759 - acc: 0.6123 - val_loss: 1.8715 - val_acc: 0.4407 - lr: 1.0000e-05\n",
      "Epoch 40: early stopping\n",
      "\n",
      "Running model with seed 456\n",
      "Train Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 2711, NLoS samples count: 107\n",
      "scenario33 - LoS samples count: 3317, NLoS samples count: 121\n",
      "scenario34 - LoS samples count: 3676, NLoS samples count: 96\n",
      "\n",
      "Test Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 283, NLoS samples count: 14\n",
      "scenario33 - LoS samples count: 384, NLoS samples count: 15\n",
      "scenario34 - LoS samples count: 406, NLoS samples count: 13\n",
      "LoS Train Shape: (9704, 5, 150, 150, 4), LoS Test Shape: (1073, 5, 150, 150, 4)\n",
      "NLoS Train Shape: (324, 5, 150, 150, 4), NLoS Test Shape: (42, 5, 150, 150, 4)\n",
      "Train Labels Shape: (10028, 64)\n",
      "Test Labels Shape: (1115, 64)\n",
      "Train LoS Labels Shape: (9704, 64)\n",
      "Train NLoS Labels Shape: (324, 64)\n",
      "Test LoS Labels Shape: (1073, 64)\n",
      "Test NLoS Labels Shape: (42, 64)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_2 (TimeDis  (None, 5, 256)           341076    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 64)                61824     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 411,220\n",
      "Trainable params: 410,612\n",
      "Non-trainable params: 608\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.8367 - acc: 0.0987\n",
      "Epoch 1: val_acc improved from -inf to 0.12363, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 91s 328ms/step - loss: 3.8367 - acc: 0.0987 - val_loss: 3.5158 - val_acc: 0.1236 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.4586 - acc: 0.1349\n",
      "Epoch 2: val_acc improved from 0.12363 to 0.16451, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 84s 313ms/step - loss: 3.4586 - acc: 0.1349 - val_loss: 3.1788 - val_acc: 0.1645 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.1646 - acc: 0.1649\n",
      "Epoch 3: val_acc improved from 0.16451 to 0.19691, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 84s 312ms/step - loss: 3.1646 - acc: 0.1649 - val_loss: 2.9551 - val_acc: 0.1969 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.9153 - acc: 0.1981\n",
      "Epoch 4: val_acc improved from 0.19691 to 0.24776, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 2.9153 - acc: 0.1981 - val_loss: 2.7155 - val_acc: 0.2478 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.6994 - acc: 0.2296\n",
      "Epoch 5: val_acc improved from 0.24776 to 0.27468, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 2.6994 - acc: 0.2296 - val_loss: 2.4473 - val_acc: 0.2747 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.4949 - acc: 0.2689\n",
      "Epoch 6: val_acc improved from 0.27468 to 0.30259, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 2.4949 - acc: 0.2689 - val_loss: 2.2949 - val_acc: 0.3026 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.3286 - acc: 0.2964\n",
      "Epoch 7: val_acc improved from 0.30259 to 0.31505, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 2.3286 - acc: 0.2964 - val_loss: 2.1217 - val_acc: 0.3151 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.1987 - acc: 0.3220\n",
      "Epoch 8: val_acc improved from 0.31505 to 0.32602, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 2.1987 - acc: 0.3220 - val_loss: 2.0841 - val_acc: 0.3260 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.1202 - acc: 0.3389\n",
      "Epoch 9: val_acc improved from 0.32602 to 0.35543, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 2.1202 - acc: 0.3389 - val_loss: 1.9842 - val_acc: 0.3554 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.0323 - acc: 0.3611\n",
      "Epoch 10: val_acc did not improve from 0.35543\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 2.0323 - acc: 0.3611 - val_loss: 1.9884 - val_acc: 0.3554 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.9527 - acc: 0.3836\n",
      "Epoch 11: val_acc improved from 0.35543 to 0.37687, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.9527 - acc: 0.3836 - val_loss: 1.8477 - val_acc: 0.3769 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8734 - acc: 0.3886\n",
      "Epoch 12: val_acc improved from 0.37687 to 0.38485, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.8734 - acc: 0.3886 - val_loss: 1.8417 - val_acc: 0.3848 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8413 - acc: 0.3929\n",
      "Epoch 13: val_acc improved from 0.38485 to 0.38833, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.8413 - acc: 0.3929 - val_loss: 1.8389 - val_acc: 0.3883 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8079 - acc: 0.4051\n",
      "Epoch 14: val_acc did not improve from 0.38833\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.8079 - acc: 0.4051 - val_loss: 1.9019 - val_acc: 0.3574 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7799 - acc: 0.4107\n",
      "Epoch 15: val_acc improved from 0.38833 to 0.41276, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.7799 - acc: 0.4107 - val_loss: 1.7106 - val_acc: 0.4128 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6995 - acc: 0.4274\n",
      "Epoch 16: val_acc did not improve from 0.41276\n",
      "268/268 [==============================] - 82s 307ms/step - loss: 1.6995 - acc: 0.4274 - val_loss: 1.8527 - val_acc: 0.3903 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6902 - acc: 0.4261\n",
      "Epoch 17: val_acc improved from 0.41276 to 0.41476, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.6902 - acc: 0.4261 - val_loss: 1.7061 - val_acc: 0.4148 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6413 - acc: 0.4379\n",
      "Epoch 18: val_acc did not improve from 0.41476\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.6413 - acc: 0.4379 - val_loss: 2.2498 - val_acc: 0.3185 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6158 - acc: 0.4481\n",
      "Epoch 19: val_acc improved from 0.41476 to 0.42124, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.6158 - acc: 0.4481 - val_loss: 1.7071 - val_acc: 0.4212 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6059 - acc: 0.4437\n",
      "Epoch 20: val_acc improved from 0.42124 to 0.42572, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 82s 307ms/step - loss: 1.6059 - acc: 0.4437 - val_loss: 1.7185 - val_acc: 0.4257 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5782 - acc: 0.4627\n",
      "Epoch 21: val_acc did not improve from 0.42572\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.5782 - acc: 0.4627 - val_loss: 1.7275 - val_acc: 0.4177 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5677 - acc: 0.4584\n",
      "Epoch 22: val_acc improved from 0.42572 to 0.43071, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.5677 - acc: 0.4584 - val_loss: 1.6576 - val_acc: 0.4307 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5311 - acc: 0.4660\n",
      "Epoch 23: val_acc did not improve from 0.43071\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.5311 - acc: 0.4660 - val_loss: 1.7463 - val_acc: 0.4202 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5202 - acc: 0.4637\n",
      "Epoch 24: val_acc improved from 0.43071 to 0.43968, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.5202 - acc: 0.4637 - val_loss: 1.7022 - val_acc: 0.4397 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4982 - acc: 0.4774\n",
      "Epoch 25: val_acc did not improve from 0.43968\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.4982 - acc: 0.4774 - val_loss: 1.6971 - val_acc: 0.4138 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4715 - acc: 0.4840\n",
      "Epoch 26: val_acc did not improve from 0.43968\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.4715 - acc: 0.4840 - val_loss: 1.6915 - val_acc: 0.4277 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4324 - acc: 0.4899\n",
      "Epoch 27: val_acc did not improve from 0.43968\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.4324 - acc: 0.4899 - val_loss: 1.6842 - val_acc: 0.4337 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4175 - acc: 0.4950\n",
      "Epoch 28: val_acc did not improve from 0.43968\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.4175 - acc: 0.4950 - val_loss: 1.7154 - val_acc: 0.4267 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4131 - acc: 0.4975\n",
      "Epoch 29: val_acc did not improve from 0.43968\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.4131 - acc: 0.4975 - val_loss: 1.7510 - val_acc: 0.4217 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3870 - acc: 0.5035\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 30: val_acc did not improve from 0.43968\n",
      "268/268 [==============================] - 82s 308ms/step - loss: 1.3870 - acc: 0.5035 - val_loss: 1.7513 - val_acc: 0.4227 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2850 - acc: 0.5339\n",
      "Epoch 31: val_acc improved from 0.43968 to 0.44566, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 82s 307ms/step - loss: 1.2850 - acc: 0.5339 - val_loss: 1.6699 - val_acc: 0.4457 - lr: 1.0000e-04\n",
      "Epoch 32/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2235 - acc: 0.5550\n",
      "Epoch 32: val_acc improved from 0.44566 to 0.44616, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 82s 308ms/step - loss: 1.2235 - acc: 0.5550 - val_loss: 1.6722 - val_acc: 0.4462 - lr: 1.0000e-04\n",
      "Epoch 33/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1934 - acc: 0.5692\n",
      "Epoch 33: val_acc did not improve from 0.44616\n",
      "268/268 [==============================] - 82s 307ms/step - loss: 1.1934 - acc: 0.5692 - val_loss: 1.6858 - val_acc: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 34/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1716 - acc: 0.5740\n",
      "Epoch 34: val_acc did not improve from 0.44616\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.1716 - acc: 0.5740 - val_loss: 1.6872 - val_acc: 0.4372 - lr: 1.0000e-04\n",
      "Epoch 35/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1580 - acc: 0.5858\n",
      "Epoch 35: val_acc improved from 0.44616 to 0.45065, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_456.hdf5\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.1580 - acc: 0.5858 - val_loss: 1.6869 - val_acc: 0.4506 - lr: 1.0000e-04\n",
      "Epoch 36/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1243 - acc: 0.5890\n",
      "Epoch 36: val_acc did not improve from 0.45065\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.1243 - acc: 0.5890 - val_loss: 1.6885 - val_acc: 0.4487 - lr: 1.0000e-04\n",
      "Epoch 37/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1163 - acc: 0.5906\n",
      "Epoch 37: val_acc did not improve from 0.45065\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.1163 - acc: 0.5906 - val_loss: 1.7099 - val_acc: 0.4482 - lr: 1.0000e-04\n",
      "Epoch 38/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0984 - acc: 0.6038\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 38: val_acc did not improve from 0.45065\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.0984 - acc: 0.6038 - val_loss: 1.7061 - val_acc: 0.4472 - lr: 1.0000e-04\n",
      "Epoch 39/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0778 - acc: 0.6124\n",
      "Epoch 39: val_acc did not improve from 0.45065\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.0778 - acc: 0.6124 - val_loss: 1.7085 - val_acc: 0.4477 - lr: 1.0000e-05\n",
      "Epoch 40/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0773 - acc: 0.6060\n",
      "Epoch 40: val_acc did not improve from 0.45065\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.0773 - acc: 0.6060 - val_loss: 1.7141 - val_acc: 0.4437 - lr: 1.0000e-05\n",
      "Epoch 41/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0766 - acc: 0.6146\n",
      "Epoch 41: val_acc did not improve from 0.45065\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.0766 - acc: 0.6146 - val_loss: 1.7192 - val_acc: 0.4422 - lr: 1.0000e-05\n",
      "Epoch 42/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0720 - acc: 0.6122\n",
      "Epoch 42: val_acc did not improve from 0.45065\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.0720 - acc: 0.6122 - val_loss: 1.7178 - val_acc: 0.4452 - lr: 1.0000e-05\n",
      "Epoch 42: early stopping\n",
      "\n",
      "Running model with seed 789\n",
      "Train Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 2706, NLoS samples count: 105\n",
      "scenario33 - LoS samples count: 3343, NLoS samples count: 126\n",
      "scenario34 - LoS samples count: 3652, NLoS samples count: 96\n",
      "\n",
      "Test Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 288, NLoS samples count: 16\n",
      "scenario33 - LoS samples count: 358, NLoS samples count: 10\n",
      "scenario34 - LoS samples count: 430, NLoS samples count: 13\n",
      "LoS Train Shape: (9701, 5, 150, 150, 4), LoS Test Shape: (1076, 5, 150, 150, 4)\n",
      "NLoS Train Shape: (327, 5, 150, 150, 4), NLoS Test Shape: (39, 5, 150, 150, 4)\n",
      "Train Labels Shape: (10028, 64)\n",
      "Test Labels Shape: (1115, 64)\n",
      "Train LoS Labels Shape: (9701, 64)\n",
      "Train NLoS Labels Shape: (327, 64)\n",
      "Test LoS Labels Shape: (1076, 64)\n",
      "Test NLoS Labels Shape: (39, 64)\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_3 (TimeDis  (None, 5, 256)           341076    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 64)                61824     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 411,220\n",
      "Trainable params: 410,612\n",
      "Non-trainable params: 608\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.8081 - acc: 0.0965\n",
      "Epoch 1: val_acc improved from -inf to 0.13161, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 89s 322ms/step - loss: 3.8081 - acc: 0.0965 - val_loss: 3.5034 - val_acc: 0.1316 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.4800 - acc: 0.1228\n",
      "Epoch 2: val_acc improved from 0.13161 to 0.16700, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 3.4800 - acc: 0.1228 - val_loss: 3.1904 - val_acc: 0.1670 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.1812 - acc: 0.1629\n",
      "Epoch 3: val_acc improved from 0.16700 to 0.20738, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 3.1812 - acc: 0.1629 - val_loss: 2.8892 - val_acc: 0.2074 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.8927 - acc: 0.1996\n",
      "Epoch 4: val_acc improved from 0.20738 to 0.25573, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 2.8927 - acc: 0.1996 - val_loss: 2.6013 - val_acc: 0.2557 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.6626 - acc: 0.2330\n",
      "Epoch 5: val_acc improved from 0.25573 to 0.28116, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 82s 307ms/step - loss: 2.6626 - acc: 0.2330 - val_loss: 2.4115 - val_acc: 0.2812 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.5079 - acc: 0.2632\n",
      "Epoch 6: val_acc improved from 0.28116 to 0.28215, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 2.5079 - acc: 0.2632 - val_loss: 2.3268 - val_acc: 0.2822 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.3649 - acc: 0.2841\n",
      "Epoch 7: val_acc improved from 0.28215 to 0.31505, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 2.3649 - acc: 0.2841 - val_loss: 2.2531 - val_acc: 0.3151 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.2442 - acc: 0.3123\n",
      "Epoch 8: val_acc improved from 0.31505 to 0.34796, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 2.2442 - acc: 0.3123 - val_loss: 2.0643 - val_acc: 0.3480 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.1516 - acc: 0.3287\n",
      "Epoch 9: val_acc did not improve from 0.34796\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 2.1516 - acc: 0.3287 - val_loss: 2.0397 - val_acc: 0.3455 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.0842 - acc: 0.3446\n",
      "Epoch 10: val_acc improved from 0.34796 to 0.36939, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 84s 314ms/step - loss: 2.0842 - acc: 0.3446 - val_loss: 1.9506 - val_acc: 0.3694 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.0095 - acc: 0.3666\n",
      "Epoch 11: val_acc did not improve from 0.36939\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 2.0095 - acc: 0.3666 - val_loss: 2.1954 - val_acc: 0.3410 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.9779 - acc: 0.3702\n",
      "Epoch 12: val_acc improved from 0.36939 to 0.38136, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.9779 - acc: 0.3702 - val_loss: 1.8433 - val_acc: 0.3814 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.9365 - acc: 0.3778\n",
      "Epoch 13: val_acc improved from 0.38136 to 0.40179, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.9365 - acc: 0.3778 - val_loss: 1.8109 - val_acc: 0.4018 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8527 - acc: 0.3917\n",
      "Epoch 14: val_acc did not improve from 0.40179\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.8527 - acc: 0.3917 - val_loss: 1.7898 - val_acc: 0.3948 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8115 - acc: 0.4018\n",
      "Epoch 15: val_acc did not improve from 0.40179\n",
      "268/268 [==============================] - 83s 308ms/step - loss: 1.8115 - acc: 0.4018 - val_loss: 2.4742 - val_acc: 0.2832 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7588 - acc: 0.4164\n",
      "Epoch 16: val_acc improved from 0.40179 to 0.40479, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.7588 - acc: 0.4164 - val_loss: 1.7906 - val_acc: 0.4048 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7586 - acc: 0.4129\n",
      "Epoch 17: val_acc did not improve from 0.40479\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.7586 - acc: 0.4129 - val_loss: 1.8460 - val_acc: 0.3709 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7115 - acc: 0.4268\n",
      "Epoch 18: val_acc did not improve from 0.40479\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.7115 - acc: 0.4268 - val_loss: 1.8234 - val_acc: 0.3978 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6688 - acc: 0.4402\n",
      "Epoch 19: val_acc did not improve from 0.40479\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.6688 - acc: 0.4402 - val_loss: 2.0324 - val_acc: 0.3699 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6504 - acc: 0.4328\n",
      "Epoch 20: val_acc did not improve from 0.40479\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.6504 - acc: 0.4328 - val_loss: 1.8196 - val_acc: 0.4033 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6157 - acc: 0.4521\n",
      "Epoch 21: val_acc improved from 0.40479 to 0.40927, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 83s 312ms/step - loss: 1.6157 - acc: 0.4521 - val_loss: 1.7513 - val_acc: 0.4093 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6151 - acc: 0.4491\n",
      "Epoch 22: val_acc improved from 0.40927 to 0.41775, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.6151 - acc: 0.4491 - val_loss: 1.7274 - val_acc: 0.4177 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5712 - acc: 0.4574\n",
      "Epoch 23: val_acc did not improve from 0.41775\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.5712 - acc: 0.4574 - val_loss: 1.8481 - val_acc: 0.3973 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5417 - acc: 0.4666\n",
      "Epoch 24: val_acc improved from 0.41775 to 0.41974, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.5417 - acc: 0.4666 - val_loss: 1.7286 - val_acc: 0.4197 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5474 - acc: 0.4688\n",
      "Epoch 25: val_acc improved from 0.41974 to 0.42921, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.5474 - acc: 0.4688 - val_loss: 1.7384 - val_acc: 0.4292 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5247 - acc: 0.4683\n",
      "Epoch 26: val_acc improved from 0.42921 to 0.43170, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.5247 - acc: 0.4683 - val_loss: 1.7490 - val_acc: 0.4317 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4917 - acc: 0.4852\n",
      "Epoch 27: val_acc did not improve from 0.43170\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.4917 - acc: 0.4852 - val_loss: 2.0267 - val_acc: 0.3704 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4861 - acc: 0.4803\n",
      "Epoch 28: val_acc did not improve from 0.43170\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.4861 - acc: 0.4803 - val_loss: 1.8069 - val_acc: 0.4083 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4604 - acc: 0.4892\n",
      "Epoch 29: val_acc did not improve from 0.43170\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.4604 - acc: 0.4892 - val_loss: 1.7686 - val_acc: 0.4242 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4360 - acc: 0.4910\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 30: val_acc did not improve from 0.43170\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.4360 - acc: 0.4910 - val_loss: 1.7400 - val_acc: 0.4182 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3135 - acc: 0.5274\n",
      "Epoch 31: val_acc improved from 0.43170 to 0.43719, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.3135 - acc: 0.5274 - val_loss: 1.6856 - val_acc: 0.4372 - lr: 1.0000e-04\n",
      "Epoch 32/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2610 - acc: 0.5486\n",
      "Epoch 32: val_acc did not improve from 0.43719\n",
      "268/268 [==============================] - 84s 312ms/step - loss: 1.2610 - acc: 0.5486 - val_loss: 1.6936 - val_acc: 0.4352 - lr: 1.0000e-04\n",
      "Epoch 33/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2359 - acc: 0.5491\n",
      "Epoch 33: val_acc improved from 0.43719 to 0.44317, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 84s 312ms/step - loss: 1.2359 - acc: 0.5491 - val_loss: 1.6953 - val_acc: 0.4432 - lr: 1.0000e-04\n",
      "Epoch 34/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2231 - acc: 0.5603\n",
      "Epoch 34: val_acc improved from 0.44317 to 0.44367, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.2231 - acc: 0.5603 - val_loss: 1.7016 - val_acc: 0.4437 - lr: 1.0000e-04\n",
      "Epoch 35/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2035 - acc: 0.5674\n",
      "Epoch 35: val_acc improved from 0.44367 to 0.44716, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.2035 - acc: 0.5674 - val_loss: 1.7037 - val_acc: 0.4472 - lr: 1.0000e-04\n",
      "Epoch 36/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1773 - acc: 0.5752\n",
      "Epoch 36: val_acc improved from 0.44716 to 0.45214, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.1773 - acc: 0.5752 - val_loss: 1.7237 - val_acc: 0.4521 - lr: 1.0000e-04\n",
      "Epoch 37/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1746 - acc: 0.5793\n",
      "Epoch 37: val_acc improved from 0.45214 to 0.45264, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.1746 - acc: 0.5793 - val_loss: 1.7245 - val_acc: 0.4526 - lr: 1.0000e-04\n",
      "Epoch 38/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1642 - acc: 0.5829\n",
      "Epoch 38: val_acc did not improve from 0.45264\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.1642 - acc: 0.5829 - val_loss: 1.7265 - val_acc: 0.4526 - lr: 1.0000e-04\n",
      "Epoch 39/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1365 - acc: 0.5905\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 39: val_acc did not improve from 0.45264\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.1365 - acc: 0.5905 - val_loss: 1.7381 - val_acc: 0.4521 - lr: 1.0000e-04\n",
      "Epoch 40/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1268 - acc: 0.5990\n",
      "Epoch 40: val_acc improved from 0.45264 to 0.45314, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.1268 - acc: 0.5990 - val_loss: 1.7403 - val_acc: 0.4531 - lr: 1.0000e-05\n",
      "Epoch 41/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1123 - acc: 0.6027\n",
      "Epoch 41: val_acc improved from 0.45314 to 0.45414, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_789.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 1.1123 - acc: 0.6027 - val_loss: 1.7457 - val_acc: 0.4541 - lr: 1.0000e-05\n",
      "Epoch 42/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1227 - acc: 0.6052\n",
      "Epoch 42: val_acc did not improve from 0.45414\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.1227 - acc: 0.6052 - val_loss: 1.7443 - val_acc: 0.4501 - lr: 1.0000e-05\n",
      "Epoch 43/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1089 - acc: 0.6043\n",
      "Epoch 43: val_acc did not improve from 0.45414\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.1089 - acc: 0.6043 - val_loss: 1.7412 - val_acc: 0.4497 - lr: 1.0000e-05\n",
      "Epoch 44/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1161 - acc: 0.6033\n",
      "Epoch 44: val_acc did not improve from 0.45414\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.1161 - acc: 0.6033 - val_loss: 1.7485 - val_acc: 0.4521 - lr: 1.0000e-05\n",
      "Epoch 45/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1167 - acc: 0.6000\n",
      "Epoch 45: val_acc did not improve from 0.45414\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.1167 - acc: 0.6000 - val_loss: 1.7468 - val_acc: 0.4511 - lr: 1.0000e-05\n",
      "Epoch 46/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1069 - acc: 0.6071\n",
      "Epoch 46: val_acc did not improve from 0.45414\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.1069 - acc: 0.6071 - val_loss: 1.7483 - val_acc: 0.4511 - lr: 1.0000e-05\n",
      "Epoch 47/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1118 - acc: 0.5986\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 47: val_acc did not improve from 0.45414\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.1118 - acc: 0.5986 - val_loss: 1.7484 - val_acc: 0.4487 - lr: 1.0000e-05\n",
      "Epoch 48/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1068 - acc: 0.6015\n",
      "Epoch 48: val_acc did not improve from 0.45414\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.1068 - acc: 0.6015 - val_loss: 1.7523 - val_acc: 0.4526 - lr: 1.0000e-06\n",
      "Epoch 49/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1001 - acc: 0.6030\n",
      "Epoch 49: val_acc did not improve from 0.45414\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.1001 - acc: 0.6030 - val_loss: 1.7469 - val_acc: 0.4477 - lr: 1.0000e-06\n",
      "Epoch 50/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1020 - acc: 0.6032\n",
      "Epoch 50: val_acc did not improve from 0.45414\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.1020 - acc: 0.6032 - val_loss: 1.7520 - val_acc: 0.4477 - lr: 1.0000e-06\n",
      "Epoch 51/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1143 - acc: 0.6038\n",
      "Epoch 51: val_acc did not improve from 0.45414\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.1143 - acc: 0.6038 - val_loss: 1.7487 - val_acc: 0.4526 - lr: 1.0000e-06\n",
      "Epoch 51: early stopping\n",
      "\n",
      "Running model with seed 101112\n",
      "Train Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 2692, NLoS samples count: 104\n",
      "scenario33 - LoS samples count: 3330, NLoS samples count: 120\n",
      "scenario34 - LoS samples count: 3684, NLoS samples count: 98\n",
      "\n",
      "Test Data Scenario Counts:\n",
      "scenario32 - LoS samples count: 302, NLoS samples count: 17\n",
      "scenario33 - LoS samples count: 371, NLoS samples count: 16\n",
      "scenario34 - LoS samples count: 398, NLoS samples count: 11\n",
      "LoS Train Shape: (9706, 5, 150, 150, 4), LoS Test Shape: (1071, 5, 150, 150, 4)\n",
      "NLoS Train Shape: (322, 5, 150, 150, 4), NLoS Test Shape: (44, 5, 150, 150, 4)\n",
      "Train Labels Shape: (10028, 64)\n",
      "Test Labels Shape: (1115, 64)\n",
      "Train LoS Labels Shape: (9706, 64)\n",
      "Train NLoS Labels Shape: (322, 64)\n",
      "Test LoS Labels Shape: (1071, 64)\n",
      "Test NLoS Labels Shape: (44, 64)\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_4 (TimeDis  (None, 5, 256)           341076    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 64)                61824     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 411,220\n",
      "Trainable params: 410,612\n",
      "Non-trainable params: 608\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.8281 - acc: 0.1010\n",
      "Epoch 1: val_acc improved from -inf to 0.12463, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 95s 332ms/step - loss: 3.8281 - acc: 0.1010 - val_loss: 3.5741 - val_acc: 0.1246 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.4449 - acc: 0.1344\n",
      "Epoch 2: val_acc improved from 0.12463 to 0.16251, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 83s 309ms/step - loss: 3.4449 - acc: 0.1344 - val_loss: 3.1358 - val_acc: 0.1625 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 3.1142 - acc: 0.1704\n",
      "Epoch 3: val_acc improved from 0.16251 to 0.20987, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 84s 312ms/step - loss: 3.1142 - acc: 0.1704 - val_loss: 2.8616 - val_acc: 0.2099 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.8585 - acc: 0.2046\n",
      "Epoch 4: val_acc improved from 0.20987 to 0.23779, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 2.8585 - acc: 0.2046 - val_loss: 2.6604 - val_acc: 0.2378 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.6289 - acc: 0.2443\n",
      "Epoch 5: val_acc improved from 0.23779 to 0.27418, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 2.6289 - acc: 0.2443 - val_loss: 2.4534 - val_acc: 0.2742 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.4694 - acc: 0.2751\n",
      "Epoch 6: val_acc improved from 0.27418 to 0.28215, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 84s 314ms/step - loss: 2.4694 - acc: 0.2751 - val_loss: 2.3642 - val_acc: 0.2822 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.3293 - acc: 0.2928\n",
      "Epoch 7: val_acc improved from 0.28215 to 0.31456, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 2.3293 - acc: 0.2928 - val_loss: 2.2298 - val_acc: 0.3146 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.1883 - acc: 0.3216\n",
      "Epoch 8: val_acc improved from 0.31456 to 0.32502, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 84s 313ms/step - loss: 2.1883 - acc: 0.3216 - val_loss: 2.1342 - val_acc: 0.3250 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.1170 - acc: 0.3358\n",
      "Epoch 9: val_acc improved from 0.32502 to 0.37089, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 84s 312ms/step - loss: 2.1170 - acc: 0.3358 - val_loss: 2.0296 - val_acc: 0.3709 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 2.0251 - acc: 0.3601\n",
      "Epoch 10: val_acc did not improve from 0.37089\n",
      "268/268 [==============================] - 84s 313ms/step - loss: 2.0251 - acc: 0.3601 - val_loss: 2.0067 - val_acc: 0.3659 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.9434 - acc: 0.3762\n",
      "Epoch 11: val_acc did not improve from 0.37089\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.9434 - acc: 0.3762 - val_loss: 1.9699 - val_acc: 0.3679 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8729 - acc: 0.3886\n",
      "Epoch 12: val_acc did not improve from 0.37089\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.8729 - acc: 0.3886 - val_loss: 2.0617 - val_acc: 0.3529 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.8233 - acc: 0.4048\n",
      "Epoch 13: val_acc did not improve from 0.37089\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.8233 - acc: 0.4048 - val_loss: 1.9232 - val_acc: 0.3674 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7771 - acc: 0.4081\n",
      "Epoch 14: val_acc improved from 0.37089 to 0.37836, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 84s 312ms/step - loss: 1.7771 - acc: 0.4081 - val_loss: 1.8785 - val_acc: 0.3784 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7319 - acc: 0.4167\n",
      "Epoch 15: val_acc improved from 0.37836 to 0.39083, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 84s 312ms/step - loss: 1.7319 - acc: 0.4167 - val_loss: 1.8276 - val_acc: 0.3908 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.7063 - acc: 0.4279\n",
      "Epoch 16: val_acc improved from 0.39083 to 0.39631, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 84s 312ms/step - loss: 1.7063 - acc: 0.4279 - val_loss: 1.8817 - val_acc: 0.3963 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6702 - acc: 0.4353\n",
      "Epoch 17: val_acc did not improve from 0.39631\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.6702 - acc: 0.4353 - val_loss: 1.8979 - val_acc: 0.3908 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6294 - acc: 0.4439\n",
      "Epoch 18: val_acc improved from 0.39631 to 0.40080, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.6294 - acc: 0.4439 - val_loss: 1.8204 - val_acc: 0.4008 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.6006 - acc: 0.4445\n",
      "Epoch 19: val_acc improved from 0.40080 to 0.40429, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 84s 313ms/step - loss: 1.6006 - acc: 0.4445 - val_loss: 1.8058 - val_acc: 0.4043 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5931 - acc: 0.4555\n",
      "Epoch 20: val_acc improved from 0.40429 to 0.41575, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.5931 - acc: 0.4555 - val_loss: 1.8034 - val_acc: 0.4158 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5581 - acc: 0.4521\n",
      "Epoch 21: val_acc did not improve from 0.41575\n",
      "268/268 [==============================] - 84s 312ms/step - loss: 1.5581 - acc: 0.4521 - val_loss: 1.8105 - val_acc: 0.3998 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5322 - acc: 0.4637\n",
      "Epoch 22: val_acc improved from 0.41575 to 0.43719, saving model to chkp/LVRG_v5_remake_v1_5_multipleRuns_seed_101112.hdf5\n",
      "268/268 [==============================] - 84s 312ms/step - loss: 1.5322 - acc: 0.4637 - val_loss: 1.7878 - val_acc: 0.4372 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.5133 - acc: 0.4690\n",
      "Epoch 23: val_acc did not improve from 0.43719\n",
      "268/268 [==============================] - 84s 313ms/step - loss: 1.5133 - acc: 0.4690 - val_loss: 1.8345 - val_acc: 0.4078 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4873 - acc: 0.4781\n",
      "Epoch 24: val_acc did not improve from 0.43719\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.4873 - acc: 0.4781 - val_loss: 1.8495 - val_acc: 0.4113 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4813 - acc: 0.4799\n",
      "Epoch 25: val_acc did not improve from 0.43719\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.4813 - acc: 0.4799 - val_loss: 1.8226 - val_acc: 0.4177 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4397 - acc: 0.4868\n",
      "Epoch 26: val_acc did not improve from 0.43719\n",
      "268/268 [==============================] - 84s 312ms/step - loss: 1.4397 - acc: 0.4868 - val_loss: 1.8763 - val_acc: 0.3913 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4447 - acc: 0.4828\n",
      "Epoch 27: val_acc did not improve from 0.43719\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.4447 - acc: 0.4828 - val_loss: 1.8093 - val_acc: 0.4252 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4026 - acc: 0.4985\n",
      "Epoch 28: val_acc did not improve from 0.43719\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.4026 - acc: 0.4985 - val_loss: 1.8155 - val_acc: 0.4143 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.4130 - acc: 0.4979\n",
      "Epoch 29: val_acc did not improve from 0.43719\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.4130 - acc: 0.4979 - val_loss: 1.8499 - val_acc: 0.4177 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.3682 - acc: 0.5007\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 30: val_acc did not improve from 0.43719\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.3682 - acc: 0.5007 - val_loss: 1.8266 - val_acc: 0.4282 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2757 - acc: 0.5379\n",
      "Epoch 31: val_acc did not improve from 0.43719\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.2757 - acc: 0.5379 - val_loss: 1.8008 - val_acc: 0.4352 - lr: 1.0000e-04\n",
      "Epoch 32/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.2182 - acc: 0.5548\n",
      "Epoch 32: val_acc did not improve from 0.43719\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.2182 - acc: 0.5548 - val_loss: 1.8042 - val_acc: 0.4327 - lr: 1.0000e-04\n",
      "Epoch 33/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1865 - acc: 0.5676\n",
      "Epoch 33: val_acc did not improve from 0.43719\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.1865 - acc: 0.5676 - val_loss: 1.8157 - val_acc: 0.4292 - lr: 1.0000e-04\n",
      "Epoch 34/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1772 - acc: 0.5711\n",
      "Epoch 34: val_acc did not improve from 0.43719\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.1772 - acc: 0.5711 - val_loss: 1.8220 - val_acc: 0.4332 - lr: 1.0000e-04\n",
      "Epoch 35/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1480 - acc: 0.5878\n",
      "Epoch 35: val_acc did not improve from 0.43719\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.1480 - acc: 0.5878 - val_loss: 1.8416 - val_acc: 0.4312 - lr: 1.0000e-04\n",
      "Epoch 36/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1312 - acc: 0.5865\n",
      "Epoch 36: val_acc did not improve from 0.43719\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.1312 - acc: 0.5865 - val_loss: 1.8452 - val_acc: 0.4277 - lr: 1.0000e-04\n",
      "Epoch 37/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1195 - acc: 0.5955\n",
      "Epoch 37: val_acc did not improve from 0.43719\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.1195 - acc: 0.5955 - val_loss: 1.8495 - val_acc: 0.4322 - lr: 1.0000e-04\n",
      "Epoch 38/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.1078 - acc: 0.5956\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 38: val_acc did not improve from 0.43719\n",
      "268/268 [==============================] - 83s 310ms/step - loss: 1.1078 - acc: 0.5956 - val_loss: 1.8552 - val_acc: 0.4302 - lr: 1.0000e-04\n",
      "Epoch 39/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0887 - acc: 0.6057\n",
      "Epoch 39: val_acc did not improve from 0.43719\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.0887 - acc: 0.6057 - val_loss: 1.8665 - val_acc: 0.4342 - lr: 1.0000e-05\n",
      "Epoch 40/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0762 - acc: 0.6122\n",
      "Epoch 40: val_acc did not improve from 0.43719\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.0762 - acc: 0.6122 - val_loss: 1.8608 - val_acc: 0.4337 - lr: 1.0000e-05\n",
      "Epoch 41/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0790 - acc: 0.6087\n",
      "Epoch 41: val_acc did not improve from 0.43719\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.0790 - acc: 0.6087 - val_loss: 1.8660 - val_acc: 0.4297 - lr: 1.0000e-05\n",
      "Epoch 42/300\n",
      "268/268 [==============================] - ETA: 0s - loss: 1.0803 - acc: 0.6101\n",
      "Epoch 42: val_acc did not improve from 0.43719\n",
      "268/268 [==============================] - 83s 311ms/step - loss: 1.0803 - acc: 0.6101 - val_loss: 1.8581 - val_acc: 0.4317 - lr: 1.0000e-05\n",
      "Epoch 42: early stopping\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "seeds = [42, 123, 456, 789, 101112]\n",
    "\n",
    "results = []\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"\\nRunning model with seed {seed}\")\n",
    "    \n",
    "    # Train-Test Split with the current seed\n",
    "    X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "        multiModalData, classes, np.arange(len(multiModalData)), test_size=0.1, stratify=classes, random_state=seed)    \n",
    "    \n",
    "    #%% Scenarios and LoS NLoS analysis of train and test samples\n",
    "    df_train = pd.read_csv('./ml_challenge_dev_multi_modal_v3_all_scenarios_with_LoS_status.csv')\n",
    "\n",
    "    # Find LoS and NLoS samples in the train and test indices\n",
    "    train_los_indices = df_train[df_train['LoS_status'] == 'LoS'].index.intersection(train_indices)\n",
    "    train_nlos_indices = df_train[df_train['LoS_status'] == 'NLoS'].index.intersection(train_indices)\n",
    "    test_los_indices = df_train[df_train['LoS_status'] == 'LoS'].index.intersection(test_indices)\n",
    "    test_nlos_indices = df_train[df_train['LoS_status'] == 'NLoS'].index.intersection(test_indices)\n",
    "\n",
    "    # Verify that all train and test samples are classified\n",
    "    assert len(train_los_indices) + len(train_nlos_indices) == len(train_indices), \"Mismatch in total train samples\"\n",
    "    assert len(test_los_indices) + len(test_nlos_indices) == len(test_indices), \"Mismatch in total test samples\"\n",
    "\n",
    "    # Identify scenarios\n",
    "    scenario_path = df_train['unit2_loc_1']\n",
    "\n",
    "    # Function to count LoS and NLoS samples for a scenario\n",
    "    def count_scenario_samples(scenario_keyword, los_indices, nlos_indices):\n",
    "        scenario_indices = df_train[scenario_path.str.contains(scenario_keyword)].index\n",
    "        los_count = len(np.intersect1d(los_indices, scenario_indices))\n",
    "        nlos_count = len(np.intersect1d(nlos_indices, scenario_indices))\n",
    "        return los_count, nlos_count\n",
    "\n",
    "    # Count LoS and NLoS samples for each scenario in train and test sets\n",
    "    scenario_los_nlos_counts_train = {}\n",
    "    scenario_los_nlos_counts_test = {}\n",
    "    for scenario_keyword in ['scenario32', 'scenario33', 'scenario34']:\n",
    "        los_count_train, nlos_count_train = count_scenario_samples(scenario_keyword, train_los_indices, train_nlos_indices)\n",
    "        los_count_test, nlos_count_test = count_scenario_samples(scenario_keyword, test_los_indices, test_nlos_indices)\n",
    "        scenario_los_nlos_counts_train[scenario_keyword] = {'LoS': los_count_train, 'NLoS': nlos_count_train}\n",
    "        scenario_los_nlos_counts_test[scenario_keyword] = {'LoS': los_count_test, 'NLoS': nlos_count_test}\n",
    "\n",
    "    # Print the counts for each scenario in train and test sets\n",
    "    print(\"Train Data Scenario Counts:\")\n",
    "    for scenario, counts in scenario_los_nlos_counts_train.items():\n",
    "        print(f\"{scenario} - LoS samples count: {counts['LoS']}, NLoS samples count: {counts['NLoS']}\")\n",
    "\n",
    "    print(\"\\nTest Data Scenario Counts:\")\n",
    "    for scenario, counts in scenario_los_nlos_counts_test.items():\n",
    "        print(f\"{scenario} - LoS samples count: {counts['LoS']}, NLoS samples count: {counts['NLoS']}\")\n",
    "\n",
    "    # Extract LoS and NLoS samples from the modalities and classes\n",
    "    X_train_los = multiModalData[train_los_indices]\n",
    "    X_train_nlos = multiModalData[train_nlos_indices]\n",
    "    X_test_los = multiModalData[test_los_indices]\n",
    "    X_test_nlos = multiModalData[test_nlos_indices]\n",
    "    y_train_los = classes[train_los_indices]\n",
    "    y_train_nlos = classes[train_nlos_indices]\n",
    "    y_test_los = classes[test_los_indices]\n",
    "    y_test_nlos = classes[test_nlos_indices]\n",
    "\n",
    "    # Print shapes of train and test datasets for each modality\n",
    "    print(f'LoS Train Shape: {X_train_los.shape}, LoS Test Shape: {X_test_los.shape}')\n",
    "    print(f'NLoS Train Shape: {X_train_nlos.shape}, NLoS Test Shape: {X_test_nlos.shape}')\n",
    "\n",
    "    # Print shapes of train and test labels\n",
    "    print(f'Train Labels Shape: {y_train.shape}')\n",
    "    print(f'Test Labels Shape: {y_test.shape}')\n",
    "    print(f'Train LoS Labels Shape: {y_train_los.shape}')\n",
    "    print(f'Train NLoS Labels Shape: {y_train_nlos.shape}')\n",
    "    print(f'Test LoS Labels Shape: {y_test_los.shape}')\n",
    "    print(f'Test NLoS Labels Shape: {y_test_nlos.shape}')\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    # some global params\n",
    "    NBFRAME = 5\n",
    "    N_CLASSES = 64\n",
    "    INSHAPE = (5,imageX,imageY,4)\n",
    "    model = GRU_model(INSHAPE, N_CLASSES)\n",
    "    optimizer = keras.optimizers.Adam(0.001) \n",
    "    model.compile(optimizer, 'categorical_crossentropy', metrics=['acc'])\n",
    "    print(model.summary())\n",
    "\n",
    "    #Run the training\n",
    "    EPOCHS=300\n",
    "    BS = 30\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, mode='min', verbose=1),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=8, mode='min', verbose=1),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            f'chkp/{model_name}_seed_{seed}.hdf5', \n",
    "            monitor='val_acc',  # Monitor validation accuracy\n",
    "            save_best_only  = True,\n",
    "            mode='max',  # Maximize the monitored quantity\n",
    "            verbose=1),\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        validation_split = 0.2, #0\n",
    "        #validation_data=(X_val, y_val),\n",
    "        verbose=1,\n",
    "        #verbose='auto', #auto\n",
    "        epochs=EPOCHS,\n",
    "        batch_size =BS,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model with seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 01:35:31.580908: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-08-25 01:35:31.580941: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: edison\n",
      "2024-08-25 01:35:31.580946: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: edison\n",
      "2024-08-25 01:35:31.581091: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 560.35.3\n",
      "2024-08-25 01:35:31.581147: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: NOT_FOUND: could not find kernel module information in driver version file contents: \"NVRM version: NVIDIA UNIX Open Kernel Module for x86_64  560.35.03  Release Build  (dvs-builder@U16-I1-N07-12-3)  Fri Aug 16 21:42:42 UTC 2024\n",
      "GCC version:  gcc version 11.4.0 (Ubuntu 11.4.0-1ubuntu1~22.04) \n",
      "\"\n",
      "2024-08-25 01:35:31.581488: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 30s 93ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 3s 94ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 40ms/step\n",
      "\n",
      "Evaluating model with seed 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 30s 95ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 3s 92ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 40ms/step\n",
      "\n",
      "Evaluating model with seed 456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 30s 94ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 3s 94ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 50ms/step\n",
      "\n",
      "Evaluating model with seed 789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 30s 94ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 3s 93ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 42ms/step\n",
      "\n",
      "Evaluating model with seed 101112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 30s 94ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 3s 92ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 46ms/step\n",
      "\n",
      "Average Results Across All Seeds:\n",
      "Type: Train - Avg Accuracies: [0.61094 0.91    0.96424] ± [0.05599174 0.02450526 0.01029847], Avg Score: 0.924 ± 0.01743559577416269, top31_beam: 0.89 ± 0.02097617696340305, top33_beam: 0.978 ± 0.0040000000000000036, PF1_mean: 0.9800000000000001 ± 1.1102230246251565e-16, PF2_mean: 0.99 ± 0.0, PF3_mean: 0.998 ± 0.0040000000000000036, Recall: 0.61 ± 0.05761944116355175, Precision: 0.5980000000000001 ± 0.06764613810115107\n",
      "Type: Test_LoS - Avg Accuracies: [0.45788 0.82842 0.9376 ] ± [0.01324982 0.006801   0.00629254], Avg Score: 0.89 ± 0.006324555320336764, top31_beam: 0.844 ± 0.01019803902718558, top33_beam: 0.968 ± 0.0040000000000000036, PF1_mean: 0.9800000000000001 ± 1.1102230246251565e-16, PF2_mean: 0.99 ± 0.0, PF3_mean: 0.992 ± 0.0040000000000000036, Recall: 0.458 ± 0.014696938456699055, Precision: 0.41600000000000004 ± 0.02416609194718914\n",
      "Type: Test_NLoS - Avg Accuracies: [0.04458 0.1131  0.18594] ± [0.03757331 0.06624974 0.06776992], Avg Score: 0.16599999999999998 ± 0.05043808085167397, top31_beam: 0.248 ± 0.08328265125462805, top33_beam: 0.48600000000000004 ± 0.0615142259969188, PF1_mean: 0.898 ± 0.011661903789690611, PF2_mean: 0.922 ± 0.00979795897113272, PF3_mean: 0.93 ± 0.008944271909999118, Recall: 0.041999999999999996 ± 0.03709447398198282, Precision: 0.062 ± 0.07138627319029898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sa457043/miniconda3/envs/tf_jupyter/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10514"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% Test on all scens together\n",
    "#%%Test on Train and Test data (top-1,2,3)\n",
    "\n",
    "# Model evaluation and prediction\n",
    "def evaluate_model(model, X_data, y_data, pwrs_array, data_type, result_list, sample_indices):\n",
    "    predictions = model.predict(X_data)\n",
    "    y_pred = np.argsort(predictions, axis=1)[:, ::-1]\n",
    "    save_pred_to_csv(sample_indices, y_pred, top_k=[1,2,3], target_csv=f'preds_{model_name}_{data_type}.csv')\n",
    "    true = np.argmax(y_data, axis=1).reshape(-1, 1)\n",
    "    acc = compute_acc(y_pred, true, top_k=[1, 3, 5])\n",
    "    score = compute_DBA_score(y_pred, true, max_k=3, delta=5)\n",
    "    recall = recall_score(true, y_pred[:, 0], average='weighted')\n",
    "    precision = precision_score(true, y_pred[:, 0], average='weighted')\n",
    "    PF_mean = compute_powerfactor(y_pred, pwrs_array, k=3)\n",
    "    top_beams = calculate_top_beams(predictions, pwrs_array)\n",
    "   \n",
    "    result_list.append({\n",
    "        'type': data_type,\n",
    "        'acc': acc,\n",
    "        'score': round(score, 2),\n",
    "        'top31_beam': top_beams[0],\n",
    "        'top33_beam': top_beams[1],\n",
    "        'PF1_mean': PF_mean[0],\n",
    "        'PF2_mean': PF_mean[1],\n",
    "        'PF3_mean': PF_mean[2],\n",
    "        'recall': round(recall, 2),\n",
    "        'precision': round(precision, 2)\n",
    "    })\n",
    "\n",
    "\n",
    "# Define the seeds used for training\n",
    "seeds = [42, 123, 456, 789, 101112]\n",
    "\n",
    "# Placeholder for storing results from all seeds\n",
    "all_results = []\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"\\nEvaluating model with seed {seed}\")\n",
    "\n",
    "    # Train-Test Split with the current seed\n",
    "    X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "        multiModalData, classes, np.arange(len(multiModalData)), test_size=0.1, stratify=classes, random_state=seed)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    # Reload the scenario data\n",
    "    df_train = pd.read_csv('./ml_challenge_dev_multi_modal_v3_all_scenarios_with_LoS_status.csv')\n",
    "\n",
    "    # Find LoS and NLoS samples in the train and test indices\n",
    "    train_los_indices = df_train[df_train['LoS_status'] == 'LoS'].index.intersection(train_indices)\n",
    "    train_nlos_indices = df_train[df_train['LoS_status'] == 'NLoS'].index.intersection(train_indices)\n",
    "    test_los_indices = df_train[df_train['LoS_status'] == 'LoS'].index.intersection(test_indices)\n",
    "    test_nlos_indices = df_train[df_train['LoS_status'] == 'NLoS'].index.intersection(test_indices)\n",
    "\n",
    "    # Extract LoS and NLoS samples from the data and classes\n",
    "    X_test_los = multiModalData[test_los_indices]\n",
    "    X_test_nlos = multiModalData[test_nlos_indices]\n",
    "    y_test_los = classes[test_los_indices]\n",
    "    y_test_nlos = classes[test_nlos_indices]\n",
    "\n",
    "    # Power analysis - make sure to get the correct power arrays for each seed\n",
    "    N_CLASSES = 64\n",
    "    pwrs_array = np.zeros((df_train.shape[0], N_CLASSES))\n",
    "    for sample_idx in range(df_train.shape[0]):\n",
    "        pwr_abs_path = df_train['unit1_pwr_60ghz'].values[sample_idx]\n",
    "        pwrs_array[sample_idx] = np.loadtxt(pwr_abs_path)\n",
    "\n",
    "    pwrs_array[np.isnan(pwrs_array)] = 0\n",
    "    pwrs_array_train = pwrs_array[train_indices]\n",
    "    pwrs_array_test_los = pwrs_array[test_los_indices]\n",
    "    pwrs_array_test_nlos = pwrs_array[test_nlos_indices]\n",
    "\n",
    "    # Load the model corresponding to the current seed\n",
    "    model = load_model(f'chkp/{model_name}_seed_{seed}.hdf5')\n",
    "\n",
    "    # Initialize results list for the current seed\n",
    "    seed_results = []\n",
    "\n",
    "    # Evaluate on training data\n",
    "    evaluate_model(model, X_train, y_train, pwrs_array_train, 'Train', seed_results, train_indices)\n",
    "\n",
    "    # Evaluate on test data\n",
    "    evaluate_model(model, X_test_los, y_test_los, pwrs_array_test_los, 'Test_LoS', seed_results, test_los_indices)\n",
    "    evaluate_model(model, X_test_nlos, y_test_nlos, pwrs_array_test_nlos, 'Test_NLoS', seed_results, test_nlos_indices)\n",
    "\n",
    "    # Store the results of this seed in all_results\n",
    "    all_results.append(seed_results)\n",
    "\n",
    "# Function to average results across all seeds\n",
    "def average_results(all_results, metric):\n",
    "    averages = {}\n",
    "    types = ['Train', 'Test_LoS', 'Test_NLoS']\n",
    "    for data_type in types:\n",
    "        type_results = [res for seed_res in all_results for res in seed_res if res['type'] == data_type]\n",
    "        avg_metric = np.mean([res[metric] for res in type_results], axis=0)\n",
    "        std_metric = np.std([res[metric] for res in type_results], axis=0)\n",
    "        averages[data_type] = (avg_metric, std_metric)\n",
    "    return averages\n",
    "\n",
    "# Compute averages and standard deviations for each metric\n",
    "avg_accuracies = average_results(all_results, 'acc')\n",
    "avg_scores = average_results(all_results, 'score')\n",
    "avg_top31_beams = average_results(all_results, 'top31_beam')\n",
    "avg_top33_beams = average_results(all_results, 'top33_beam')\n",
    "avg_PF1_means = average_results(all_results, 'PF1_mean')\n",
    "avg_PF2_means = average_results(all_results, 'PF2_mean')\n",
    "avg_PF3_means = average_results(all_results, 'PF3_mean')\n",
    "avg_recalls = average_results(all_results, 'recall')\n",
    "avg_precisions = average_results(all_results, 'precision')\n",
    "\n",
    "# Print the average results across all seeds\n",
    "print(\"\\nAverage Results Across All Seeds:\")\n",
    "for data_type in avg_accuracies:\n",
    "    print(f\"Type: {data_type} - Avg Accuracies: {avg_accuracies[data_type][0]} ± {avg_accuracies[data_type][1]}, \"\n",
    "          f\"Avg Score: {avg_scores[data_type][0]} ± {avg_scores[data_type][1]}, \"\n",
    "          f\"top31_beam: {avg_top31_beams[data_type][0]} ± {avg_top31_beams[data_type][1]}, \"\n",
    "          f\"top33_beam: {avg_top33_beams[data_type][0]} ± {avg_top33_beams[data_type][1]}, \"\n",
    "          f\"PF1_mean: {avg_PF1_means[data_type][0]} ± {avg_PF1_means[data_type][1]}, \"\n",
    "          f\"PF2_mean: {avg_PF2_means[data_type][0]} ± {avg_PF2_means[data_type][1]}, \"\n",
    "          f\"PF3_mean: {avg_PF3_means[data_type][0]} ± {avg_PF3_means[data_type][1]}, \"\n",
    "          f\"Recall: {avg_recalls[data_type][0]} ± {avg_recalls[data_type][1]}, \"\n",
    "          f\"Precision: {avg_precisions[data_type][0]} ± {avg_precisions[data_type][1]}\")\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to CSV:\n",
      "        Type                                    Acc        Score   top31_beam  \\\n",
      "0      Train  0.61 ± 0.06, 0.91 ± 0.02, 0.96 ± 0.01  0.92 ± 0.02  0.89 ± 0.02   \n",
      "1   Test_LoS  0.46 ± 0.01, 0.83 ± 0.01, 0.94 ± 0.01  0.89 ± 0.01  0.84 ± 0.01   \n",
      "2  Test_NLoS  0.04 ± 0.04, 0.11 ± 0.07, 0.19 ± 0.07  0.17 ± 0.05  0.25 ± 0.08   \n",
      "\n",
      "    top33_beam     PF1_mean     PF2_mean     PF3_mean       Recall  \\\n",
      "0  0.98 ± 0.00  0.98 ± 0.00  0.99 ± 0.00  1.00 ± 0.00  0.61 ± 0.06   \n",
      "1  0.97 ± 0.00  0.98 ± 0.00  0.99 ± 0.00  0.99 ± 0.00  0.46 ± 0.01   \n",
      "2  0.49 ± 0.06  0.90 ± 0.01  0.92 ± 0.01  0.93 ± 0.01  0.04 ± 0.04   \n",
      "\n",
      "     Precision  \n",
      "0  0.60 ± 0.07  \n",
      "1  0.42 ± 0.02  \n",
      "2  0.06 ± 0.07  \n"
     ]
    }
   ],
   "source": [
    "# Define a function to format mean ± std\n",
    "def format_mean_std(mean, std):\n",
    "    return f\"{mean:.2f} ± {std:.2f}\"\n",
    "\n",
    "# Initialize the final results list\n",
    "formatted_results = []\n",
    "\n",
    "# Process the results for saving\n",
    "for data_type in avg_accuracies:\n",
    "    acc_means, acc_stds = avg_accuracies[data_type]\n",
    "    row = {\n",
    "        'Type': data_type,\n",
    "        'Acc': ', '.join([format_mean_std(m, s) for m, s in zip(acc_means, acc_stds)]),\n",
    "        'Score': format_mean_std(*avg_scores[data_type]),\n",
    "        'top31_beam': format_mean_std(*avg_top31_beams[data_type]),\n",
    "        'top33_beam': format_mean_std(*avg_top33_beams[data_type]),\n",
    "        'PF1_mean': format_mean_std(*avg_PF1_means[data_type]),\n",
    "        'PF2_mean': format_mean_std(*avg_PF2_means[data_type]),\n",
    "        'PF3_mean': format_mean_std(*avg_PF3_means[data_type]),\n",
    "        'Recall': format_mean_std(*avg_recalls[data_type]),\n",
    "        'Precision': format_mean_std(*avg_precisions[data_type])\n",
    "    }\n",
    "    formatted_results.append(row)\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "df = pd.DataFrame(formatted_results)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(f'results_{model_name}_AllScens.csv', index=False)\n",
    "\n",
    "print(\"Results saved to CSV:\")\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
